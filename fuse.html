[{"title":"Python\u00a0Notes","url":"python-notes-2.html","body":"__call__() In Python, every call function method such my_function() interpreter replace ( .__call__( >>> def >>> x+1 >>> 3 class Prefixer: def __init__(self, prefix): self.prefix = prefix def __call__(self, message): self.prefix + message Then prefixer like\u00a0this: >>> simonsays = says: \") >>> high!\") 'Simon says: jump high!' Every call function method, you\u2019re really just calling built __call__ method. There should one, preferably one, obvious way do\u00a0something It\u2019s \u2018zen Python\u2019, set guidelines help design decisions. It\u2019s choice Python made, other languages There different levels languages applies idiom level design pattern level. It applies even less architectural level where there several equally good ways organizing business logic Perl \u201cTMTOWTDI\u201d (tim towtdi) principle - \u201cThere\u2019s More Than One Way To Do It\u201d. Perl\u2019s philosophy give users way do\u00a0something.","tag":"[, ]","category":"Technical/Developer Tools"},{"title":"Adding\u00a0Search","url":"Adding-search.html","body":"I\u2019ve added search blog. Results generated type. Try typing / ctrl-k cmd-k. look Pelican plugins index you\u2019ll see Tipue search search tool ready-made Pelican plugin, unfortunately project seems died projects website now But searching static site quite common googling alternatives gave me few choices. Lunr.js seems most popular, also seemed fairly complicated probably needed. went Tiny Search seemed needed easy setup. There\u2019s even example Pelican\u00a0blogs. One hurdle success minimising false positives. default settings seem prioritise keeping size index small (tiny) over giving good user experience. Maybe amount text site significanly less, more, typical case. Either way, after checking project\u2019s issues Github found issue matched problem perfectly. solution increase tiny_magic variable build\u00a0time. According Readme, requires container building index docker run.... Unfortunately Dockerfile wouldn\u2019t complete without errors. Checking issues again adding discussion resulted alternative Dockerfile being suggested, works. Woohoo! build search index massive tiny_magic value\u00a0(2048). Then something weird happened. write Vim fzf find open files. realised fzf had stopped working. After investigating, realised working blog project, fzf.vim calls fzf CLI tool, turn calls ripgrep tool. underlying issue ripgrep wasn\u2019t working, after few hours (sob) debugging, found things makes rg special ignores stuff .gitignore file. Sneakily, without me noticing, Docker image constructing tinysearch files had created .gitignore file single entry. entry *, selects everything. So rg ignoring everything, giving no results. Which meant couldn\u2019t find open\u00a0files. still don\u2019t know (or part of) Dockerfile does this, I\u2019ve created file contains correct content, after generate search index replace traitorous .gitignore contents I\u2019ll come back later when/if better understanding Dockerfile syntax, or\u00a0Rust. Adding search site made content feel lot closer accessible. Once working immediately wanted keyboard shortcuts open search box select results. Kind does it. It feels really fast and\u00a0precise. Googling jquery packages, also vanilla javaScript showed me enough get things working. You hit / ctrl-k cmd-k bring search box populates results you\u00a0type! Only whole words matched unfortunately, still super useful feature. search index includes article content well article titles categories. I\u2019d tweak few keyboard shortcut behaviours, add contents various pages (which aren\u2019t articles) search\u00a0index.","tag":"[, , , ]","category":"Technical/Web"},{"title":"Cardano: Generating\u00a0Addresses","url":"cardano-generating-addresses.html","body":"different customers deposit send ADA (The unit currency Cardano blockchain) Cardano node, necessary determine customer responsible transaction correct customer account be\u00a0updated. As things involving blockchains, initially seemed simple requirement involved several hours of\u00a0work. Cardano wallets generated parameter called default 20, unused addresses node generate client REST API. addresses used, node automatically generate another there always 20 probably very convenient personal use. want someone send me funds, simple api call cURL get fresh address. But running service, weather e-commerce financial service, really good enough. Some advice forums says generate wallet very large such 10,000 just generate wallet run fresh addresses, still feels a\u00a0compromise. But lets explain our situation detail first. customer wants send us ADA, want give them fresh address that\u2019s never been before have. Then know any funds arrive address particular customer. However don\u2019t know customer actually address transfer any funds. address might remain unused might not. Nevertheless, address now reserved them, no else use\u00a0it. In way, might generate maintain list thousands addresses never used. Using seems bad\u00a0solution. Fortunately, answer, albeit fairly convoluted obscured form. mnemonic generate wallet originally, generate 2^31 unique addresses like\u00a0so: Clone repo build docker\u00a0image: git clone docker build -t . Get mnemonic generate file containing list space separated words one\u00a0row. Run the\u00a0following: export increment=0 && cat mnumonic.txt | docker run --rm -i key Shelley | docker run --rm -i key child | docker run --rm -i key public | docker run --rm -i address payment --network-tag testnet > payment.addr && cat payment.addr ;echo","category":"Technical/Cryptocurrencies"},{"title":"More VIM\u00a0notes","url":"more-vim-notes.html","body":"Vim Python great notes linting code completion plugins I\u2019ve either copied less doing\u00a0already. Valuable Dev following gems I\u2019d start\u00a0using. gf - edit file file path under the\u00a0cursor gx - open file file path under the\u00a0cursor [m, ]m - move start end a\u00a0method @: - repeat last\u00a0command :<C-f> - open command history\u00a0list >> indent line. . repeat operation, >>.. indent 3\u00a0times. You along count, indention lines (with current being top line). 3>>.. indent 3 lines 3 blocks the\u00a0right. <C-y> - moves screen line, moves cursor go off the\u00a0screen <C-e> - moves screen down lines, moves cursor go off\u00a0screen <C-f> - move screen down page, cursor top of\u00a0screen <C-b> - move screen page, cursor bottom of\u00a0screen","category":"Technical/Developer Tools"},{"title":"Two Years Of\u00a0Vim","url":"two-years-of-vim.html","body":"I\u2019ve been feeling very comfortable Vim + Tmux setup recently. Navigating around shells files isn\u2019t taking much mental effort It\u2019s taken years working full vim get stage where commands pepper text files outside vim (email, notes, etc) vim keys accidentally - j k x etc can\u2019t remember command something I\u2019m actually doing it. When action, muscle memory pay attention underlying key press something goes\u00a0wrong. noticeable trying find unbound key combination action, reading article vim thinking \u201cthat\u2019s new\u201d actually I\u2019ve been doing A pleasant surprise been doesn\u2019t take much effort rebind single command retrain myself it. presumably mental effort other commands become negligible. In early days, retraining key combination took lot effort already making effort get doing things in\u00a0Vim. work even vision blurry (and speech slurred head heavy) text objects navigation commands get where know text is. I\u2019m saying should work I\u2019m tired, can, I\u2019m already familiar","category":"Technical/Developer Tools"},{"title":"Binance-Chain: Running a\u00a0node","url":"binance-node-api.html","body":"week I\u2019ve been setting binance-chain node. Unlike Polkadot Cardano, I\u2019m going run container until it\u2019s working reliably. Binance docs show couple ways install node. install.sh script went default values much possible. Installation My first attempts sync full node install.sh script, node wouldn\u2019t sync completely, get stuck. setup VM did manual install (\u201cOption Two\u201d) far node been syncing without any issues. You download genesis file separately case. Also, sure download node-binary repo git lfs just git. It look worked bnbchaind wont completely downloaded unless lfs It took me awhile realise documentation assumes environment variable called BNCHOME. You either create export (like any environment variable) replace environment variable start node command file path: nohup bnbchaind start --home BNCHOME & Note: I\u2019m sure bnbchaind needs environment variable set not. It doesn\u2019t give errors isn\u2019t set, seem having success BNCHOME defined. Syncing node There three ways sync node. Fast-sync isn\u2019t fastest way sync node, hot-sync is. Using install.sh should put correct default values file, needed adjust ping_interval pong_timeout recommended values. Surprises documentation assumes familiarity running tasks background terminal session, you\u2019re familiar nohup. wasn\u2019t - I\u2019d even forgotten & symbol does1 did research wrote notesIt starts process background. You move foreground fg see list running jobs jobs. You move running job background (like vim session) ctrl-z \u21a9","category":"Technical/Cryptocurrencies"},{"title":"nohup and Background\u00a0Processes","url":"nohup-and-background-processes.html","body":"Stop stuff from\u00a0stopping run command terminal session terminal session disconnected, processes running also be\u00a0terminated. discovered last night trying download ~500gb database overnight. logged morning expecting see completed download, realised had half the\u00a0file. Use nohup ignore HUP signals One solution seems nohup, command ignores HUP signal. It stops programme stopping terminal session running is\u00a0stopped. By convention, HUP signal method terminal warn dependent processes to\u00a0logout. You probably want run nohup background. You might want prevent creating nohup.out. Close redirect fd0 -\u00a0fd2 On Linux, run command nohup nohup automatically closes stdin. you\u2019re MacOS BSD doesn\u2019t automatically happen, might want redirect yourself. background process tries read anything stdin pause itself wait bring foreground fg input. probably waste of\u00a0time. nohup detects redirected stdout stderr won\u2019t create nohup.out. As commands, put & end command, run background. You bring foreground running fg, see list jobs running jobs. redirect input /dev/null </dev/null stop program receiving keyboard (stdin) input, won\u2019t prevent accessing terminal directly. Also haven\u2019t removed program shell\u2019s process\u00a0group. Stopping signals disown want remove program shell\u2019s process group, immediately after you\u2019ve run command start programme, run disown no arguments. background process no longer associated shell job wont any signals forwarded the\u00a0shell. A disowned process gets nothing (no signals) sent shell. But without nohup still sent HUP signal sent via other means, such manual kill command. A nohuped process ignore any HUP signal, no matter are\u00a0sent. Source","category":"Technical/Developer Tools"},{"title":"File Descriptors and\u00a0/dev/null","url":"file-descriptors.html","body":"/dev/null In Linux everything file, including virtual devices. Processes (programmes) request access these\u00a0devices. difference between these virtual device \u201cfiles\u201d real files, virtual device OS generates goes file, instead reading from\u00a0storage. /dev/null virtual device looks file write output black hole discarded, lost forever never seen. It isn\u2019t written the\u00a0terminal. File descriptors integer values assigned a\u00a0file. stdin file descriptor of\u00a00 stdout file descriptor of\u00a01 stderr file descriptor of\u00a02 Two outputs generated whenever CLI run stdout stderr. By default, both these streams associated terminal. You file descriptors redirect\u00a0them. command exits successfully, exit status is\u00a00. exits exit status don\u2019t specify file descriptor want use, bash stdout by\u00a0default. following redirects stdout away terminal /dev/null. $ echo \u201cHello World\u201d > log.txt redirect stderr a\u00a0file: $ asdfadsa 2> error.txt run command generates lots error messages along \u201cgood\u201d messages, redirect error messages (stderr) /dev/null see useful stdout $ grep -r hello /sys/ 2> /dev/null want run command see errors, (stderr) filter stdout redirecting stdout messages /dev/null: $ ping google.com 1> /dev/null Redirect output /dev/null want command run\u00a0quietly, Redirect output. command below redirects stdout /dev/null (the default file descriptor isn\u2019t specified) redirects file descriptor file descriptor\u00a01. $ grep -r hello /sys/ > /dev/null 2>&1 Read input file instead the\u00a0terminal 0<infile Direct stderr append 2>>logfile Combining 2>&1 means send stderr wherever stdout going. means you\u2019ve combined stdout stderr stream can\u2019t separate them anymore. It also means pipe stderr same stdout. Input You redirect stdin similarly. run </dev/null program attempt read stdin merge (or redirect) syntax (for example <&2) won\u2019t work, redirect","category":"Technical/Developer Tools"},{"title":"Cardano: Running a full\u00a0node","url":"cardano-node-api.html","body":"recently deployed Cardano node Google Cloud Platform API create watch addresses, transactions. Helpfully, Cardano quite simple get running familiar know where look, questions ask. Table Contents Docker Compose Cardano wallet Cardano-CLI REST API Surprising things Docker Compose Cardano Wallet repo1 contains almost get started. command run is: docker-compose -d does couple things you: Creates Cardano node begins syncing network Creates Cardano Wallet instance Creates required volumes Maps ports required API calls. Running docker ps should show two containers running, cardano-node Cardano wallet In order run cardano-wallet commands (not API, directly node) you\u2019ll docker exec container this: sudo docker exec -it sh Then run commands like: cardano-wallet network information Cardano-CLI Similarly, want cardano-cli programme, exec cardano-wallet container: sudo docker exec -it sh cardano-cli \u2014version REST API Perhaps wont though once containers running online, REST API monitor node, transactions, watch addresses.2 For example, good test see node ok run curl Addresses Cardano BIP39 compliant, before REST API create address already generated keys mnemonic. done various other tools (web page, python) results put JSON file according API spec. Surprising things Cardano requires addresses created sequentially instead allowing user generate them ad-hoc, node default manage creation addresses wallet.3 sets unused addresses wallet. By default 20. When address used, node automatically generate unused address wallet, there always pool 20 unused \u21a9","category":"Technical/Cryptocurrencies"},{"title":"Polkadot: Running and interacting with a full\u00a0node","url":"running-a-polkadot-node.html","body":"recently set Polkadot node Google Cloud Platform create addresses Instead building source Docker. After found command run\u00a0is: docker run -it -p 30333:30333 -p 9944:9944 -p 80:9933 -v --rpc-external --rpc-cors=all --chain westend --ws-external differs (current) documentation two\u00a0ways: volume needs point symlink supposed exist /data appears broken current image. See GitHub issue for\u00a0details. Port 9944 needs be\u00a0mapped. One first API calls likely check things working expected, particularly WebSocket connections, open WS connection notified node syncs block. node does once caught piers. Whilst still syncing current highest block initial API call. ended chatting Parity devs issue discord Stack Overflow. Other that, everything went described","category":"Technical/Cryptocurrencies"},{"title":"Microservices, Docker,\u00a0Azure","url":"microservices_events_docker.html","body":"great presentation microservices event And comprehensive overview of\u00a0Azure","category":"Technical/Developer Tools"},{"title":"Regrets Of The\u00a0Dying","url":"regrets-of-the-dying.html","body":"wish that: I\u2019d had courage live life true myself, life others expected me. hadn\u2019t worked hard. I\u2019d had courage express feelings. had stayed touch friends. I\u2019d myself happier. \u2026the five most common regrets terminally ill patients, described palliative care nurse1:Source \u21a9","category":"Non-technical/Family"},{"title":"A List Of Unconnected Thoughts And\u00a0Aphorisms","url":"a-list-of-unconnected-thoughts-and-aphorisms.html","body":"Do people care love back? It does matter slowly go long stop. Assume nobody going help you, nobody going stop you. Money (just) fuel. Lets talk end. My current self, existing now, seen context end, beginning. When want money, ask advice. When want advice, ask money. You follow rules war you, enemy. You fight rules keep humanity.1 want top performer any field become abnormal. Normal average, definition, far below top! \u201cWe always average what\u2019s normal. I\u2019m what\u2019s normal.\u201d \u2013Kobe Bryant Becoming Abnormally Good2 something: No reasonable excuses - don\u2019t (reasonable) excuses off hook. You negative emotions leads inspired decision making. Not Worrying About What You Can\u2019t Control We know it\u2019s best genuinely friendly no matter who you\u2019re trying get information of, thanks part work Hanns Scharff slew studies interrogation techniques3. source \u21a9source \u21a9source \u21a9","category":"Non-technical/Family"},{"title":"Notes From An Interview With Geoffrey\u00a0Hinton","url":"notes-from-an-interview-with-geoffrey-hinton.html","body":"Read literature don\u2019t read too much of\u00a0it. Trust intuitions, don\u2019t trust them there\u2019s no\u00a0point \u2018This person either drunk stupid\u2018 - feedback his papers went For creative researchers; read bit literature notice something think everybody doing wrong. (I guess GH contrarian this\u00a0sense) Look problem doesn\u2019t feel right. Then figure it\u00a0right. When people tell (contrarian) approach just no good, just keep at\u00a0it. Either intuitions good they\u2019re not. good should follow them eventually successful. bad doesn\u2019t matter you\u00a0do. You might well trust When try replicate published paper discover little tricks needed it\u00a0work. Never give student something bad student they\u2019ll come back say didn\u2019t work. They\u2019ll say little decision made didn\u2019t realise crucial. But give good student, give them anything come back say it\u00a0works Read enough start developing intuitions, trust intuitions go it! - Don\u2019t too worried everybody else says its\u00a0nonsense. think it\u2019s really good idea, others tell complete nonsense, know really One example Ramford first came variational methods, sent mail explaining former student, who showed his colleagues. He told me said \u2018Either guy drunk he just stupid\u2019. They really really thought was\u00a0nonsense. Maybe partly i explained - explained intuitive terms, think good idea other people think complete rubbish, sign really good\u00a0idea. See find advisor who beliefs similar own, work stuff adviser feels deeply about, you\u2019ll get lot good advice from\u00a0them. Read enough trust","category":"Non-technical/Career"},{"title":"Questions For Interesting\u00a0Conversations","url":"questions.html","body":"What\u2019s best piece advice ever\u00a0received? What say 18-year-old self had chat them\u00a0today? Have ever lost rejected friend? Tell me changed mind. What been thinking lately? What\u2019s your\u00a0mind? Do work language that\u2019s mother tongue? What live translation? there choice between remembering forgetting, lean towards side of\u00a0forgetting? Were raised autonomy loyalty? Was there ever moment where thought, \u2018I\u2019m giving up\u2019 \u2014 did you\u00a0do? Was identity given chosen you?","category":"Non-technical/Family"},{"title":"Portfolio: Image\u00a0Recognition","url":"portfolio-image-recognition.html","body":"I\u2019ve created computer vision model recognizes traffic lights. I\u2019ve also created page where model queried results shown. needed custom page typical blog article, hosted portfolio section here. page redirect automatically view browser, those reading RSS, head over see the\u00a0results!","category":"Technical/Data Science"},{"title":"Photographs","url":"photographs.html","body":"","category":"Non-technical/Photography"},{"title":"Notes From \u201cMastering Vim\u00a0Quickly\u201d","url":"notes-from-mastering-vim-quickly.html","body":"Table Contents Verbs Registers Insert\u00a0Mode Normal\u00a0Mode Command\u00a0Mode Visual Block Mode\u00a0<C-V> Ranges Searching Undo Splits Macros Other Verbs s - delete char under cursor enter Insert\u00a0Mode. r - replace char under\u00a0cursor. c/hello - change until next occurrence of\u00a0\u2018hello\u2019 Registers \"ayy yank entire row register a. \"Ay yank register A append text existing contents the\u00a0register. :registers - preview contents Insert\u00a0Mode <C-W> - delete back one\u00a0word. <C-U> - delete back start start cgn - searching word (either / * #) want change instance search result, <verb>gn change delete go next result. .dot operator repeat both steps (moving and\u00a0changing). <C-R> - paste. <C-R><C-P>0 there new-line chars Normal\u00a0Mode <C-A> <C-X increase decrease a\u00a0number. Command\u00a0Mode set ft? - find filetype is\u00a0loaded. Visual Block Mode <C-V> Select column numbers want increment, g<C-A> turn them Ranges :put =range(1,10) - insert list :for i range(1,100) | put | endfor - loop generate long\u00a0list. Searching g# g* partial matches, # * exact\u00a0matches. Search word under cursor, similar: Press /. <C-R> <C-W> - copy paste word under cursor search box. Edit as\u00a0necessary. After you\u2019ve done search, <C-o> jump back where cursor was\u00a0before. Find replace whole words only: Find replace either old-word1 old_word2: g <C-G> - show stats current bugger - word count, count, char\u00a0count. Undo g- g+ - undo\u00a0branches. Under changes within period time: :earlier 2d - undo changes last 2\u00a0days :later 5m - redo changes last 5\u00a0minutes :earlier 3f - undo changes last three buffer\u00a0writes s seconds, m minutes, h hours, d days, f saves @a - Use global command execute macro lines current buffer containing - For every containing \u201cgood\u201d substitute \u201cbad\u201d with\u00a0\u201cugly\u201d Splits <C-W> r - rotate splits left right split vertically. <C-W> R - rotate splits right left. <C-W> H - move current split far left full height. <C-W> J - move current split bottom screen full\u00a0width. :only - close splits except current\u00a0split. Macros @o - macro stored buffer O lines match Other <C-O> Insert Mode jump Command Mode command put back Insert .dot command repeats commands changes buffer content. It wont repeat","category":"Technical/Developer Tools"},{"title":"Notes From \u201cPowerful\u00a0Python\u201d","url":"python-notes.html","body":"parts Aaron Maxwell\u2019s Power Python newsletter don\u2019t want forget: Table Contents Emergent Abstractions Practioner, Engineer, Scientist Sentinel Values Levels Python Code Read PEPs Emergent Abstractions Get expecting letting abstractions emerge projects. find yourself repeatedly solving similar problems similar ways, simplify code Is couple convenience methods helper class? below code snippet gives three ways instantiating twitter API client: A generic \u201cnormal\u201d way A specialized way looks certain environment variables A specialized way looks configuration file import os # get environment variables import twitter # class ApiClient: def __init__(self, consumer_key, self.api = twitter.Api( consumer_key, @classmethod def cls( @classmethod def path): open(path) config_file: # ... cls(...) # ... Practioner, Engineer, Scientist Practioner - You thing (a framework, tool) Engineer - You thing needed to, recreate Scientist - You create frameworks paradigms never existed before Aim engineer level. Sentinel Values Instead setting sentinel something quite impossible, None \"None\" set object() better creates unique instance object class there no ambiguity where came from. A sentinel set variable to. It\u2019s special differs other legal possible values variable have. It\u2019s signal canary something happened. Levels Python Code Syntax - understand indentation important, sometimes parenthesis, etc Idiom - building blocks program. \u201cParagraphs\u201d code follow common patterns, loops, context managers. Design Pattern - Less well defined Idioms, useful. - Creational Patterns, factories - Structural Patterns, Adapters Proxies - Behavioural Patterns, Visitor Strategy These tend same across different languages. Architectural - large-scale structure software system. language itself doesn\u2019t lot difference, application same architecture whether written Python Java. interface between different components different, \u201corgans\u201d body essentially same. Read PEPs A Python Enhancement Proposal document that\u2019s written propose feature Python. It fully details proposed feature, arguments against it, lots sample code. PEP accepted future version Python, PEP becomes authoritative document feature it. PEPs tend written best programmers world, hang them. Abstraction principal OOP \u21a9","category":"Technical/Developer Tools"},{"title":"Mental Models I Used To\u00a0Use","url":"mental-models-i-used-to-use.html","body":"rules1 mental models helped me succeed season phase life may best next phase. Here list few mental models remember being concious previous years. Probably I\u2019ve already forgotten some. Always ask \u201cwhy\u2026\u201d. Be obsessive this. It\u2019s going things harder while before things get easier. You\u2019ll find difficult answers otherwise wouldn\u2019t. you\u2019re concerned present true ignorance bliss, otherwise it\u2019s liability. \u201cWhat if\u2026\u201d another good question ask lot. Adapt situation, don\u2019t adapt any choice. Be kind water, going around things through gaps. Look edges gaps, parts aren\u2019t well known. Let people talk much want to. Shut listen. mean harm don\u2019t respect it\u2019ll become obvious keep talking. mean well they\u2019re saying something useful, benefit letting them talk more. Inversion - hard know should something, feel didn\u2019t it, didn\u2019t happen? Regrets inevitable, everyone them. Same making mistakes. Let regrets things did do, didn\u2019t do. willing try something, fail it, still glad tried, should almost definitely it. Commit enjoy experience! Don\u2019t scared, least, scared optimistic happy2. There beauty luxury being such bad spot backed corner seemingly no way out. Things become black white, instead shades gray, priorities options much clearer. You likely work very efficiently effectively scenario, learn important things yourself. Now I\u2019m older can\u2019t ever things become bad situation becomes black white. navigate world grays. become black white, I\u2019ll already long list failings. When younger, things were fragile. My resources were smaller things quickly flip good bad. Enjoy few benefits situation gives, (hopefully) once gone gone good. best way solve problem prevent occurring first place. Succeeding bring own challenges. Take responsibility things responsible for, kind of. Do deliberately own benefit, don\u2019t forget pretending it\u2019s this, force yourself understand situation deeply other peoples perspectives. learn faster help future. Keep arms length though - it\u2019s make-believe able switch off. It\u2019s toy play with. seems \u201cextreme is. think important mental models you\u2019re comfortable with, lets decisions quickly consistently. But understand map territory, these just tools toolbox.or policies \u21a9Courage isn\u2019t absence fear. It\u2019s being scared doing right thing anyway. \u21a9","category":"Non-technical/Family"},{"title":"Vim: GoTo Tag\u00a0Definition","url":"vim-notes-goto-tag-definition.html","body":"There multiple ways doing anything vim, including going where function object defined, usually something least 3 times before without breaking focus train thought. My memory hazy remember spending 1/2 day looking considering solution wanted commit to.1 My options seemed between YouCompleteMe ALE. [Update!2] can\u2019t remember everything read tried, trust conclusions. Looking .vimrc see <leader>x mapped :YcmCompleter GoTo works just fine, even module imported somewhere outside current project. tool working ready use, just hadn\u2019t internalized yet. Commands remember: <Leader>x - GoTo definition - YCMs best guess \u2018intelligent\u2019 goto command, whether declaration definition. <F2> - Toggle tagbar Jump Lists Change Lists you\u2019re going jumping around where things defined, know jump back again. It seems there two lists aware of, jump list3 change list4. Jump List A list locations cursor jumped to. Relevant jumping definition. <C-O> move jump list <C-I> mode down jump list Change List A list locations where change made. A change something undone u. '. move . mark. . special mark automatically set location last edit. '' bring back where were before last jump g; g, also move down change list powerful tool, worthwhile take closer look can\u2019t do. \u21a9YCM ALE work fine goto definition linting, don\u2019t give me satisfactory looks might offer improvements. \u21a9:help jumplist \u21a9:help changelist \u21a9","category":"Technical/Developer Tools"},{"title":"What\u2019s So Different About\u00a0Now","url":"whats-so-different-about-now.html","body":"think less aware our ignorance previous generations. It easy implicitly assume useful information available us, therefore informed really\u00a0are. think internet made information accessible global air travel made world feel\u00a0smaller. Whilst individual hopefully never pretend know everything, think easy assume right information exists being people whom is\u00a0relevant. But accessibility information put us situation similar information scarcity. We still actively search information want, information comes us easily free equal find apply\u00a0effort. easily short pieces news information am always slightly overwhelmed. pace modern communications encourages me never slow down enough form own questions frame own arguments. always find answer questions, last checked whoever gave me wasn\u2019t going profit from\u00a0it?","category":"Non-technical/Career"},{"title":"Predicting the Future using Human Nature and\u00a0Technology","url":"what-happens-next.html","body":"Predicting future sounds tough problem, try without realising\u00a0it. We predict future think risky scary something is, think what\u2019s really going change announcement press release. We try predict future we\u2019re supermarket checkouts try pick queue move fastest. always seem pick wrong\u00a0one. There million ways trying predicting future good ones models reduce complexity emphasise key One them comparing influence human nature technology outcome, comparing event what\u2019s Human nature doesn\u2019t change, something driven fear greed probably doesn\u2019t matter century occurs in. Technology change, something enabled prevented due technological progress date is\u00a0important. What driving scenario? Is human nature technology? Supermarket checkouts mostly manual require couple adults work together, human nature much bigger role efficiency tech. Young men stack pack quickly, old women opposite. What types shopping bags have, pay, even items they\u2019re buying, probably going lead same probably works getting through","category":"Non-technical/Career"},{"title":"Financial Doom And\u00a0Gloom","url":"financial-doom-and-gloom.html","body":"Financial crises seem happen fairly regularly, shouldn\u2019t unexpected. But other hand, no-one seems particularly concerned any particular aspect our current financial system. At moment our attention controlled other threats. am concerned lot money been injected money supply haven\u2019t seen any inflation, am concerned price stocks no longer driven business fundamentals company, macro economics. It terrible investor, alarming. Value investing should always decent way money, unless markets broken. price something doesn\u2019t represent value, correction inevitable. Interest rates really low moment, spare money want work where put it? Not bank account, interest rates low1, government debt, yield low. It stocks want investments increase meaningfully. But everyone doing drives price up, their price increasing excel even further. think reason concern super low interest rates massive increases money supply, there couple other factors also contributing. It\u2019s easier ever retail investors participate stock market, seems good idea. However retail investors influence effect prices, themselves manipulated influenced regarding buy sell, likely kind threat financial stability. We\u2019ve never seen social media combined quick, cheap investment services amateurs before. Index funds also popular ever2 - efficacy index investing relative traditional funds stock pickers very high over medium long horizons index funds much cheaper. But index funds become too large end influencing market predictable rigid ways. Index funds cannot choose buy much buy - just track index. company\u2019s stock crosses certain thresholds, their stock bought sold. It seems possible create feedback loops where funds buy rising stock, increases scarcity price, requires index funds purchase same stock. amount euros existence 2019 90% 2010.3 But inflation between 2010 2020 13%.4 Why that? price something doesn\u2019t represent value, correction inevitable.Why interest rates low? Because confidence economy low, central bankers lower interest rates 1. Cheaper business borrow money invest their business therefore easier business investments profitable, 2. So attractive investors their capital invest business (which grows economy) relative depositing spare cash bank account (which safer less efficient way deploy capital). Interest rates affect relative risk-reward ratios different investment strategies \u21a9Index Funds Are New Kings Wall Street \u21a9statista \u21a9","category":"Non-technical/Career"},{"title":"Debugging the more_categories plugin for\u00a0Pelican","url":"debugging-more-categories-pelican-plugin.html","body":"I\u2019ve realised plugins blog working correctly. plugin to: add subcategories assign multiple categories articles. Subcategories aren\u2019t working Pelican thinks article just categories contain forward slashes. In his \u201cpowerful python\u201d emails, Aaron Maxwell recommends looking source code popular python libraries see really good Python written, talented developers write code solve problems. good opportunity look code powers plugin see can: Understand source code Locate source problem Fix problem don\u2019t know Pelican amazingly good quality not, get feeling developer resources, I\u2019ve got real reason motivation look underlying code I\u2019m going give shot. documentation sparse doesn\u2019t help, get impression whoever wrote feels Pelican simple it\u2019s obvious what\u2019s going 1. It\u2019s obvious me. Pelican Plugins Every plugin register() function, here plugin: def register(): understand idea signals Django, generators discussed bit documentation. So else happening\u2026 As write down understanding plugin, I\u2019m aware understanding definitely incomplete probably wrong. hope progress see mistakes I\u2019ve already written. called first, takes two arguments, generator metadata. entire function 3 lines here is: def metadata): categories = = name categories] = It looks gets category metadata article. Presumably function called articles already been parsed metadata object already been created populated metadata articles, including categories. first row splits categories multiple categories listed. metadata dictionary, there metadata dict article, otherwise couldn\u2019t just get get assoiciated dictionary key split string commas. means function called once article. don\u2019t know text_type does yet. Maybe ensures output always string. It\u2019s imported six remember seeing being dependecy other packages. .. Having checked documentation six looks right - represents unicode textual both python2 python3. Pelican originally written Python2 guess. Next step write key-value pair metadata dictionary article. plugin adds functionality python enabling categories just category article. It seems clear adding categories key metadata dict obvious way this. categories key list where item instance Category class. class instantiated two arguments, name string previous row, currently understood. .. printing contents shows dictionary settings. Easily assumed good confirm. I\u2019ll dig Category class moment, first lets quickly cover last row function. category attribute articles metadata simply updated first item categories list (categories list indexed.) class Category(): class class defined plugin (which 96 lines code). It 6 methods, 5 them decorated, no constants. decorators property [3], _name.setter [1] [1]. URLWrapper imported don\u2019t know does beyond \u201cwrapping URLs\u201d. @property Decorators functions takes methods functions inputs. Using property along setter decorators lets class property assigned whilst ensuring arbitrary conditions logic upheld. @property decorator over method called foo, there decorator called foo.setter method somewhere class. That doesn\u2019t seem entirely right though, our Category class, @property decorator over _name method, also @_name.setter decorator over another method called _name. But other methods @property decorators (slug ancestors) any associated setter decorators methods. setter _name seems create parent categories string contains slashes: @_name.setter def _name(self, val): '/' val: parentname, val = 1) self.parent = self.settings) else: self.parent = None self.shortname = val.strip() Here, self.parent becomes instance category class, instantiated parentname self.settings. recursive however levels subcategories specified. ancestors as_dict methods seem confusing. ancestors isn\u2019t called mentioned within class definition, called function called after get_categories function returns. don\u2019t understand why needs @property decorator though. class inherits URLWrapper probably next best place look\u2026 Indeed, looking definition URLWrapper shows as_dict method overriding definition base class.I guess it\u2019s \u201ccurse knowledge\u201d \u21a9","category":"Technical/Developer Tools"},{"title":"Different Views For Different\u00a0Users","url":"different-views-for-different-users.html","body":"blog serves variety purposes. It\u2019s partly journal I\u2019m teaching myself developer scientist, it\u2019s also personal blog, articles interests experiences. It\u2019s unlikely anyone interested every article, I\u2019d easy people read content they\u2019re interested in. Therefore thought separate articles two broad groups, technical non-technical. visit blog first clicking link technical article, site show technical articles blog. It\u2019s same non-technical articles. want, change these settings clicking paw icon1 navbar blog index page. did mainly could. playing around blog. JAM stack feels accessible fun working tailwind jQuery. think playing (being curious, lighthearted, unhurried being concerned failure) really important. Especially adults who don\u2019t usually much. Most successes big opportunities been result process started playing around. Here list requirements adding feature: Requirements: user lands page DOESNT local setting - create local setting based article being read user lands lands page DOES local setting contradicted - reset local setting \u201call\u201d user lands index DOES local settings, show articles match setting Steps: Index page: check local storage option exists, print console result Index page: button group Index page: correct button active page load localstorage Index page: update active button page click Index page: articles button clicked Index page: local storage does exist, respect Index page: add 3 stage switch hamburger menu Index page: hamburger menu behave intuitively small screens Index page: local storage does exist, pop modal asking choice Article page: check local storage option exists, print console result Article page: local storage doesn\u2019t exist, create according article Article page: local storage does exist contradicted, update article It\u2019s paw cat\u2019s paws cat category. might change something intuitive future, making icon N user seeing non-technical posts, T technical, A posts. \u21a9","category":"Technical/Web"},{"title":"3 Different Types Of Programming\u00a0Problems","url":"different-types-of-problem.html","body":"Three categories problem Last year creating moneybar pippip there were few problems took much effort solve others. think group problems 3 buckets, based much take solve. Type takes less 15 minutes solve, takes between 15 45 minutes solve, 3 takes 45 minutes (usualy much more). Type 3: When start learning hard thing (like web development), almost everything third bucket it\u2019s exhausting. You set aside big chunks time, focussed undistracted, calm wide awake, prepared long arduous journey. Probably criteria success should \u201cam dead?\u201d you\u2019re asking question you\u2019re guaranteed successful keeping morale high necessary success. Type 2: Hopefully good progress understanding basics internalizing relevant abstractions, problems quickly1 become problems. They take 15 45 minutes solve. Maybe know enough break big general problem smaller problems (you developing domain expertise) intuitions solve problem becoming better first second attempts likely correct, rather fifth sixth. Knowing google problem get answer also really important skill, requires intuiting English speaking expert ask question. isn\u2019t trivial don\u2019t hear people discussing often. When most coding problems 2, feels I\u2019m learning most efficiently I\u2019m most productive2. Type 1: After while, problems solved become problems. They take less 15 minutes solve, because: All big problems been solved now you\u2019ve got smaller problems left, Your intuitions good expertise increased know where look answers.3 Exceptional problems: But there seems consistent exception model.4 Let\u2019s silly call them W problems. These problems eat far too hours, tiring solve, even (in most other respects) expert. For me, these tend relate blob storage solutions web apps deployed production. think several factors why so, I\u2019ll describe specifics before generalising. When web app runs production, stored web server things web-server cheap efficient things database file storage bucket cheap efficient. Therefore stored somewhere else plumbing join everything together. There abstractions involved work easily securely. However developing locally, doing everything laptop. You web-server, relational database file system same place. big, fundamental, architectural difference between development environment production environment. As general rule, these supposed similar possible. These differences much easier something works locally doesn\u2019t work production, it\u2019s very hard test thing work production without deploying staging environment, likely less familiar local development setup. Deploying staging debugging staging slower harder doing same thing locally. Logging (and filtering) likely important. Solving exceptional problems So solve these problems quickly efficiently? What problem makes hard? Let\u2019s examine makes problem difficult solve: Iteration cycles slow - can\u2019t test locally, deploy staging takes time. problem occurs \u2018high friction\u2019 environment - difficult dig around figure what\u2019s really going hidden below 3 different layers abstraction, remote machine limited access via web browser. want able dig investigate quickly easily same tools writing testing code locally. I\u2019ve taken great efforts set local development environment this, stressful switch different limited set tools. problem result several things interacting once, can\u2019t just test things time. These things probably very similar abstractions. Thinking clearly, learning, buidling, solving problems, rely being able separate untangle seemingly complex situation component parts figure causes what. can\u2019t isolate individual concerns components, black box keeping ignorant. In web development, customized logging usually good way being isolating exploring particular components. Having said that, think best way solve problem prevent occurring first place, I\u2019m good enough figure that, yet.on timescale? Life long, does really matter takes week month learn something meaningful? Momentum, having fun, important though. \u21a9from personal growth point view. suppose employers point view want problems solved fast, problems. \u21a9Open right file, google right query (and follow link stack overflow), changes, run static checker linter, run tests, push. Done next item. \u21a9which totally fine. It\u2019s just mental model, map territory \u21a9","category":"Technical/Web"},{"title":"Why I Want To Write\u00a0Regularly","url":"why-i-want-to-write-regularly.html","body":"As see, I\u2019ve recently started writing frequently. want often thoughts I\u2019d explore develop further, rarely do. find writing hard forces me organise thoughts look substantial really are, aren\u2019t. There truth saying \u201cto know thing able teach \u201c, writing well several similarities teaching. Can really copy collection thoughts head yours? remember watching Inception hearing most resilient parasite idea. think that\u2019s mostly true, older get believe ideas matter2. They subtle consequences. They first dominos. don\u2019t expect writing regularly become permanent habit - doesn\u2019t be. But want focus while become significantly better. It\u2019s skill too benefits ignored. realised blogs remembered most were focussed unapologetic their priorities. Most them lot text focus design. They easy read text, don\u2019t spend attention header images styling. Before redesigned blog had default settings asked me supply image post, summary, suggested tweet. None necessary, whilst tried blog better ended making worse added complexity distracted thing. These features still there want them, set default anymore. They\u2019ve been moved background, forget exist OK - just shows weren\u2019t important practice thought they\u2019d Yak Shaving. You Ain\u2019t Gonna Need It, mate.wikipedia article, extenal validation \u21a9and also, asking right question important finding right answer. guess asking right question always necessary, finding right answer sometimes sufficient. Sometimes get answer bit wrong asked right question, still get enough benefits avoid problem. \u21a9","category":"Non-technical/Learning"},{"title":"Python: Becoming A Better Python\u00a0Developer","url":"becoming-a-better-python-developer.html","body":"I\u2019ve been subscribed Aaron Maxwell\u2019s \u201cPowerful Python\u201d newsletter over year really it. His emails opinionated candid, singularly focussed. He seems passionate he does like\u00a0that. Ultimately, emails designed drive sign-ups his courses suspect very good, there lot free emails. Thanks Aaron. realised emails sequential subscriber gets same sequence messages regardless signed up. There \u2018first\u2019 message, \u2018second\u2019, kind progress and\u00a0flow. means there benefits paying attention usual email subscriptions. Even though emails arrive I\u2019m supermarket, making dinner kids, it\u2019s good try read After being subscribed several months, unsubscribed resubscribed. Now know reliable high quality advice I\u2019m going prioritise working through examples doing missed first time. I\u2019ve gone back beginning reinforce parts know try again eluded me first\u00a0time. Three kinds practice projects become A web app - Django don\u2019t know framework user. Done\u00a0this. A command tool - argparse module, it\u2019s standard library. Haven\u2019t done yet, guess now good start. It seems simplest quickest three kinds project, see useful - lets app different contexts, outside python eco-system anywhere command tools A machine learning model - I\u2019ve already studied this, theory (numpy) frameworks (tensorflow). I\u2019m happy see it\u2019s\u00a0included.","category":"Technical/Developer Tools"},{"title":"Managing Large Projects with\u00a0Vim","url":"vim-for-large-projects.html","body":"Vim text editor IDE. free open source, customize it. post most useful plugins features I\u2019ve started year. There\u2019s copy .vimrc the\u00a0end. I\u2019m happy invest effort learning most vim plugins I\u2019m confident I\u2019ll still twenty years from\u00a0now. Filetype plugins - want settings active particular filetypes, .py (python) .txt (text) create file Vim look file opens buffer corresponding file type. Good formatting options length, tab spaces, vim commands You can\u2019t activate plugins these files though. All plugins activated .vimrc usual\u00a0way. - plugin lets runs tests without leaving vim. You run test that\u2019s nearest cursor, tests current buffer. It\u2019s very customizable. wish bit faster, probably improve myself changing some\u00a0settings. - incredible Asyncronous Linting Engine (A.L.E) applies fixers linters various filetypes, want want. Super useful writing tidy code catching mistakes before code is\u00a0run. junegunn/fzf - It took little getting first, now can\u2019t imagine tool (this said vim-related things). Use fzf switch between open buffers, open file, search files filename, search within files project specific\u00a0text. - plugin opens sidebar contains list functions classes methods (tags). You see methods class contains, jump part buffer where tag is\u00a0defined. \" ========== Global ========== set nocompatible \" always put top .vimrc. effects mappings, undo, etc. set encoding=utf-8 \" utf-8 encoding set termguicolors set t_Co=256 \" colors set noerrorbells vb t_vb= \" no error bells, yes screnflash. set linespace=8 set scrolloff=2 \" minimum screen lines above below cursor set shortmess-=S \" show times search result occurs current buffer, index current match set hidden set relativenumber \" Line numbers set splitbelow set splitright \" set tabstop=8 softtabstop=0 expandtab shiftwidth=4 smarttab set undofile \" Maintain undo history between sessions set \" put undo files dir filetype \" enables filetype detection filetype plugin indent \" detection on, plugin on, indent on. To see current status, type: :filetype syntax \" syntax highlighting - try 'syntax on/enable' set noesckeys \" might break stuff, should <ESC> delay smaller set timeoutlen=350 \" timeoutlen mapping delays set ttimeoutlen=10 \" ttimeoutlen key code delays set incsearch ignorecase smartcase hlsearch highlight Search guibg=purple guifg='NONE' highlight Search cterm=none ctermbg=green ctermfg=black highlight CursorColumn guibg=blue guifg=red highlight CursorColumn ctermbg=red ctermfg=blue nnoremap // nnoremap # #`` nnoremap * *`` \" close buffers properly go previous buffer, delete buffer were just in. nnoremap <Leader>bd :bp\\|bd #<CR> inoremap <Leader>bd :bp\\|bd #<CR> \" Spell check set spelllang=en nnoremap <leader>ss :setlocal spell!<CR> nnoremap <leader>sf z=1<CR><CR> \" ========== Set leader local leader \" insert space right, without leaving mode nnoremap \" Flash cursor row (and column) colors set after scheme ======== \" nnoremap <leader>f :call Flash()<CR> \" function! Flash() \" \" set cursorline cursorcolumn \" set cursorline \" redraw \" sleep 110m \" set nocursorline \" endfunction \" Edit/Reload .vimrc file nnoremap <silent> <leader>ve :e $MYVIMRC<CR> nnoremap <silent> <leader>vr :so $MYVIMRC<CR> augroup VimReload autocmd! autocmd BufWritePost $MYVIMRC source $MYVIMRC augroup END \" Yank clipboard vnoremap <C-c> \"+y set \" copy system clipboard \" X11 support set endif endif \" Go NORMAL mode inoremap jk <ESC> \" view working directory nnoremap <leader>pwd :cd %:p:h<CR> \" toggle wrap nnoremap <leader>lw :set nowrap!<CR> \" toggle numbers nnoremap <leader>ln :set \" Insert current datetime nnoremap <leader>dt A ()<ESC>hh \" map w ` nnoremap ` w \" Swap : ; nnoremap ; : nnoremap : ; vnoremap ; : vnoremap : ; \" Navigation & movemement \" save buffer been changed nnoremap ww :update<CR> \" close Vim, there unsaved changes nnoremap qa :qa<CR> \" save changes nnoremap wa :wa<CR> \" close buffer nnoremap qq :bp\\|bd #<CR> nnoremap wq #<CR> \" switch buffers nnoremap <silent> + :bn<CR> nnoremap <silent> _ :bp<CR> \" Split navigations nmap <Leader>h <C-W><C-H> nmap <Leader>j <C-W><C-J> nmap <Leader>k <C-W><C-K> nmap <Leader>l <C-W><C-L> nmap <Leader>ww <C-W><C-W> nmap <Leader>wq <C-W><C-Q> \" split (pane) resize nnoremap <C-k> :resize +2<CR> nnoremap <C-j> :resize -2<CR> nnoremap <C-h> :vertical resize +2<CR> nnoremap <C-l> :vertical resize -2<CR> \" open help vertical split default cabbrev vhelp vert help \" Natural cursor movement over wrapped lines nnoremap j gj nnoremap k gk \" Insert blank lines mode nnoremap <leader>o o<ESC>k nnoremap <leader>O O<ESC>j \"========== PLUGINS ========== call \" numbers text objects Plug \"run shell commands async vim8\" Plug = \" When :python :!python, access packages venv \" \" <tab> Plug \" force quickfix full widtth au FileType qf wincmd J \" testing - languages test runners Plug test#strategy = = 'pytest' = '-x' = \"belowright\" nnoremap <silent> t<LEADER>n nnoremap <silent> t<LEADER>f :TestFile<CR> nnoremap <silent> t<LEADER>s :TestSuite<CR> nnoremap <silent> t<LEADER>l :TestLast<CR> nnoremap <silent> t<LEADER>g :TestVisit<CR> \" toggle quickfix window function! copen 15 setlocal else cclose endif endfunction nnoremap <silent> cc :call \" generates index (or tag) file language objects found source files \" <C-]> jump definition \" <C-O> jump back \" g] see list multiple matches \" <C-t> Plug \" (re)generate tags file bg Plug = ['.json', \" sidebar displays tags current file, ordered their scope Plug nnoremap <F2> nnoremap <F2> \" add python library code tags file, goto def <C-]> pyEnvLib = $VIRTUAL_ENV pyEnvLib .= \" Async linting engine Plug = = \" ALE completion = set = nnoremap <leader>at :ALEToggle<CR> nnoremap <leader>af :ALEFix<CR> nnoremap <silent> <leader>aj :ALENext<cr> nnoremap <silent> <leader>ak \" iSort Plug \" track snippets engine Plug \" Snippets separated engine. Add want them: Plug \" Trigger configuration. Do <tab> \" want :UltiSnipsEdit split window. \" Plug Plug Plug nnoremap <leader>x :YcmCompleter GoTo<CR> \" subcommands add entries Vim's 'jumplist' \" 'CTRL-O' jump back where were before invoking command (and \" 'CTRL-I' jump forward; see ':h jumplist' details) = = = = = = = \" autoclose parens, brackets etc \" Plug \" vim-tmux focus events Plug \" Code folding \" Plug \" match m \" Plug \" adds vertical lines easily show indent levels Plug \" Fugitive Plug \" Marks Plug \" Latex Vimtex Plug g:tex_flavor = 'latex' autocmd Filetype tex set updatetime=1 = 'open -a Preview' = \\'specifier changed to'.\"\\n\". \\'You \\'Missing number, treated zero.'.\"\\n\". \\'There were undefined \\'Citation %.%# \\'Double space found.'.\"\\n\" = 8 \" Rainbow parenthesis blacklist = ['html', 'md', 'wiki'] autocmd BufWritePre * &ft) < | Plug = g:rainbow_conf = { \\'guifgs': ['green', 'magenta1', 'gold', 'red', \\'guis': \\} \" Set scheme. set Plug \" colorscheme colorscheme badwolf = = = \" colorscheme modifications highlight Comment ctermfg=cyan guifg=cyan highlight pythonComment ctermfg=cyan guifg=cyan highlight LineNr ctermfg=cyan guifg=cyan hi nontext term=bold ctermfg=Cyan guifg=#80a0ff gui=bold hi vimLineComment term=bold ctermfg=Cyan guifg=#80a0ff gui=bold \" SpecialKey - :set list toggle visibility EOL, CR, etc hi specialKey term=bold ctermfg=Cyan guifg=#80a0ff gui=bold \" colors flashing cursorline cursorcolumn hi CursorLine cterm=NONE ctermbg=green ctermfg=black guibg=green guifg=black hi CursorColumn cterm=NONE ctermbg=green ctermfg=black guibg=green guifg=black \" query kind syntax color? - wc nnoremap wc :echo \"hi<\" . . '> trans<' . .\"> lo<\" . . \">\"<CR> \" fuzzy file, buffer, tag finder set \" ensure latest version Plug { 'do': { -> fzf#install() } } Plug nnoremap <silent> <Leader>e :Files<CR> nnoremap <silent> <Leader>r :Buffers<CR> nnoremap <silent> <Leader>t :Tags<CR> nnoremap <silent> <Leader>ff :Rg<CR> \" nnoremap <silent> <Leader>ff :Ag<CR> nnoremap <silent> <Leader>la :BLines<CR> nnoremap <silent> <Leader>ll :Lines<CR> nnoremap <silent> <Leader>' :Marks<CR> nnoremap <silent> <Leader>fh :Helptags<CR> nnoremap <silent> <Leader>fs :Snippets<CR> nnoremap <silent> <Leader>fc :Commits<CR> nnoremap <silent> <Leader>fbc :BCommits<CR> nnoremap <silent> <Leader>hh :History<CR> nnoremap <silent> <Leader>h: :History:<CR> nnoremap <silent> <Leader>h/ :History/<CR> \" = --info=inline' \" --files --hidden\" = g:fzf_layout = { 'down': '~50%' } \" = '' = 'right:0%' function! joined_lines = join(a:lines, \"\\n\") len(a:lines) > joined_lines .= \"\\n\" endif @+ = joined_lines endfunction g:fzf_action = { \\ 'ctrl-t': 'tab split', \\ 'ctrl-x': 'split', \\ 'ctrl-v': 'vsplit', \\ 'ctrl-o': \\ } g:fzf_colors = \\ { 'fg': ['fg', 'Normal'], \\ 'bg': ['bg', 'Normal'], \\ 'hl': ['fg', 'Comment'], \\ 'fg+': ['fg', 'CursorLine', 'Normal'], \\ 'bg+': ['bg', 'CursorLine', \\ 'hl+': ['fg', 'Statement'], \\ 'info': ['fg', 'PreProc'], \\ 'prompt': ['fg', \\ 'pointer': ['fg', 'Exception'], \\ 'marker': ['fg', 'Keyword'], \\ 'spinner': ['fg', 'Label'], \\ 'header': ['fg', 'Comment'] } \" grep vim - shows results split window Plug \" session tracking Plug \" pairs handy bracket mapping Plug \" Plug \" repeat commands plugin mappings Plug \" vinegar Plug = 3 \" CSV Plug \" nerdtree Plug nnoremap <Leader>n = \" Automatically delete buffer file just deleted \" - open nerdtree directory given startup argument \" always focus file window after startup \" Status bars Plug Plug = = = \" remove encoding status = = = = = = = = = = = \" comments Plug = = = 'left' = = \" markdown. tabular required Plug Plug = ['python=py'] = = = = g:tex_conceal = \"\" = = 4 = \" writing prose Plug Plug augroup pencil autocmd! autocmd FileType wiki,md,txt call pencil#init() autocmd FileType wiki,md,txt :PencilSoft augroup END = 'soft' autocmd! User GoyoEnter autocmd! User GoyoLeave \" Ensure :q quit even Goyo active function! s:goyo_enter() b:quitting = = autocmd QuitPre <buffer> b:quitting = cabbrev <buffer> q! = <bar> q! setlocal wrap endfunction \" Quit Vim remaining buffer function! s:goyo_leave() b:quitting && bufnr('$')), == qa! else qa endif endif endfunction autocmd! User GoyoEnter call autocmd! User GoyoLeave call nnoremap <Leader>g :Goyo<CR> \" python linting \" F7 checks flake8 Plug Plug \"Flagging Unnecessary Whitespace highlight BadWhitespace ctermbg=red guibg=darkred Plug = ['latex', 'html'] = = [] \" javaScript Plug = = \" format .JSON files jq cli tool com! JQ %!jq \" HTML/JINJA Plug Plug \" Plug = \"*.html, *.xhtml, *.phtml\" call plug#end()","category":"Technical/Developer Tools"},{"title":"Using RSS","url":"using-rss.html","body":"Updated: Feb 2021 found blog post surprisingly similar thoughts RSS feeds, better presented thought through. post mentions idea \u201cRSS capturing long tail blogs don\u2019t post frequently\u201d 1. idea crystalised why glad I\u2019d started RSS feeds again. readers RSS, authors don\u2019t concern themselves attention. removes pressure author post frequently lets them focus quality over quantity. News feeds ad supported platforms fundamentally different mechanics incentives. With RSS good quality content come me, own schedule. don\u2019t remember look it, authors don\u2019t remind me exist. Google Reader RSS very effective way having good quality information come you. Back 2008, Google Reader subscribe RSS feeds. aspiring photographer back remember being subscribed around 80 blogs. Each day I\u2019d read articles whoever had posted something new, without needing visit their websites remember who I\u2019d subscribed their blog. authors didn\u2019t optimize their output according opaque changing algorithm either - didn\u2019t optimize article length, tags, post frequency, image inclusion linked content. They write wanted to, suspect leads higher quality content. Social Media A few years later Google Reader closed down, presumably RSS didn\u2019t fit Googles advertising model. unaware imagine sent shockwaves through blogging communities probably upended businesses. mostly stopped reading blogs. Facebook growing fast, Instagram felt exciting, content moving onto \u2018platforms\u2019, walled gardens. And kept growing average quality content decreased. Twitter now think. There real diamonds found time, there\u2019s lot mud too. Mostly just mud, occasional diamond outsized benefits. RSS isn\u2019t this. choose contents \u2018news feed\u2019, article much longer Tweet, caption photo, status update. It\u2019s hard write well create interesting useful blog post, makes harder dilute quality entertaining distractions. complete control content see, change whenever want. process designed around me. Reeder5 netNewsWire few weeks, couldn\u2019t sync between laptop phone, bought Reeder 5. It\u2019s got few unusual design patterns, works well features want. I\u2019ve been unsubscribing email newsletters subscribing RSS feed instead. It keeps inbox quieter, feels good \u2018separation concerns\u2019. It makes easier read interesting content without being \u21a9","category":"Non-technical/Learning"},{"title":"Notes on learning\u00a0Django","url":"learning-to-django.html","body":"Table Contents In the\u00a0beginning A personal best moments Adding unique identifier existing Testing\u00a0code In the\u00a0beginning came web development via business analytics. working accountant Excel wasn\u2019t good enough anymore, looked around way get started came across Jupyter Notebooks. Notebooks said kind \u201cgateway drug\u201d programming, think that\u2019s true. They\u2019re easiest fastest way start programming I\u2019ve come\u00a0across. When you\u2019re working notebook, easy get data, wrangle it, show results. But soon create chart summary table inevitably wonder show people easily, publishing results website feels best most general Unfortunately it\u2019s also hardest, begins long series compromises incremental progress. Learn dashboarding API, learn create static sites. But end-goal, ultimate solution, driven web app, saved user preferences, scalable performance, automatically updated data\u00a0sources. A personal When moved Netherlands, wanted personal finances dashboard check weekly expenses. There wasn\u2019t web-app (though there couple apps trying) built own dashboard. Then few friends asked too. They couldn\u2019t just dashboard web app, thought good reason jump It much bigger task anticipated. (And that\u2019s OK.) It took several attempts super frustrating, dabble few weeks, few tutorials, get completely lost tried something myself. I\u2019d get disorientated working across different files trying visualise part model, cycle currently working\u00a0on. came realisea mental load seems large beginning really whole stack technologies abstractions combined (or stacked) together. Many these together same before see any evidence success all. think hardest things Django actually Django. You\u2019ll comfortable classes inheritance. You\u2019ll also comfortable working across multiple files, tools searching across open buffers, files project, same time. You\u2019ll also comfortable version control (Git) command line. Get familiar stack traces\u00a0too. you\u2019re familiar enough these things, them doesn\u2019t feel new, ideally feels familiar comfortable, think you\u2019ll quite quick progress with\u00a0Django. Django uses model. Models django maps Python objects items database (oh yeah, familiar SQL too\u2026), Views where requests processed (also Middleware) turned Responses, combined templates (unless building API). You might notice haven\u2019t mentioned Controller - get information feeling incomplete whilst you\u2019re learning ropes. It\u2019ll become clear soon\u00a0enough. best\u00a0moments \u2018curse knowledge\u2019 states once you\u2019ve learnt something can\u2019t imagine remember it\u2019s know it. Before happens completely, want record \u2018ahah!\u2019 moments For context, stopped working freelance scientist April after few weeks wondering django PostgreSQL python way go (yes is. boring technology), began working full-time become MoneyBar.nl. called \u2018myeuros\u2019 the\u00a0beginning. learning curve felt steep. wanted things \u201cright\u201d first wasn\u2019t building toy, although felt hindsight show mistake terms efficiency, did anyway hunch following compulsions sometimes makes life harder short term better long\u00a0term. best moments usually preceded Adding unique identifier existing pydanny\u2019s template. Honestly, I\u2019d gone through quickstart process googled nouns questions (what Sentry, Celery task que, whitenoise, etc.) already tired. Play few times come back to\u00a0it. Anyway, wanted start project template part kind rnuning box. uses Django Allauth package, awesome, reliable, fully featured\u2026 extremely abstracted. Good luck looking module code understanding youre an\u00a0expert. wanted give user unique ID - UUID signed up. query strings instead usernames incremental keys. hard first time! And turns trivial task, already few users (test) database. Sure reset database start again, experimenting fairly complex. Understanding python model classes (the ORM) maps relations PostgreSQL databse complex, got confused, should try fix changing python Models, editing migrations, working database directly? Getting started After I\u2019d figured started creating models other simpler (transactions bank accounts expect). much simpler faster. remember driving home evening thinking get far success Testing\u00a0code Before long, testing part app hand added changed feature no longer trivial. needed find way automatically creating users checking log access\u00a0views. began working pytest, really found hard wrap head around idea accessing different parts app requests responses accessing class think good code limit knowledge, where know just enough thing \u201cwork\u201d. But approach falters want test wrote. Or least, measure \u201cjust enough\u201d really changes require tests written. You don\u2019t just work, understand why works, write tests assert certain conditions pass others\u00a0fail. feels really satisfying works, proof really grasped bigger picture. There far fewer (relevant) black boxes write tests. But also makes learning slower, least short term. It means might two get comfortable handful abstractions, you\u2019ve already solved problem started with. frustrating, takes discipline slow down, take deeper look solution, just race next\u00a0feature.","category":"Technical/Web"},{"title":"Data Science vs Web Development: Larger Code\u00a0Bases","url":"larger-code-bases.html","body":"Code\u00a0Structure One most immediate basic differences between working scientist web developer files codebase spread across amount code within each\u00a0file. Web applications tend very modular - there lot different things going modern web app generally able modified updated independently other. requirement encourages modular code base architecture code broken down When working science project often well defined quite narrow pipe line. Each stage pipeline well defined inputs and\u00a0outputs. seems consequence making science projects tend towards handful files substantial amount unique (not boilerplate) code. In web development there seems boilerplate, files spread across tree directories, average lines code per file IDE\u00a0features These differences mean code organization tools IDE features play very different roles within industry. In web development really able jump between different files (or buffers) quickly, search text across multiple files. Writing idiomatically becomes important, writing code within discreet testable units becomes essential things don\u2019t break without being\u00a0noticed. In science, linting feels optional, searching text within methods functions outside current module is\u00a0rarer. didn\u2019t appreciate until paused work Data Scientist began building non-trivial web\u00a0apps.","category":"Technical/Developer Tools"},{"title":"TDD: Test Driven\u00a0Development","url":"test-driven-development.html","body":"Test Driven Development mind-bending first grappled it. Last summer building web app Django began break things adding features. soon led lots clicking around different pages test stuff still working made update. soon led me thinking there better way. Which brought me Test Driven Development (TDD). It should just led me writing tests, did. But googling whatever googled got me down TDD rabbit hole rather just \u201cwrite tests\u201d rabbit hole. Write tests code before write code. Write tests bugs you\u2019ve fixed check stay fixed. Write tests kind documentation show stuff supposed doing. Errr\u2026 Django big enough pile abstractions was. Views, ORMs, mixins, serializers\u2026 Trying add factories fixtures took getting to. But eventually made progress, now quite enjoy running coverage reports keep coverage close 100%1. Some things I\u2019ve learnt writing tests: Use PyTest much possible rather other testing libraries - assert statements intuitive Django\u2019s own testing framework, any Python codebase, just Django. It lots extensions seems good getting job done fairly easily. Write tests go. haven\u2019t (yet) reached elevated level writing tests before write code tested, though see why sometimes useful. think writing tests sooner rather later best though, ideally soon you\u2019ve got basic version feature working. Use Coverage show code covered tests, branches edge cases not. But warned, doesn\u2019t tell test useful not, passes methods functions uses. Fixtures great keeping tests fairly DRY. Freezegun great testing anything dates times. Static checkers, Mypy, get attractive proportion codebase complexity size. Which fun all, testing sake doesn\u2019t necessarily stop bad things happening. Its very possible write test covers code you\u2019ve just written without ensuring intended behaviours happen. \u21a9","category":"Technical/Developer Tools"},{"title":"Why Start Talking About Faith In\u00a0Jesus?","url":"faith-in-jesus.html","body":"Start happiness It seems me am much happier Christian weren\u2019t. By \u201cbeing Christian\u201d mean following Jesus - trying best act, think speak he want\u2019s me I\u2019m grateful he did believe he did. believe he died sins now alive, having been miraculously resurrected his father1 (who now father too). It\u2019s just intellectual exercise. believe Jesus alive seem experienced his companionship intervention day-to-day life. unusual, mind boggling, makes things significantly complicated thought he were dead. Nonetheless seems true. It\u2019s see supernatural intervention every day anything, there been various times - too discard - prayers been answered practical ways (I\u2019ll leave intangible now) surprised me given me lot respect risen Jesus doing said he\u2019d bible. Obvious answers There Yemen trying get back room across town, night during storm. lost couldn\u2019t read Arabic understand bus get. So prayed, two buses later got off right stop. Another example, getting haircut Liverpool Street Station London, sitting chair someone took work bag. When came pay, realised laptop wallet had gone. Trying find stolen bag central London feels ridiculous. Even so, spent few hours wondering around alleys parks looking it, resigned myself awkward conversations most next salary replace stolen computer. To surprise, parents-in-law prayed were really confident come back me, seemed super unlikely. A few days later received call office worker Gherkin building - bag under his desk he wanted know I\u2019d collect it. guess I\u2019ll try same mistake twice. other example tend remember happened long after I\u2019d first moved Vienna. feeling lonely isolated wondering earth going find sort healthy sustainable. Try might, wasn\u2019t enjoying things feeling stressed overwhelmed. remember walking steep hill 18th district towards office, repeatedly praying really simple prayer \u2018God, please help, please help, please help..\u2019. It simple couldn\u2019t think anything useful say. Nothing dramatic happened day, even week far remember. But look back, turning point things started getting better instead worse. suppose call last example intangible answer prayer. Maybe is, think anyone whose grappled overwhelming loneliness panic say emotions become too tangible times. Being different emotional state seemed tangible difference just every area life. Eating, productivity work, relationships friends colleagues, etc. beginning why think Jesus alive why think Christianity real living faith. It\u2019s primarily tradition, worldview set rules ideals. Christianity relationship Jesus. He did lots amazing things me very practical relationship him. It\u2019s almost unbelievable premise live life. It implications. And holds scrutiny experiences bear out. Why write this? Despite Jesus\u2019 incredible works their implications, modern Christianity seems really confused ineffective state. Ideas thoughts become mixed cultural christianity, christian politics traditions. These different things, unless distinguish between them words use, going find hard think communicate clearly. suspect negative cycle imprecise thinking leading imprecise articulation, leads further imprecise thinking. Unless talk think thing time, atomically2 necessary, take additional risks reaching wrong conclusions personally, arguing others due rather actual disagreement. We should try create precise vocabulary navigate our Christian lives, think clearly experiences questions have. Imprecise thinking frustrating, conversations less effective there\u2019s increased risk disagreement someone else means. makes harder talk our faith, makes talking less common, creates room apathy, missed opportunities, sadness.And other things also. \u21a9from first principals \u21a9","category":"Non-technical/christianity"},{"title":"API Design\u00a0Principles","url":"api-design.html","body":"Some super brief notes made API\u00a0design: Background It\u2019s art a\u00a0science RESTful State Transfer) API design Alternative API architectures: SOAP (Simple Object Access Protocol) heavier\u00a0style. GraphQL - doesnt overfetch. Graph query language made by\u00a0Facebook. APIs everywhere (not just web APIs). They\u2019re abstraction hides Django model managers API (and also part Django\u2019s ORM), JavaScript API,\u00a0etc. RESTful\u00a0APIs Web APIs (all REST APIs?) expose databases to\u00a0clients A rest api URL route (endpoint) returns JSON XML. POST, GET, PUT, PATCH, DELETE, corresponds Create, Read, Update/Modify, Delete (HTTP methods correspond CRUD\u00a0methods) HTTP METHODS: PUT (create update) idempotent, POST idempotent (keep PATCH - partial\u00a0update GET, HEAD, OPTIONS TRACE methods idempotent cos designed DELETE HEAD - almost identical GET, without any body. Good checking request return, i.e. Before downloading large amount of\u00a0data, OPTIONS - returns describing other methods operations server supports given URL. More loosely defined other\u00a0verbs. Use HTTP verbs requests Use sensible resource names. Naming things hard, think bit before starting. Use identifiers URLs, query string. Good: /users/12345 Poor: Use hierarchical structure URL imply structure API. Design (names structure things) user/client, database. Resource names should nouns not\u00a0verbs Use plurals consistently, collection verbiage. Good: customers/123 Use camel case snake Short better long, be\u00a0clear Spend design before writing\u00a0code Use HTTP response codes Prefer JSON over XML. (Hotline does HTML..) XML requires schemas validation namespaces. Don\u2019t support complexity beginning (or ever) unless required. required, XML similar JSON as\u00a0possible. Put links HTTP link header, JSON representation of\u00a0this. Use HTTP location header contain link resource creation, GET pagination, first, last, next,\u00a0prev. Connectedness - links response link useful resources. At minimum, link show received, or\u00a0posted. Idempotence - clients making same repeated requests create same result server side. I.e. making repeated requests same result making similar request, server side. On client side, response code may change, of\u00a0course.","category":"Technical/Developer Tools"},{"title":"Principles Of Object Orientated\u00a0Programming","url":"principles-of-oop.html","body":"recently interviewed lead developer role Lab Digital1 thought sensible review fundamental aspects Object Orientated Programming (OOP). You might think that\u2019s unusual way prepare interview, you\u2019d right. Nothing close these notes arose during interview, find stuff interesting. I\u2019m motivated enough study it, think that\u2019s good enough reason itself, without specific reason. These brief notes. Object Orientated Programming four key aspects: Encapsulation (Hiding information) Abstraction (Hiding Inheritance Polymorphism 1. Encapsulation Each object keeps state private, inside class. Instance kept private accessor methods made public. Other objects don\u2019t direct access state. They call list public functions (methods). object manages own state via methods, no other class touch unless explicitly (not default) allowed. Private variables. Public methods. You define classes within classes, functions within functions. 2. Abstraction A natural extension encapsulation A concept idea associated any particular instance. Expresses intent class, rather specific Programs often extremely large separate objects communicate other lot. makes maintaining large programs difficult, abstraction tries solve this. Applying abstraction means object should expose high-level mechanism it. mechanism should hide internal implementation details. It should reveal operations relevant other objects. mechanism should easy should rarely change over time. Implementation changes \u2014 example, software update \u2014 rarely affect abstraction use. e.g. coffee machine. It does lot stuff makes quirky noises under hood. But put coffee press button. 3. Inheritance In OOP, objects often similar, sharing similar logic. But 100% same. Create (child) class deriving another (parent) class. way, form hierarchy. child class reuses fields methods parent class (common part) implement own unique part method attribute overloading. 4. Polymorphism Gives way class exactly parent there\u2019s no confusion mixing types. But child class keeps own methods are. typically happens defining (parent) interface reused. It outlines bunch common methods. Then, child class implements own version these methods. Any collection (such list) method expects instance parent (where common methods outlined), language takes care evaluating right implementation common method \u2014 regardless child passed. I\u2019d familiar following features them without referring notes: Getters setters. Instance methods compared class methods. Inheritance, mixins, decorators. \u201cmagic\u201d within Django source code requires mypy extensions order static checking correctly. Unfortunately, didn\u2019t get job. They wanted senior Python developer experience Infrastructure As Code, also working agency. Can\u2019t win them all. \u21a9","category":"Technical/Developer Tools"},{"title":"Optimizing The Performance Of This\u00a0Blog","url":"site-performance.html","body":"I\u2019m coming end redesigning site. Now changes been made fun (and good practice) optimize site loads quickly optimized SEO Lighthouse utility built Chrome runs technical audit webpage assesses wide range features. It also provides details improve the\u00a0page. My site hosted Github Pages accessed via Cloudflare, gives me lot performance gains including minified HTML CSS, caching, super fast server I\u2019m Github Pages Cloudflare free think amazing get benefits these services without needed pay anything. someone knows where look teach themselves free resources, read anyone anywhere world. It\u2019s\u00a0amazing. Below lighthouse results blog\u2019s index page recent\u00a0post.","category":"Technical/Web"},{"title":"Unix: Utilities To Analyse And Update Multiple Text\u00a0Files","url":"using-unix-utilities-to-analyse-and-update-multiple-files.html","body":"As part redesign blog wanted article\u2019s category meaningful. Previously, simply picked handful categories assigned single category post. method becomes limiting article relevant Also, nested categories seems good way grouping similar content allowing nuanced filtering of\u00a0interests. As considered update categories existing articles, realised good opportunity practice analyzing updating text files Here reviewed updated categories Pelican generate static files site. It converts markdown HTML. Metadata article set beginning file, title set typing Title: ... similarly category set typing Category: ... own\u00a0line. To locate, analyse update existing categories, therefore find markdown files row begins Category: grep -h \u2018Category:\u2019 **/*.md - prints search\u00a0result. grep -h \u2018Category:\u2019 **/*.md | sort - prints sorts search\u00a0result. grep -h \u2018Category:\u2019 **/*.md | sort | uniq -c prints sorts search result, counts occurrences unique result there\u00a0are. had repeat results though rows had white space end, order these same, needed remove grep -h 'Category:' **/*.md | sed | sort | uniq -c gave me 6 Category: Category:Data 16 15 15 8 Category:Tools Category repeated isn\u2019t\u00a0needed: grep -h 'Category:' **/*.md | sed | sort | uniq -c | sort | sed gives me following output, is\u00a0acceptable: Data Engineering Front-end 6 8 Tools 15 General 15 Startups 16 New\u00a0Categories next stage begin updating these categories new, nested categories. I\u2019ve decided try splitting categories technical imagine splitting Technical > Data even future, perhaps having Data Analytics, Data Science, Data Engineering Technical Data Web Cryptocurrency Not technical Family Self Career cd directory containing markdown files, change articles Category: Tools Category: Tools I\u00a0did: grep -l 'Category: Tools' *.md | xargs sed -i 's/Category: Tools/g want see list files containing Category: General: grep -H 'Category: General' *.md want see just file names,\u00a0then: grep -l 'Category: General' *.md","category":"Technical/Developer Tools"},{"title":"A New Blog\u00a0Design","url":"a-new-blog-design.html","body":"blog design! Out old, well-written HTML, improved CSS framework, maintainable code, dark mode, articles website first ever project HTML CSS, codebase original blog terrible. It poorly written hard maintain. remember first building trying figure <div> <span> really\u00a0was. At times felt little monkey randomly bashing keys, hitting save refreshing browser tab. felt guilty spending any non-essential away wife daughter. wondered any benefits actually materialize outweigh costs rushing home take care new-born relieve tired stressed\u00a0mum. It took awhile, eventually blog became most effective force multiplier I\u2019ve ever\u00a0used. As I\u2019ve learnt web development, JAM stack become increasingly intuitive familiar. A side effect became comfortable \u201cgood\u201d dev work, working blog\u2019s old code base became increasingly uncomfortable. wanted update blog easy fun again. want able play quickly wasn\u2019t aiming radical re-design, focus text I\u2019m exploring any on-trend design choices. think original design choices held well. want design work years, templates code easy intuitive read, design elements easier work\u00a0with. hope I\u2019ll writing here regularly over next few months. It\u2019s been busy year there lots write\u00a0about!","category":"Technical/Web"},{"title":"Product-Led\u00a0Growth","url":"product-led-growth.html","body":"Part 1: Design your\u00a0strategy Chapter 1: Why product-led growth Product-Led Growth go-to-market (GTM) strategy relies product vehicle acquire, activate Product-Led Growth (PLG) means every team influences product: Marketing - our products generate Sales - product qualify our prospects for\u00a0us? Customer Success - create product helps customers become successful beyond our\u00a0dreams? By having every team focussed product, create culture built around enduring customer\u00a0value By leading product throughout org, PL companies get shorter sales\u00a0cycles lower Customer Acquisition Costs\u00a0(CACs) higher Revenue Per Employee (RPE) A GTM strategy action plan specifies company reach target customers achieve In order select GTM, first understand: ideal\u00a0customer Knowing these elements help choose correct GTM acquire, retain grow customer base most Sales-Led Profit Centers: Sales, Marketing, Cost Centers: Advantages: Annual Contract Value (ACV) very\u00a0high Enterprise first solutions very complex therefore high-touch sales\u00a0model Total Addressable Market (TAM) very small, market super niche, quite easily talk almost market participants. (PLG built large\u00a0TAMs) It\u2019s great categories product where education required, change people approach problem. takes turn requires understand customers pain points, objections, core problems. jump quickly PLG GTM strategy risk high church rate haven\u2019t understood educated customers well\u00a0enough. Disadvantages: Sales cycles very\u00a0long Life Time Value (LTV) high enough recoup investment CAC. often requires charging customer premium. premium price isn\u2019t product amazing, valuable customer, customer acquisition model Sales-Led GTM, watch competitors who sell efficiently, efficient Customer Acquisition Model. They steal market share offering same product lower\u00a0price. Customer Acquisition methods super leaky. Most leads (MQLs) never result closed deal, partly because: encourages markets gate content order hit their MQL\u00a0goals focusses content consumption leading indicator intent. (but reading white-paper brochure doesn\u2019t mean I\u2019m going buy the\u00a0thing). entire process rewards creating friction buying\u00a0process Consequently, there often disconnect between marketing and\u00a0sales Product-Led Switching Sales-Led GTM Product-Led GTM creates defensive\u00a0moat A product led marketing team asks \u201cHow product qualify our prospects for\u00a0us?\u201d A product led customer success team asks \u201cHow create product helps customers successful without our\u00a0help?\u201d A product-led engineering team asks \u201cHow create product Growth much faster, because: fewer resources to\u00a0scale, top customer funnel much\u00a0wider. CAC much\u00a0lower Higher RPE (revenue per\u00a0employee) User experience is\u00a0better Chapter - Free, Freemium or\u00a0Demo Use MOAT framework pick right GTM\u00a0strategy: Market Strategy - Dominant? Ocean Conditions - Blue or\u00a0Red? Audience - Do top-down bottom-up Time Value - How much customer experience the\u00a0value? Dominant - Do better competition charge lower\u00a0price Is TAM big\u00a0enough? Does product solve specific job significantly better lower cost anyone else the\u00a0market? Can user realize significant ongoing quickly little no\u00a0help? Do want undisputed market\u00a0leader? Differentiated - Pick win fight against industry giant Main defense against giant Focus Do specific job better competition charge Free trials demos work well\u00a0here. Because specialized, combining freemium quick time-to-value is\u00a0difficult Main competitive advantage solve Does market Is TAM big\u00a0enough? ACV high\u00a0enough? Could prospects experience Magic Moment during free\u00a0trial? Disruptive - Charge less inferior product (e.g. Canva, Google docs) Build simpler product solves specific pain point, simpler, faster, charge less, appropriate over-served It\u2019s Costs be\u00a0low Product easy to\u00a0use Is TAM large\u00a0enough? Can on-boarding Freemium model\u00a0thrives Chapter 3 - Red-Ocean Red-ocean companies try outperform their rivals order grab larger share existing market. As market gets crowded, opportunity profit growth reduces. Products become commodities. Cut-throat competition turns waters\u00a0red. Blue-ocean companies access untapped market space create demand. They opportunity highly profitable growth. Competition irrelevant. Create capture new\u00a0demand. Some markets red-ocean, particular niche within blue\u00a0ocean. Blue Oceans require educating customer create demand. high-touch, often PL GTM strategy isn\u2019t going work. It needs sales-led order educate customer enough. But Time-To-Value (TTV) short PLG be\u00a0great. Red Oceans big wide funnels order compete, PL GTM strategies work great. They\u2019re defensible, keep costs low sales cycles\u00a0short. Chapter 4 - Top-Down Bottom-Up PLG works for\u00a0bottom-up. High touch sales-led strategies work Top-Down enterprise sales strategies, where product super complex sales cyccle very\u00a0long. Top-Down (Sales team High ACV Lower customer\u00a0churn Poor High CAC Long sales\u00a0cycles Free Trial Bottom-Up (Product Low CAC Predictable sales\u00a0figures Scalable\u00a0fast Small contracts\u00a0only upfront investment non-paying customers Freemium Free-Trial Chapter 5 How much until deliver promise to\u00a0prospects? How much until product sells\u00a0itself? PL GTM strategies require Rank uses across dimensions group 4 quadrants. dimensions Ability (low - high) Motivation (low - high) Low Motivation - Low Ability = High Motivation - Low Ability =\u00a0Rookie Low Motivation - High Ability =\u00a0Veteran High Motivation - High Ability =\u00a0Spoiled Figure top two quadrants. Unless users Spoiled, Questions: How motivated your\u00a0users? Is product easy target audience to\u00a0use? Can users experience core (magic moment?) Part - Build Chapter 7 - Build A positive feedback\u00a0loop: Understand your\u00a0value Communicate\u00a0it Deliver your\u00a0promise Repeat Chapter 8 - Understand your\u00a0value you\u2019re selling live-chat software, you\u2019re really selling live-chat software, selling better way You selling outcome, result, the\u00a0why. Pain makes us want change avoid prevent Pain There three reasons why people buy a\u00a0product: Functional Outcome - core task needs get\u00a0done. Emotional Outcome - customer wants feel avoid feeling result Social Outcome - customer wants perceived others your\u00a0product. In every software, there usage patterns point towards core outcomes most important to\u00a0customers. One biggest differences between sales-led product-led companies SL companies monitor usage patters see users accomplishing meaningful outcomes. These outcomes referred value-metrics. A value-metric way measure exchange product. They linchpin successful execution product-led GTM strategy aligning revenue model directly customer acquisition model. Because metrics play vital role price product, set monitoring, build your\u00a0team. Value metrics could\u00a0be: Vimeo, videos uploaded the\u00a0user. Slack, messages sent the\u00a0user PayPal, amount revenue generated There functional outcome based metrics. Functional metrics \u201cper user\u201d \u201cper 100 videos\u201d. Pricing scales around functions usage. Outcome based metrics charge based outcome, e.g. views video received, much money customer made payment Many SaaS companies rely feature way justify higher prices, produces higher\u00a0churn. Value metrics outperform feature upto 75% less\u00a0churn\u2026 Outcome based metrics reduce church additional A good metric easy customer understand. They immediately understand they\u2019re paying where fit structure. you\u2019re established market, makes senses look A good metric aligned customer receives through product. Consider low-level components high-level outcome. E.g. low level actions necessary get end result? Sending lots messages? Meeting lots people? Finding lots of\u00a0things? A good metric grows customers usage valuable outcome. customers get incredible product, charge them product worth it. Also, aren\u2019t getting much product, charge them\u00a0less. Don\u2019t user based pricing want get lots users - conflict of\u00a0interests. you\u2019re small, try different pricing strategies iterate to\u00a0success. Ask\u00a0yourself: What best customers\u00a0do? What best customers not\u00a0do? What features did best customers try first What similarities along best customers led to\u00a0success? For churned customers, were differences between them best customers? Were ideal audience? Why did church? What did good","tag":"[, ]","category":"Non-technical/Learning"},{"title":"The Mom\u00a0Test","url":"mom-test.html","body":"It\u2019s called Mom Test leads questions even mom couldn\u2019t lie you\u00a0about Overview: Ask good\u00a0questions Avoid bad\u00a0data Keep it\u00a0casual Push commitment Frame meeting\u00a0well Focus right, tight, Prep well, take good notes, review your\u00a0notes. Chapter - Opinions worthless, want objective facts happened the\u00a0past Find people care idea never mentioning\u00a0it. Forcing yourself mention idea force ask Make sure questions pass mom test: Talk their lives, idea Ask specifics the\u00a0past, hypotheticals Spend most listening, not\u00a0talking Rule thumb: Anything involving future overly optimistic\u00a0lie Chapter - Avoid bad - Compliments, Fluff, You aren\u2019t allowed tell them their problem is, aren\u2019t allowed tell to\u00a0build. Chapter 3 - Ask You should terrified least questions ask Search scary questions you\u2019ve been avoiding. What\u2019s worst thing prospect say? What\u2019s scariest question could\u00a0ask? A good way find scary questions imagine company failed ask\u00a0why. get unexpected answer questions doesn\u2019t any effect you\u2019re going do, really worth asking\u00a0it? General advice hard things including asking hard questions - imagine were delegating task, tel person do? That\u2019s\u00a0you. You ask about\u00a0money. Love bad news - find idea fundamentally flawed you\u2019ve just saved tonne energy money. Move on. It\u2019s getting closer the\u00a0truth. Bad news isn\u2019t result opinion. No knows idea work, market knows. Opinions don\u2019t\u00a0count. A lukewarm response idea great conversation, realise idea isn\u2019t great idea. Lukewarm means don\u2019t care enough buy first (worst) version before it\u2019s\u00a0ready. Look before zoom. Don\u2019t focus details too soon, understand big picture\u00a0first. You product risk customer risk: Product risk - build grow\u00a0it? Customer risk - there big enough group people who going buy\u00a0it? Pre-plan list 3 most important questions (including scary one) before every meeting conversation. Be ready these. They should change week week. As get good quality answers existing questions bring new\u00a0questions. Chapter 4 - Keep casual, Structure: Problem -> Solution ->\u00a0Sales Normally 3 meetings client order big sale. lets stage really well without blurring data: Identify Explain your\u00a0solution Sell the\u00a0solution Identifying problem doesn\u2019t meeting, keep casual get honest feedback much faster. It works better a\u00a0chat. It take 5 minutes (max) identify problem exists is\u00a0important Give little info possible idea whilst still nudging Chapter 5 - currencies conversation - Time, In early stage sales, goal learning. Money a\u00a0side-effect. someone willing risk reputation, spend money idea, believe Hearing compliment still useful - means they\u2019re trying get rid of\u00a0you bad meeting, push commitment kind. Ask them spend time, reputation money you\u2019ll see really\u00a0think. aren\u2019t excited (not just interested, pain excited solution) find ASAP. It\u2019s still good meeting discover\u00a0this. A lead isn\u2019t real lead until you\u2019ve given them concrete chance reject\u00a0you. Ask learning questions Mom Test, confirm selling\u00a0it. You crazy customers: They painful They know painful They money pay solve\u00a0it They already their own bad solution terrible problem, yours clearly\u00a0better A crazy customer doesn\u2019t say \u201cyeah that\u2019s great, I\u2019m really interested, me know ready\u201d. They say \u201cAHHH THIS IS THE WORST PART OF MY LIFE AND WILL PAY YOU RIGHT NOW TO FIX IT!\u201d A crazy customer front money prototype made of\u00a0duct-tape A crazy customer person reading blog, searching workarounds, haven\u2019t spent loads marketing Keep crazy customer close - they\u2019ll stick times are\u00a0tough. Chapter 6 - Finding eep having conversations until stop hearing new\u00a0stuff it\u2019s topic both care about, find excuse. You\u2019ll both enjoy chat. You don\u2019t mention idea breaks the\u00a0premise. Warm introductions ideal way start conversation. 6 degrees freedom world, find someone who knows someone who Cold calls - Serendipity - prepared, be\u00a0bold Have good excuse -\u00a0hustle Landing pages googling problems brings them to\u00a0you. Organise event - bring businesses together event. You\u2019ll considered expert cos you\u2019re Become subject matter\u00a0expert Speaking teaching engagements - get strong opinions, you\u2019ll be\u00a0respected. Vision -> Framing -> Weakness -> Pedestal ->\u00a0Ask Chapter 7 - Choosing you\u00a0customers Startups don\u2019t starve, drown. In options, choices, ideas. You Choose good customer segment, focus it, don\u2019t In beginning: Google - PhD\u00a0students PayPal -\u00a0eBay Evernote - Moms recipes,\u00a0etc It look obvious hindsight, probably obvious before you\u2019ve figured out\u00a0though. can\u2019t get consistent answer question, maybe you\u2019re speaking aren\u2019t finding consistent problems goals don\u2019t specific enough customer segment Within group, person want the\u00a0most? Would everyone within group want buy/use it? Or only\u00a0some? Why does subset want\u00a0it? Does everyone group What other motivations are\u00a0there? Who else (outside group) Go Who-Where pairs segments. \u201cFinance professionals who You want customers who reachable, profitable, Good segments usually \u201cwho-where\u201d pairs. don\u2019t know where find customers, keep slicing until do. Make sure segment reachable, profitable, Chapter 8 - Getting most conversations prepping and\u00a0reviewing Prepare well Have 3 big questions ready, including scary\u00a0ones Know who speaking\u00a0to Know commitment next-steps want push\u00a0for Spend hour writing down best guesses think say, care want. focussed segment, you\u2019ll Whilst prepping, come across question answered internet, the\u00a0internet. Take good notes Ask record the\u00a0audio Record emotions well words. Verbatim alone isn\u2019t always accurate 6 months\u00a0later Use shorthand follow up, happy, angry, meh,\u00a0etc Pains obstacles lot important someone embarrassed angry they\u2019re talking about\u00a0them. Dig big emotions, find what\u2019s causing them, why big\u00a0deal Review notes Meta - questions went well or\u00a0not? What were answers How better next\u00a0time? What were clear signals? What signals did you\u00a0miss?","category":"Non-technical/Learning"},{"title":"Obviously\u00a0Awesome","url":"obviously-awesome.html","body":"Intro In order better marketing, understand Understand makes Positioning fundamental input every business tactic you\u00a0use fail positioning, fail marketing and\u00a0sales Positioning \u201cconext setting\u201d for\u00a0products Customers able easily understand What product\u00a0does Why is\u00a0special Why matters to\u00a0them prospects can\u2019t figure product does quickly, invent position you. It might hide key strengths misunderstand your\u00a0value. Find people demo product to, ask them describe back you. Do same existing customers. they\u2019re saying same thing Products strong positioning: Find best kind of\u00a0customer Make value\u00a0obvious Sell\u00a0quickly Part\u00a01 Positioning as\u00a0context Without positioning guide us, don\u2019t know understnad a\u00a0product Positioning lets us assumptions who product is\u00a0for features\u00a0are much it\u00a0costs Without paralyzed choice, wouldnt able sense products around\u00a0us. context purpose product perspective often different those the\u00a0prospect Products positioned multiple ways, often best positioning Bad positioning makes harder prospects figure product worth Positioning requires considering: Customers point view - problem/pain does it\u00a0solve ways product best market context Five (plus one) components Competitive Alternatives - didn\u2019t exist, customers instead? Its prospects task product didn\u2019t exist. It excel, pen paper. It nothing, (in case maybe product doesn\u2019t solve real pain\u00a0point.) You probably know lot market, problem, alternative solutions, prospects do. (\u201cDoing nothing\u201d opportunity, red\u00a0flag.) Its important understand customers compare product with, define \u201cbetter\u201d. Is \u201ceasier\u201d pen and\u00a0paper? Customers might never purchased solution yours\u00a0before. Unique Attributes - What alternative not? Could be: Delivery Model (online vs offline, installed on-site vs\u00a0not) Business model (rental vs\u00a0purchase) Specific expertise (data scientist financial back-end web dev\u00a0expertise) Value (and quantifiable objective proof) - What attributes enable customers? unique attributes secret sauce, why someone might care secret\u00a0sauce Fact based, provable, demonstrable, quantifiable, objective. Third party opinions are\u00a0relevant. Target market - Who cares lot value? Focus customers who most likely purchase quickly, wont ask discounts, tell their friends about\u00a0you. You should clearly identify who these are\u00a0and Identity sets them apart other groups customers. Why uniquely likely buy others wouldnt take longer consider a\u00a0purchase Market Category - What context makes obvious ideal customer? Declaring product exists certain market triggers powerful set of\u00a0assumptions these assumptions help you, hinder\u00a0you. When presented product, customers try already know figure product why special. You want them able really quickly and\u00a0easily. Make these assumptions work you, against you. You won\u2019t list every feature, most them assumed context Get right, sales efforts (copy) wont wasted battling those assumptions, instead build off them show secret sauce (Bonus) Relevant Trends - trends product relevant right now? Used carefully, trends show prospoects why should pay attention product right now. It increase urgency, excitement, trend directly relevant, practically Blockchains, AI, ML trends - relevant Each these components relevant the\u00a0others","tag":"[, , , ]","category":"Non-technical/Learning"},{"title":"How I learnt to\u00a0code","url":"How-I-learnt-to-code.html","body":"4 years ago started learning code, really difficult! It\u2019s still difficult, now collection tools perspectives less daunting (more below). Leveling requires abstraction wrap head around, API understand. do\u00a0it. But don\u2019t think needed difficult, now I\u2019m building Code School Meta easier learn to\u00a0code. Learning code been fun, ultimately successful, life changing (hello job security!) beginning sooo slow, super\u00a0tricky. remember feeling imposter, thinking definitely real developer - hadn\u2019t taken any classes computer science. felt knew almost nothing process began Pandas, (the) Python analytics library. Spreadsheets were slowing me down work, bored. found great tutorial Brandon Rhodes. From there found Jupyter Notebooks, found Github pages blog pelican. That led HTML CSS (and also JavaScript, tried very hard avoid long possible). felt monkey bashing keyboard tried HTML elements I\u00a0wanted. Git next, found amazing tutorial help me learn. It made Git seem OK, also helped HTML CSS sense too.\u00a0Bonus! suddenly realized great learning materials crucial going keep momentum keep enjoying thrill seeing computer something hadn\u2019t made do\u00a0before. So now I\u2019m now working Code School: Meta. It\u2019s online community easier teach yourself code - less confusion get started learn next, encouragement, lots high you\u2019d know more, please check sign for\u00a0updates.","category":"Non-technical/Learning"},{"title":"The 1-Page Marketing\u00a0Plan","url":"1-page-marketing-plan.html","body":"Introduction Marketing three\u00a0phases Before (prospect) - get people know During (lead) - get buy first\u00a0time After (customer) - get them trust you, buy regularly, and\u00a0refer new\u00a0customers Marketing strategy, other things tactics Jargon free definition of\u00a0marketing Advertising - circus coming town, paint sign saying \u201cCircus coming town on\u00a0Saturday\u201d Promotion - Put sign back elephant walk into\u00a0town Publicity - Walk elephant through mayors flower beds newspaper write about\u00a0it Public relations - Get mayor laugh about\u00a0it Sales - town people go circus, explain much fun entertainment is, buy tickets, answer their questions, spend lots money food, games,\u00a0shows. Marketing plan made whole thing\u00a0happen","tag":"[]","category":"Non-technical/Learning"},{"title":"Learning to\u00a0market","url":"marketing-101.html","body":"Since April I\u2019ve been able work full solo founder. I\u2019ve challenged myself build something useful enough customers want pay process seeking goal I\u2019ve become much better I\u2019ve been working solo 7 months now, I\u2019ve begun test driven development, I\u2019ve built non-trivial driven web apps Django, I\u2019ve learnt deploy monitor those apps production I\u2019ve made two apps; moneybar.nl pippip.email, I\u2019ve learnt so\u00a0much. I\u2019m realising though, still much learn other spheres. Being great developer deeply meaningful me. It\u2019s literally bucket list item me intend writing code long live. But there no point creating products no knows they\u00a0exist. where marketing positioning comes in. Right now feels know nothing get users, validate idea, position product. These super necessary super\u00a0unknown. On meta level, I\u2019m confronted lost benefits working co-founders, having friends doing similar things. want work faster progress efficiently. part a\u00a0community. Working isolation does advantages, though. I\u2019m self-taught self-directed, figuring contours uncharted territory creating own personal map. In mind, deep almost personal relationship coding abstractions tools I\u2019ve learnt work with. Classes functions, strings floats, literally (to me) their own textures, colors weights think dream about\u00a0them. It feels pick these abstractions were physical objects turn them around examine them. Place them next other compare differences. Run thought experiements. In experience, kind relationship affection simply doesn\u2019t happen taking class following someone elses schedule. It\u2019s satisying feel ownership skill this, it\u2019s primary reasons consider coding similar a\u00a0craft. Having said that, now realise validate product, position it, figure marketing, I\u2019ve stopped writing code, put down tools, I\u2019m going learn marketing. I\u2019ve bought books. Maybe I\u2019ll post reviews here\u00a0later. In no particular order here plan to\u00a0read: 1-Page marketing plan, Allan Dib Obviously Awesome, April\u00a0Dunford Lean Analytics, Hooked, How build habit-forming products, Nir Eyal\u00a0The Mom Test, marketing, Seth\u00a0Godin Product-led growth, Wes\u00a0Bush don\u2019t know I\u2019ve covered 90% distance required 50%. It\u2019s exhausting I\u2019m here journey","tag":"[, ]","category":"Non-technical/Learning"},{"title":"Pippip.Email","url":"pippip.email.html","body":"PipPip 6 weeks ago had idea product whilst reading news\u00a0article. It great writing sending important messages separated, write something long before needed send it, know sending happen right without having think it. useful sending daughter message her 15th birthday, wife our 10th anniversary. also designed check-in mechanism, messages sent disappeared pass\u00a0away. PipPip result - event-driven scheduled email delivery, days to\u00a0decades We\u2019re working validating idea finding right","tag":"[]","category":"Non-technical/Entrepreneurship"},{"title":"Between\u00a0Clients","url":"between-clients.html","body":"At end summer had between engagements work side projects grapple (to me) libraries During August September 2019,\u00a0I: Practiced creating websites Investigated demo\u2019ed - library allows exposing Plotly Dash apps Built personal finance dashboard Plotly Dash began turning web app Django Interviewed role CoinMetrics.io created investigation Created company \u201cAtlas Consulting Internatonal\u201d facilitate life freelance scientist Spent lot working cafe IKEA co-working space wouldn\u2019t me stay late work Introduced myself coworking space suggested work together create best tech-focussed startup hub coworking space Bought our first car. It required lot research I\u00a0expected. Created Texni Data Consultancy Dan Caputo provide strategy Built website Texni Data django deployed Heroku custom domain\u00a0name. Deployed django app Google Cloud Platform App Engine. Created business website represent work freelance scientist made blog subdomain this\u00a0site. Moved blog off github pages onto firebase. Thanks Github several years simple trouble free\u00a0hosting. Experimented storage buckets Google Cloud Platform host static sites serve them over SSL. My conclusion serving static sites storage buckets great - it\u2019s simple, quick cheap (free). But adding SSL proved too difficult. spent too hours trying create loadbalancer work both root domain johnmathews.eu also subdomain In end found firebase. Firebase also quick cheap (free) simple enough Created photo book PhotoBox turned great. It covers last 3.5 years mostly full snapshots our kids selfies with\u00a0Ritsya. Chose primary school daughter go next\u00a0year.","tag":"[]","category":"Non-technical/Career"},{"title":"Analysis of the mean and median value of transactions on 5\u00a0Blockchains","url":"btc-fork-analysis.html","body":"analysis prepared Coin Metrics part their recruitment process. It short demonstration thought process. additional steps required develop useful analysis CoinMetrics Case - evaluate skills abilities multiple\u00a0ways: Importing\u00a0data Wrangling\u00a0data Exploring\u00a0data Analysis Modeling Provide: A written explanation approach the\u00a0problem Present beginning phases implementation coin metrics\u00a0data Of four options made available case study, option 3 was\u00a0chosen Advocating CoinMetric\u2019s data\u00b6Produce quality research potential clients (doesn\u2019t complete) particular focus network\u00a0data Initial ideas\u00b6My first rough ideas\u00a0were: Compare different Bitcoin based chains, (BTC, BCH, LTC, BSV) test influence whales compare their respective (evolving) claims store (SoV) and/or alternative to\u00a0cash. Develop expand research Willy Woo. find his research outstanding. In particular think following metrics merit days\u00a0destroyed hodl\u00a0waves thermo\u00a0cap average\u00a0cap Tracking twitter followers various crypto-twitter thought leaders celebrities test hypothesis \u201can increase follower numbers shows retail investors entering increase price expected\u00a0soon\u201d Thought leaders / crypto celebrities further grouped types coins speak most - smart contracts, DeFi, privacy coins,\u00a0etc. Weibo analysed well Twitter understand Chinese markets, Korean twitter analysed Korean existing side project goal recurrent neural net LSTM architecture predict BTC price movements. app (model, stored data, pipeline, visualization results) run autonomously Google Cloud Platform. Candle consumed CoinAPI.io stored in\u00a0BigQuery. Technical indicators calculated additional factors model. Sentiment analysis news outlets (Bloomberg, FT) added\u00a0later. model written TensorFlow, BigQuery tables names BQ\u2019s date format capabilites. project faster and\u00a0cheaper. Idea seemed sensible option. Ideas 3 4 interesting worth investigating, possible within scope this\u00a0exercise: Testing influence whales\u00b6and \u201cnormal users\u201d BTC 4 BTC forks, discussing results context chain\u2019s claimed technical advantages cases e.g. store alternative to\u00a0cash achieved comparing daily mean USD transaction daily median USD transaction value. done calculating mean-median ratio transaction (MMR). Hypothesis: chain much smaller median transaction size mean transaction size, chain activity dominated regular users making daily transactions, whales moving large amounts currency artificially inflate usage\u00a0metrics. contradict claims blockchain active user base blockchain meeting user needs. We assume\u00a0that: blockchain functioning digital cash, most transactions small. e.g less 100 USD. It should noted 100 USD particularly small amount even western countries due blockchains borderless nature, even futher above noraml \u2018day-to-day\u2019 transaction amount large parts the\u00a0world. Conversely, blockchain relatively little organic users whales (users large holdings) large proportion on-chain activity average transaction sizes much larger day-to-day transaction. An untested guess \u201cwhale threshold\u201d 100,000USD. Where ratio mean median transaction relatively high, environment where mean much higher median value, shows daily total transacted dominated few relatively large transactions, rather small transactions. imply whales dominate blockchain (and likely market behavior) rather members general public Chains:\u00b6The chains analysed here forks BTC. They\u00a0are: BTC BCH BSV LTC DOGE Fields\u00b6using coinmetrics api, following metrics be\u00a0used: sum USD native units transferred divided count transfers (i.e., mean \u201csize\u201d USD transfer) that\u00a0interval. TxTfrValMedUSD median USD transferred per transfer (i.e., median \u201csize\u201d USD transfer) that\u00a0interval. In\u00a0[1]: import HTML function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document </script> <font> analysis made Python. You toggle code visibility clicking <a ''') Out[1]: function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document analysis made Python. You toggle code visibility clicking here. In\u00a0[2]: # import setup import requests import json import pandas pd import go import py import plotly plotly.offline import import = \"all\" import warnings = 'local'}; {font: (typeof require !== 'undefined') { exports, module) { /** * plotly.js v1.48.1 * Copyright 2012-2019, Plotly, Inc. * All rights reserved. * Licensed under MIT license */ function a(o,!0);var c=new Error(\"Cannot find module 0.3s ease 0.3s ease 0.3s ease 0.3s ease 0.3s ease 0s;\",\"X:hover .modebar-btn .modebar-group 0, 0, 0, 0, 0, solid .vertical .vertical .vertical solid solid i){var 0-183 41t-147 114q-4 6-4 13t5 11l76 77q6 5 14 5 9-1 13-7 41-53 110 23t92 61 61 91 22 111-22 111-61 91-92 61-110 23q-55 0-25 11t-11 25v250q0 24 22 33 22 39-8l72-72q60 57 137 88t159 31q87 166-34t137-92 91-137 -1 0-25 10t-11 26v267q0 2t0 2l321 264 321-264q1-1 1-4z m124 0-12 3l-386 2-12 7l-35 41q-4 5-3 13t6 12l401 334q18 15 42 8 5 13t13 5h107q8 -1 386q0 8-5 13t-13 5q-37 5-13t13-5 12 5 5 13q0 23 16 38t38 16q8 13 5t5 13z 42-42 101 42 101 101 42 101-42 42-101z m643 320q0 89-62 152t-152 63-151 151-63 152 63 62 151z m-571 m929 0-50 21t-21 51v714q0 30 21 51t50 21h858q29 -1 251c40 63 63 138 63 218 224-182 406-407 406-224 407-406c80 155 22 218 62l250-250 125 125z m-812 250l0 438 437 0-438-437 0z m62 375l313 0-312-313 -1 350l-187 188 0-125-250 250 125 0-188 187-187-187 125 0-250-250 125-188-188 186-187 125 252 0-250-125 187-188 188 188-125 250 250 0-126 187 -1 787l0-875 875 875-875 0z m687-500l-187 0-187-125 187-188 125 188 187 125 0-187 187 -1 788l0-876 875 876-875 0z m688-500l-500 125 500 -1 850l-187 0-63 0-62 0-188 63 188 187 62z m688 0l-188 0-62 188 0-188 62 188 62-62 0z m-875-938l0 188-63 0-188 0-62 63 187 62-187 0z m875 188l0-188-188 0-62 188 62 62 188-62 0z m-125 188l-1 0-93-94-156 156 156 156 92-93 250-250 0-2 156 94 92 2-250 0-250 93 93 94 0-250 250 0-94 93 156 157 156-157-93-93 250 -1 725l0 0-375-375 375-374 0-1 1125 750-1125 -1 786l0 2-187-188 188-187 937 373-938 0z m0-499l0 1-187-188 188-188 937 -1 m228 m225 m225 -1 5l-17 108v41l-130-65 130-66c0 38 39 0-1 36-14 39-25 0-341 34-353 59 3 60 228 110 228 0-120 293-142 474-142 155 477 22 477 142 50-74 79-163 96z m-374 0-24 65-43 144-43 79 143 19 143 43 19-42 34-98 40v216h87l-132 m167 515h-136v1c16 16 31 34 46 52l84 -1 660c-5 4-9 7-14 11-359 28 58-400c0 118 108 351 249 351 249s-62 27-100 42c88 83 222 183 347 122 16-8 30-17 44-27-2 1-4 2-6 4z m36-329c0 64 229-88 296-62 27-124 14-175-11 157-78 225-208 249-266 8-19 11-31 11-31 5 6 15 11 117-50 198-32-121 80-199 346-199 55-226 155-287z m603 133l-317-139c0 4-4 19-14 7-5 24-15 4c235-287 536-112 536-112l31-22 100 299-4-1z m-298-153c6-4 14-9 24-15 0-17 10-24 -1 450c-83 0-83 67-150 150-150 83 150 67 150 150 83-67 150-150 150z m400 150h-120c-16 0-34 13-39 29l-31 93c-6 15-23 28-40 28h-340c-16 45-100 100-100h800c55 100 45 100 100v450c0 55-45 100-100 100z m-400-550c-138 0-250 112-250 250 138 112 250 250 250 138 250-112 250-250 m365 380c-19 0-35 16-35 35 19 16 35 35 35 19 35-16 35-35 -1 413l-188-125c0 37-17 71-44 94 64 38 107 107 107 187 121-98 219-219 219-121 0-61 25-117 66-156h-115c30 33 49 76 49 125 103-84 187-187 26-107 56-126 125-126h500c69 125 56 125 126l188-126c34 62 28 62 63v375c0 35-28 63-62 63z m-750 0c-69 0-125 56-125 125s56 125 125 125 125-56 m406-1c-87 0-157 70-157 157 86 70 156 157 156s156-70 -1 82v107q0 8-5 13t-13 5h-107q-8 13 5t5 13z m143 375q0 49-31 91t-77 65-95 23q-136 0-207-119-9-14 4-24l74-55q4-4 10-4 9 14 7 30 38 48 51 19 14 48 14 27 13 5t5 13q0 12 27t30 28q18 28 16t25 19 25 27 16 34 7 45z 58-155 156-58 215 58 215 155 156 216 58 215-58 156-156 -1 m500 0h72v500q0 8-6 21t-11 20l-157 156q-5 6-19 12t-22 0-37 16t-16 22 16 38t37 16h465q22 m-214 518v178q0 8-5 13t-13 5h-107q-7 13 5t5 13z 0-38 16t-16 38v750q0 22 16 38t38 16h517q23 -1 538c-36 207-290 336-568 10-57 36-108 76-151-13-66 11-137 68-183 34-28 75-41 114-42l-55-70 5-45 14-11 34-8 45 4 3 5l0 113 140c16 11 31 24 45 40 4 3 6 7 8 11 48-3 100 151 9 278 48 473 255 436 462z m-624-379c-80 14-149 48-197 96 42 42 109 47 156 9 33-26 47-66 41-105z m-187-74c-19 16-33 37-39 60 50-32 109-55 8z m360 8 62-16 128-68 170-73 59-175 54-244-5-9 20-16 40-20 61-28 159 121 317 333 354s407-60 -1 850l0-143 143 143-143 0z m286 0l0-143 143 143-143 0z m285 0l0-143 143 143-143 0z m286 0l0-143 143 143-143 0z 143 143-143 0z m857 0l0-143 143 143-143 0z 143 143-143 0z m857 0l0-143 143 143-143 0z 143 143-143 0z m286 0l0-143 143 143-143 0z m285 0l0-143 143 143-143 0z m286 0l0-143 143 143-143 -1 0-104 47-104 104 57 47 103 104 103 57 103-46 103-103z m-327-39l92 92-92 0z m-185 0l92 92-92 0z m370-186l92 93-92 0z m0-184l92 92-92 -1.5 {fill: #119dff;} .cls-2 {fill: #25fefd;} .cls-3 {fill: strict\";var strict\";var n=i(t,new instanceof _(t,e,r,n){var e)throw argument expected unwanted \"+e.operator+\" n=new t};var e=[];for(var r l(t,e){var c(t,e){return t}function a;var e={};return l=e.name?\": f(e)}var x(e)&&(b=\" \")+\" \"+t.join(\",\\n \")+\" \"+r[1];return r[0]+e+\" \"+t.join(\", \")+\" o+\": \"+s}function p(t){return t}function g(t){return t}function t}function y(t){return 0===t}function x(t){return b(t)&&\"[object _(t){return b(t)&&\"[object w(t){return instanceof t}function T(t){return A(t){return Error(\"Invalid string. Length multiple 4\");var strict\";var strict\";var strict\";var c=0;var r)f=o(r);else 52;return strict\";var i=new e=t|t-1;return strict\";var Error(\"For raw width height should provided instanceof instanceof instanceof instanceof instanceof instanceof safely store 53 array length 26;var e=t,r=0;return 0;for(var t&&t>=0);var t&&t>=0);var e=new e=new a(1);for(var t&&t>=0);var works positive a(0),mod:new i=new a(1),o=new a(0),s=new a(0),l=new i,o=new a(1),s=new v[t];var y;else x;else Error(\"Unknown prime \"+t);e=new _}return works works red works works red f}}}function strict\";var _(t){var w=[\"function k(e,o){var \"+e);var 0,r)};var n=\"for(var M=f[2*x];var S=f[2*x+1];var E=f[2*_];var C=f[2*_+1];var L=2*y;var z=2*b;var O=2*w;var I=2*p;var D=2*g;var P=2*d;for(var R=0;Rt;){var u(t,e,r,n){var l=new EventEmitter memory leak detected. \"+s.length+' listeners added. Use increase t}function 0:return 1:return 2:return 3:return t=new instanceof Error)throw e;var l=new \"error\" event. for(var strict\";var \"'+t+'\" invalid option \"size\"');var e=new e)throw TypeError('The \"string\" argument string. Received u(t)}return t)return encoding: \"+e);var TypeError(\"The first argument string, Buffer, ArrayBuffer, Array, Array-like Object. Received \"+typeof allocate Buffer larger maximum size: bytes\");return 0|t}function t)throw TypeError('The \"string\" argument string, Buffer, ArrayBuffer. Received '+typeof t);var 0;for(var d(t,e,r){var encoding: ... TypeError('The \"target\" argument Buffer Uint8Array. Received '+typeof t);if(void range 0;for(var 0)}var write outside buffer encoding: M(t,e,r){var access beyond buffer argument Buffer should n)throw encoding: a}function B(t){return i}function j(t,e){return instanceof V(t){return strict\";var l(t,e){return e strict\";var o(t,e){return c(m,v,s,f),new i=new null;var l(t,v)};var u(t,e){return strict\";var strict\";var instanceof Uint8Array||t instanceof strict\";var strict\";var strict\";var Error(f+\" map requires nshades least size l(t,e,r){var 0:return 0;case 1:return t[0]-e[0];case 2:return 3:var a;var 4:var t}(o,r)}};var strict\";var strict\";var t)throw Error(\"Font argument Error(\"Cannot parse empty Error(\"Missing required Error(\"Unknown unsupported font token: Error(\"Missing required p(t){var strict\";var Error(\"Unknown keyword t}function g(t){for(var a}return a}return strict\";var e=new a=0;a0)throw Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array args\")}else Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array index\")}else Error(\"cwise: Too arguments pre() Error(\"cwise: Too arguments body() Error(\"cwise: Too arguments post() block\");return strict\";var i(t,e,r){var x=new cwise routine e=new strict\";var e=[\"'use strict'\",\"var function (!(\"+l.join(\" && \")+\")) throw Error('cwise: Arrays same {\"),e.push(\"if (!(\"+c.join(\" && \")+\")) throw Error('cwise: Arrays same r(t){var r;return n}}}var s(t){return l(t,e){var c(t,e){var u(t,e){var _(t,e,r){var T(t,e){var n}function n(n){var d,g=new r;var e=[];for(var r e=[];for(var r e=[];for(var r r(t,e){var r}function n(){}var v(t){var e;return j(t){return V(t){return Error(\"unknown type: r,n,i=new h(){if(r){var o(t){for(var a(t,e){var o(t){return l(t){var t;var t=[];return t=[];return f(t){for(var g(t,e){for(var b(t,e){var _(t){var 0;var w(e),r=new w(r),n=new X=function t(e){function s(e){var i(i){return i(i){var a}return i(i){var i}function a(e){var u(t){return f(e){var u=s[e];return n(t){var +r+\"v\"+ t;var n(t){return t[0]}function i(t){return t[1]}function a(t,e,r){var a=new 0}function s(t){for(var e}var t,e,r=new this;var 1:do{(o=new 2:do{(o=new 3:do{(o=new t=[];return C(t,r,i,a){var e}(e);else{var L(t,e){return z(t,e){return O(t,e){return I(t,e){return D(t,e){return P(t){return R(t){return F(t,e){var B(t,e){var j(t,e){return 0});var Y(t,e){return F(){var v(t,r){var w(t){return _(t)}function k(t){return t[0]}function T(t){return t[1]}function A(){var l(r){var f(){return S(t,e){return E(t){return z(t){function e(e){return L(t(e))}return O(t){var I(){return D(){var O(r())},delete O(n())},delete O(i())},delete O(a())},delete F(t){return B(t){return N(t){var l(){var a=1;a0)for(var kt=function t(e){function r(t){return e?new wt(t,e):new gt(t,0)}return At=function t(e){function r(t){return e?new Tt(t,e):new mt(t,0)}return St=function t(e){function r(t){return e?new Mt(t,e):new xt(t,0)}return Ct(t){return r}function Vt(t,e){return t[e]}function Ut(t){var Ht(t){for(var n}function qt(t){var Gt(t){for(var v}return t=N(U);return a(){var a(r){var y(){var p(t){return m(t){return r};var x(t,e){for(var r e;var e=new L;if(t)for(var c(){var r,n=new i z(){var O(){var d(){var g(){var v(){var re(t){return ne(t){return ie(t){return se(t){return Vt;function ce(t){return fe(t,e,r){var o;if(i)return i=!1,a;var Me(){for(var t}function Se(){for(var Oe(t){return t+\"\"}var n(e){var ir(t){var or(t){for(var b=u&&h;return u(t){var r(r){for(var u}(e)}};var %b %e %X this.s}};var cr=new lr;function ur(t,e,r){var zr(t){var Or(t,e){return Rr(t){var Br(t,e){return d(t,o){var u}}function Jr(t){return Kr(){var r=e;return A(t,a){return o(t,e){return s(t,e){var an(t){var on(t,e){var o(t,e){var c(t){var vn(){var r}function 1,1 1,1 _n(){var t,e;function r(r,n){var kn(){var i(t,e){var Tn(t){var r}function An(t){var x(r,i){var En(t){return t})()}function Cn(e){var A(){return a(t,r,n){var Ln(t){return i(){var b(){return t,e,r;function n(n,i){var r(e,r){var Wn(t,e){var $n;function Xn(t,e){var n(t);function _i(t,e){var n;var s;var wi(t,e){var _i(r,e);var Ti(t,e){return Mi(t){var s,l=1/0;return function n}function $i(t,e){var 1;var n(t,n){var function t(e,r,n,i){var n}function Ha(t){return qa(t,e){return Ga(t,e){return c}function o(t){var a(a,o){var f=function t(e){var t(e){var u(t,e){for(var d(t,e,r,i){var l(t){return function s(t){return l(t){return jo(t){var s(a){var Ho(t){return qo(t){for(var c=2;cAt)+\",1 \"+e}function 0,0 \"+n}return n(n,i){var \"+l[2]+\" \"+l[3]}return function(){var 0,\"+e+\" \"+e+\",\"+e+\" u[n]:delete v(){var if(_){var L(){var e=0;es*l){var a}function o(t){for(var r,n;for(r=new t;e||(e=t);var e}function s(t){var l(t,e,r,n){var c(t,e,r){var n=t;do{var n}function l=t;do{for(var f(t,e){return r}(t,e)){var v(t,e){return b(t,e){return e){e=0;for(var strict\";var strict\";var strict\";var strict\";var strict\";var t&&(t instanceof strict\";var strict\";var instanceof n))throw requires strict\";var strict\";var strict\";var instanceof n))throw requires specify first t[0][0]){var Error(\"source length \"+c+\" does match destination length defined\");var \")+\"px o(t){return s(t,e){return t=[];return t=[];return 1:return function t(e,r){var 2:return function function this.tree;var e=new Error(\"Can't update empty node!\");var r=new U=v,H=w,A=0;A HALF_PI) && (b 2) ? + delta, option) : // option 3-n: round directions\\n (option == 2) ? + delta, hv_ratio) : // horizontal vertical\\n (option == 1) ? rawAngle + delta : // free angle, flip align direction axis\\n (option == 0) ? : // free angle, stay upwards\\n (option ==-1) ? 0.0 : // useful backward compatibility, texts remains horizontal\\n rawAngle; // otherwise back raw input isAxisTitle = (axis.x == 0.0) &&\\n (axis.y == 0.0) &&\\n (axis.z == 0.0);\\n\\nvoid main() {\\n //Compute world offset\\n axisDistance = position.z;\\n dataPosition = axisDistance * axis + offset;\\n\\n beta = angle; // i.e. user defined attributes tick\\n\\n axisAngle;\\n clipAngle;\\n flip;\\n\\n (enableAlign) {\\n axisAngle = (isAxisTitle) ? HALF_PI :\\n dataPosition + axis);\\n clipAngle = dataPosition + alignDir);\\n\\n axisAngle += 0.0) ? 1.0 : 0.0;\\n\\n beta += flip * PI);\\n }\\n\\n //Compute plane offset\\n planeCoord = position.xy * mat2 planeXform = scale * mat2(\\n cos(beta), sin(beta),\\n -sin(beta), cos(beta)\\n );\\n\\n viewOffset = 2.0 * planeXform * planeCoord / //Compute clip position\\n clipPosition = //Apply text offset clip coordinates\\n clipPosition += 0.0);\\n\\n //Done\\n gl_Position = GLSLIFY 1\\n\\nuniform color;\\nvoid main() {\\n gl_FragColor = GLSLIFY 1\\n\\nattribute model, view, main() {\\n\\n signAxis = sign(bounds[1] - realNormal = signAxis * normal;\\n\\n enable) > 0.0) {\\n minRange = min(bounds[0], bounds[1]);\\n maxRange = max(bounds[0], bounds[1]);\\n nPosition = mix(minRange, maxRange, 0.5 * (position + 1.0));\\n gl_Position = projection * view * model * 1.0);\\n } else {\\n gl_Position = }\\n\\n colorChannel = GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = colorChannel.x * colors[0] +\\n colorChannel.y * colors[1] +\\n colorChannel.z * p=new o=[];function vectorizing text:\"'+t+'\" s;var r=0;rr)throw resizing buffer, specify u(t,e){for(var Cannot specify offset resizing r-1;return n.create();var null;var GLSLIFY 1\\n\\nvec3 v) {\\n // Return up-vector only-z vector.\\n // Return ax + + cz = 0, point lies plane v isn't (0,0,0).\\n // From above if-statement ||a|| > U ||b|| > 0.\\n // Assign z = 0, x = -b, y = a:\\n // a*-b + b*a + c*0 = -ba + ba + = 0\\n (v.x*v.x > v.z*v.z || v.y*v.y > v.z*v.z) {\\n v.x, 0.0));\\n } else {\\n v.z, -v.y));\\n }\\n}\\n\\n// Calculate cone vertex given index.\\n//\\n// returned vertex cone top origin height 1.0,\\n// pointing direction vector Each cone made top vertex, center base vertex base perimeter vertices.\\n// These vertices triangles cone following:\\n// segment + top vertex\\n// segment + perimeter vertex a+1\\n// segment + perimeter vertex a\\n// segment + 3 center base vertex\\n// segment + 4 perimeter vertex a\\n// segment + 5 perimeter vertex a+1\\n// Where segment radial segment * 6 angle radial segment.\\n// To go index segment, floor(index / 6)\\n// To go segment angle, 2*pi * To go index segment index, index - d, rawIndex, coneOffset, normal) {\\n\\n const segmentCount = 8.0;\\n\\n index = rawIndex - floor(rawIndex /\\n (segmentCount * 6.0)) *\\n (segmentCount * 6.0);\\n\\n segment = floor(0.001 + index/6.0);\\n segmentIndex = index - = (segmentIndex > 2.99 && segmentIndex 0.99 && segmentIndex 4.99 && segmentIndex max(a, b)) || \\n (p U ||b|| > 0.\\n // Assign z = 0, x = -b, y = a:\\n // a*-b + b*a + c*0 = -ba + ba + = 0\\n (v.x*v.x > v.z*v.z || v.y*v.y > v.z*v.z) {\\n v.x, 0.0));\\n } else {\\n v.z, -v.y));\\n }\\n}\\n\\n// Calculate cone vertex given index.\\n//\\n// returned vertex cone top origin height 1.0,\\n// pointing direction vector Each cone made top vertex, center base vertex base perimeter vertices.\\n// These vertices triangles cone following:\\n// segment + top vertex\\n// segment + perimeter vertex a+1\\n// segment + perimeter vertex a\\n// segment + 3 center base vertex\\n// segment + 4 perimeter vertex a\\n// segment + 5 perimeter vertex a+1\\n// Where segment radial segment * 6 angle radial segment.\\n// To go index segment, floor(index / 6)\\n// To go segment angle, 2*pi * To go index segment index, index - d, rawIndex, coneOffset, normal) {\\n\\n const segmentCount = 8.0;\\n\\n index = rawIndex - floor(rawIndex /\\n (segmentCount * 6.0)) *\\n (segmentCount * 6.0);\\n\\n segment = floor(0.001 + index/6.0);\\n segmentIndex = index - = (segmentIndex > 2.99 && segmentIndex 0.99 && segmentIndex 4.99 && segmentIndex max(a, b)) || \\n (p strict\";var GLSLIFY 1\\n\\nattribute position, model, view, main() {\\n worldPosition = model * vec4(position, 1.0);\\n worldPosition = (worldPosition / + vec4(capSize * offset, 0.0);\\n gl_Position = projection * view * fragColor = color;\\n fragPosition = GLSLIFY 1\\n\\nbool a, b, p) {\\n ((p > max(a, b)) || \\n (p u||ru)throw Error(\"gl-fbo: Parameters too large FBO\");var Error(\"gl-fbo: Multiple draw buffer extension Error(\"gl-fbo: Context does support \"+f+\" draw buffers\")}}var Error(\"gl-fbo: Context does support floating point g=!0;\"depth\"in i:throw Error(\"gl-fbo: Framebuffer a:throw Error(\"gl-fbo: Framebuffer incomplete o:throw Error(\"gl-fbo: Framebuffer incomplete s:throw Error(\"gl-fbo: Framebuffer incomplete missing Error(\"gl-fbo: Framebuffer failed unspecified null;var Error(\"gl-fbo: Can't resize FBO, invalid null;var max(a, b)) || \\n (p FLOAT_MAX) {\\n vec4(127.0, 128.0, 0.0, 0.0) / 255.0;\\n } else if(v max(a, b)) || \\n (p 0){for(var max(a, b)) || \\n (p max(a, b)) || \\n (p max(a, b)) || \\n (p 0.25) {\\n discard;\\n }\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nbool a, b, p) {\\n ((p > max(a, b)) || \\n (p max(a, b)) || \\n (p t&&r>0){var 1}function M(t){var S(t){var E(t){var C(t){var null;for(var function(){var u=0;u=0){var GLSLIFY 1\\nattribute uv;\\nvoid main() {\\n uv = position;\\n gl_Position = vec4(position, 0, GLSLIFY 1\\n\\nuniform sampler2D uv;\\n\\nvoid main() {\\n accum = 0.5 * (uv + 1.0));\\n gl_FragColor = strict\";var m(t){var null}return Error(\"webgl q(){for(var c=0;c 1.0) {\\n discard;\\n }\\n baseColor = color, step(radius, gl_FragColor = * baseColor.a, GLSLIFY 1\\n\\nattribute mat3 main() {\\n hgPosition = matrix * vec3(position, 1);\\n gl_Position = 0, gl_PointSize = pointSize;\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / strict\";var e;function r(e,r){return e instanceof instanceof null;var strict\";var a)return a[t];var max(a, b)) || \\n (p max(a, b)) || \\n (p max(a, b)) || \\n (p max(a, b)) || \\n (p max(a, b)) || \\n (p 1?1:t}function O(t,e,r,i){var n=0;n0){var c(t,r,a)};var S=new t=0;t=0){var n(\"\",\"Invalid attribute \"+f+\": n(\"\",\"Unknown attribute \"+f+\": \"+h);var n(\"\",\"Invalid attribute \"+f+\": a};var i(\"\",\"Invalid uniform dimension matrix \"+name+\": i(\"\",\"Unknown uniform \"+name+\": \"+r)}var i(\"\",\"Invalid vector \"+name+\": c(e){for(var n=[\"return function n=[];for(var i r){var i(\"\",\"Invalid i(\"\",\"Invalid uniform dimension matrix \"+name+\": \"+t);return o(r*r,0)}throw i(\"\",\"Unknown uniform \"+name+\": p}function f(t){var r=0;r1){l[0]in c=1;c1)for(var l=0;l U ||b|| > 0.\\n // Assign z = 0, x = -b, y = a:\\n // a*-b + b*a + c*0 = -ba + ba + = 0\\n (v.x*v.x > v.z*v.z || v.y*v.y > v.z*v.z) {\\n v.x, 0.0));\\n } else {\\n v.z, -v.y));\\n }\\n}\\n\\n// Calculate tube vertex given index.\\n//\\n// returned vertex tube ring center origin, radius length(d), pointing direction d.\\n//\\n// Each tube segment made ring vertices.\\n// These vertices triangles tube connecting them together vertex array.\\n// indexes tube segments run 8.\\n//\\nvec3 d, index, normal) {\\n segmentCount = 8.0;\\n\\n angle = 2.0 * 3.14159 * (index / u = v = d));\\n\\n x = u * cos(angle) * length(d);\\n y = v * sin(angle) * length(d);\\n v3 = x + y;\\n\\n = color, uv;\\nuniform model\\n , view\\n , projection\\n , eyePosition\\n , f_normal\\n , , , f_data\\n , f_uv;\\n\\nvoid main() {\\n // Scale vector magnitude stay constant with\\n // model & view changes.\\n normal;\\n XYZ = * (tubeScale * vector.w * position.w, normal);\\n tubePosition = model * 1.0) + vec4(XYZ, 0.0);\\n\\n //Lighting geometry parameters\\n = view * /= = lightPosition - f_eyeDirection = eyePosition - f_normal = * // m_position = model * 1.0);\\n t_position = view * gl_Position = projection * f_color = color;\\n f_data = f_position = f_uv = : GLSLIFY 1\\n\\nfloat x, roughness) {\\n NdotH = max(x, 0.0001);\\n cos2Alpha = NdotH * NdotH;\\n tan2Alpha = (cos2Alpha - 1.0) / cos2Alpha;\\n roughness2 = roughness * roughness;\\n denom = * roughness2 * cos2Alpha * cos2Alpha;\\n exp(tan2Alpha / roughness2) / roughness,\\n fresnel) {\\n\\n VdotN = 0.0);\\n LdotN = 0.0);\\n\\n //Half angle vector\\n H = + //Geometric term\\n NdotH = H), 0.0);\\n VdotH = H), 0.000001);\\n LdotH = H), 0.000001);\\n G1 = (2.0 * NdotH * VdotN) / VdotH;\\n G2 = (2.0 * NdotH * LdotN) / LdotH;\\n G = min(1.0, min(G1, G2));\\n \\n //Distribution term\\n D = //Fresnel term\\n F = pow(1.0 - VdotN, fresnel);\\n\\n //Multiply terms done\\n G * F * D / max(3.14159265 * VdotN, a, b, p) {\\n ((p > max(a, b)) || \\n (p U ||b|| > 0.\\n // Assign z = 0, x = -b, y = a:\\n // a*-b + b*a + c*0 = -ba + ba + = 0\\n (v.x*v.x > v.z*v.z || v.y*v.y > v.z*v.z) {\\n v.x, 0.0));\\n } else {\\n v.z, -v.y));\\n }\\n}\\n\\n// Calculate tube vertex given index.\\n//\\n// returned vertex tube ring center origin, radius length(d), pointing direction d.\\n//\\n// Each tube segment made ring vertices.\\n// These vertices triangles tube connecting them together vertex array.\\n// indexes tube segments run 8.\\n//\\nvec3 d, index, normal) {\\n segmentCount = 8.0;\\n\\n angle = 2.0 * 3.14159 * (index / u = v = d));\\n\\n x = u * cos(angle) * length(d);\\n y = v * sin(angle) * length(d);\\n v3 = x + y;\\n\\n = id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n normal;\\n XYZ = * (tubeScale * vector.w * position.w, normal);\\n tubePosition = model * 1.0) + vec4(XYZ, 0.0);\\n\\n gl_Position = projection * view * f_id = id;\\n f_position = GLSLIFY 1\\n\\nbool a, b, p) {\\n ((p > max(a, b)) || \\n (p null;var strict\";var r-1}return n.create();var t-e});for(var max(a, b)) || \\n (p 0.0) ||\\n clipBounds[1], discard;\\n\\n N = V = L = {\\n N = -N;\\n }\\n\\n specular = V, N, roughness), 0.);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n //decide interpolate \\u2014 vertex fragment\\n surfaceColor =\\n .5) * vec2(value, value)) +\\n step(.5, vertexColor) * vColor;\\n\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = mix(litColor, contourColor, contourTint) * GLSLIFY 1\\n\\nattribute uv;\\nattribute f;\\n\\nuniform mat3 model, view, height, sampler2D value, kill;\\nvarying eyeDirection, main() {\\n dataCoordinate = permutation * vec3(uv.xy, height);\\n = objectOffset + worldPosition = model * 1.0);\\n\\n clipPosition = projection * view * clipPosition.z += zOffset;\\n\\n gl_Position = = f + kill = -1.0;\\n = uv.zw;\\n\\n vColor = vec2(value, value));\\n\\n //Don't lighting contours\\n surfaceNormal = vec3(1,0,0);\\n eyeDirection = vec3(0,1,0);\\n lightDirection = GLSLIFY 1\\n\\nbool a, b, p) {\\n ((p > max(a, b)) || \\n (p 0.0) ||\\n clipBounds[1], discard;\\n\\n ux = / shape.x);\\n uy = / shape.y);\\n gl_FragColor = vec4(pickId, ux.x, uy.x, ux.y + v=new k O(t,e){var invalid coordinates kt=0;kt halfCharStep + halfCharWidth 2){for(var n)return strict\";var Invalid texture size\");var Invalid shape Invalid shape pixel Invalid arguments texture2d instanceof instanceof instanceof ImageData&&t instanceof ImageData}var f(t,e,r){var Invalid texture size\");return d(t,e){return g(t){var Invalid texture Floating point textures supported platform\");var o=g(t);return Invalid ndarray, 2d 3d\");var Invalid shape Invalid shape pixel Incompatible texture format Error(\"gl-vao: Too vertex e=new t=new e=new t=new i=new n=new Error(\"Must least d+1 points\");var orient\");var i=new strict\";var x(null);return x(y(t))};var c(t,e){var u(t,e){var f(t,e){var i}}function d(t,e){for(var r;return n;return strict\";var e,r,n;function a=\"var sharedChunk = {}; r=i;else e=i}return n(t){return i(t,e){return a=o;function l=c;function u(t,e,r,n){var i=new instanceof p(t){for(var k(t){for(var 0,o=void original icon Sans Unicode MS t.kind}var i(t){return null;var 1, 2, 3 arguments, found instead.\");var i||!(i ct))return e.error('The item argument \"array\" string, number, rbga expected array containing either three four numeric ot(r||\"Could parse r=!0;return expression \"'+r+'\". wanted literal array, [\"literal\", ot(\"Input array least element. wanted literal array, [\"literal\", []].');var r)return name string, found \"+typeof r+' instead. wanted literal array, [\"literal\", ut(a,i));else null}else instanceof at)&&function t(e){if(e instanceof yt)return instanceof instanceof r=e instanceof ht||e instanceof lt||e instanceof ut,n=!0;return instanceof s=new dt;try{i=new i}return expression \"'+r+'\". wanted literal array, [\"literal\", invalid. Use null objects invalid. Use [\"literal\", {...}] array, found \"+typeof t+\" pairs \"step\" expressions arranged input values strictly ascending order.',c);var t};var e.error(\"Cubic bezier interpolation requires four numeric arguments values between pairs \"interpolate\" expressions arranged input values strictly ascending order.',h);var l.N?new \"+$(l)+\" ot(\"Array index bounds: \"+e+\" > ot(\"Array index integer, found \"+e+\" labels integers no larger branch labels integer null}else labels null;var g?new Ut(t,e){var r=e[0];throw instanceof r=e[0];return typeof i==typeof typeof n==typeof typeof i==typeof typeof n==typeof e[0].value r=e[0];return ne(t){return ie(t){return me(t,e,r){var n=void 0,t);if(void 0!==r&&void 0!==n)return _e(t){return t[0]&&t[0]in Rt}function we(t,e){var r=new n?Gt(new ot(\"Expected \")+\", found instanceof t;var Yt([new N(\"\",\"property expressions Yt([new N(\"\",\"zoom expressions a=function t(e){var r=null;if(e instanceof if(e instanceof Mt)for(var D(e,r,r+\" greater maximum ze(t){var function may \"stops\" least required property required property functions functions functions property f(t){var D(s,a,\"array expected, \"+fe(a)+\" D(s,a,\"array length expected, length \"+a.length+\" D(s,a,\"object expected, \"+fe(a[0])+\" D(s,a,\"object stop key D(s,a,\"object stop key zoom values appear ascending h(t,n){var D(t.key,c,s+\" stop domain match previous stop domain \"+e)]}else domain number, string, u=\"number expected, \"+s+\" found\";return intended categorical function, specify `\"type\": typeof t!=typeof He(t){return t(e){var D(n,r,\"array expected, \"+fe(r)+\" found\")];var D(n,r,'\"$type\" cannot operator D(n,r,'filter array operator \"'+r[0]+'\" 3 expected, \"+i+\" instanceof Error(\"can't serialize object \"+typeof t)}function t||t instanceof Boolean||t instanceof Number||t instanceof String||t instanceof Date||t instanceof RegExp||t instanceof instanceof fr)return t){var Error(\"can't deserialize object anonymous class\");var Error(\"can't deserialize unregistered class a}throw Error(\"can't deserialize object \"+typeof t)}var 1;var t};var e zr(r,void e(e,r){for(var i Xr(t,e){void Zr(t,e){return implemented concrete StructArray layout\")};var n=2*r;return a=4*i;return s=6*o;return c=8*l;return i=3*n;return r=1*e;return s=6*o;return n=4*r;return r=1*e;return i=3*n;return i=3*n;return n=2*r;return n=2*r;return a=4*i;return vertices per segment bucket requested exceeds allowed extent, reduce vector tile buffer size\")}return r}function Qn={paint:new t=new t=new t=new t=new e=t;return range source coordinates image range destination coordinates image copy\");for(var t;e||(e=t);var e}function ki(t){var Ai(t,e,r){var n=t;do{var n}function o=t;do{for(var Si(t,e){return r}(t,e)){var Oi(t,e){return Ri(t,e){return Wi(t,e){var na(t){return Error(\"unknown command if(7!==r)throw Error(\"unknown command u(t){for(var n=new Error(\"feature index Mn};function c=0;cc){var Ta=new r=new r=[],n=new Da(t,e,r){var Fa(t,e){var null;var e=new i t){var oo(t){return lo(t,e,r){var type: wo=3;function if(void if(void e(t,e,n){var r(t,e,r){var range source coordinates DEM tiles _('\"'+e+'\" valid encoding type. Valid types include \"mapbox\" a=n||i;return r=[];for(var t)n f(t,e){return h(e,r,n){void best %d after %d s=new glyphs being rendered tile. See r=new e){var l o){var _(e,r){for(var n=new t.id})))}}}var e=new x(c),r=new f){var a=f[n];a instanceof k(e,r){var r(o);var r[n],e()};var e[r]};var S(t){var $(t,e){for(var lt(t,e){var e,r,n}function ut(t){var ft(t){return ht(t){var r t}function dt(t){return t.x}function gt(t){return t.y}function Et(t){var e=[];return o}function Error(\"maxZoom should 0-24 range\");var %d clusters z%d-%d-%d (features: %d, points: %d, simplified: null;var down parent tile i)return e(new Error(\"Input valid GeoJSON e.data)return r(new Error(\"Input valid GeoJSON r(new Error(\"Input valid GeoJSON Error('Worker source name \"'+t+'\" already Error(\"RTL text plugin already Error(\"RTL Text Plugin failed import scripts self&&self instanceof t,e,r=new Error(\"failed create canvas 2d null;for(var y(t,e){var Error(\"An API access token required Mapbox GL. Error(\"Use public access token (pk.*) Mapbox GL, secret access token (sk.*). \"+m);return x(t){return t;var r=A(t);return i=A(t);return t;var Error(\"glyphs > 65535 r lat: }, array [, ]\")};var this._ne=t instanceof G?new this._sw=t instanceof G?new instanceof instanceof Y))return this}return instanceof Y?t:new Y(t)};var r=this;return r.fire(new r=this,n=void this;var this};var n=!1;for(var i e=(t-(void n={};for(var i o s n||(r=new r=this;t Xt(e,r){var $t(){return Qt(e,r){var n={};for(var i O}var T=new _e=new l i){var u=new 4294967295;var l s){var if(i&&o){var l i){var if(r)for(var i \")+\".\");return this.fire(new Error(\"An image name already this.fire(new Error(\"No image name Error(\"There already source Error(\"The property defined, following properties were given: Error(\"There no source ID\");for(var r this.fire(new Error('Source \"'+e+'\" cannot removed while layer \"'+r+'\" it.')));var Error('Layer id \"'+i+'\" already exists map')));else Error('Layer id \"'+r+'\" does exist Error('Layer id \"'+r+'\" does exist this.fire(new Error(\"The layer '\"+e+\"' does exist map's style cannot this.fire(new Error(\"The layer '\"+e+\"' does exist map's style cannot Error(\"The layer '\"+e+\"' does exist map's style cannot zoom 0,void this.fire(new Error(\"The layer '\"+e+\"' does exist map's style cannot Error(\"The layer '\"+e+\"' does exist map's style cannot this.fire(new Error(\"The layer '\"+e+\"' does exist map's style cannot e=this;return 0.5) {\\n gl_FragColor = vec4(0.0, 0.0, 1.0, 0.5) * alpha;\\n }\\n\\n (v_notUsed > 0.5) {\\n // box used, fade out\\n gl_FragColor *= .1;\\n main() {\\n projectedPoint = u_matrix * 0, 1);\\n = = clamp(\\n 0.5 + 0.5 * / 0.0, // Prevents oversized near-field boxes tiles\\n 4.0);\\n\\n gl_Position = u_matrix * vec4(a_pos, 0.0, 1.0);\\n gl_Position.xy += a_extrude * * gl_Position.w * v_placed = a_placed.x;\\n v_notUsed = main() {\\n alpha = 0.5;\\n\\n // Red = collision, hide label\\n = vec4(1.0, 0.0, 0.0, 1.0) * alpha;\\n\\n // Blue = no collision, label showing\\n (v_placed > 0.5) {\\n = vec4(0.0, 0.0, 1.0, 0.5) * alpha;\\n }\\n\\n (v_notUsed > 0.5) {\\n // box used, fade out\\n *= .2;\\n }\\n\\n = extrude_length = * stroke_width = 15.0 * / radius = v_radius * = - radius);\\n opacity_t = 0.0, gl_FragColor = opacity_t * main() {\\n projectedPoint = u_matrix * 0, 1);\\n = = clamp(\\n 0.5 + 0.5 * / 0.0, // Prevents oversized near-field circles tiles\\n 4.0);\\n\\n gl_Position = u_matrix * vec4(a_pos, 0.0, 1.0);\\n\\n padding_factor = 1.2; // Pad vertices slightly room anti-alias blur\\n gl_Position.xy += a_extrude * * padding_factor * gl_Position.w * v_placed = a_placed.x;\\n v_notUsed = a_placed.y;\\n v_radius = // We don't pitch circles, both units extrusion vector equal magnitude radius\\n\\n v_extrude = a_extrude * = * * main() {\\n gl_FragColor = main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, mapbox: define color\\n#pragma mapbox: define main() {\\n #pragma mapbox: initialize color\\n #pragma mapbox: initialize opacity\\n\\n gl_FragColor = * gl_FragColor = mapbox: define color\\n#pragma mapbox: define main() {\\n #pragma mapbox: initialize color\\n #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, mapbox: define mapbox: define v_pos;\\n\\nvoid main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n dist = length(v_pos - alpha = 1.0 - 1.0, dist);\\n gl_FragColor = outline_color * (alpha * gl_FragColor = mapbox: define mapbox: define main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos = / gl_Position.w + 1.0) / 2.0 * sampler2D mapbox: define main() {\\n #pragma mapbox: initialize opacity\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = / u_texsize, u_pattern_br_a / u_texsize, imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = / u_texsize, u_pattern_br_b / u_texsize, color2 = pos2);\\n\\n // find distance outline alpha dist = length(v_pos - alpha = 1.0 - 1.0, dist);\\n\\n\\n gl_FragColor = mix(color1, color2, u_mix) * alpha * gl_FragColor = mapbox: define main() {\\n #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n\\n v_pos_a = u_scale_a * a_pos);\\n v_pos_b = u_scale_b * a_pos);\\n\\n v_pos = / gl_Position.w + 1.0) / 2.0 * sampler2D mapbox: define main() {\\n #pragma mapbox: initialize opacity\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = / u_texsize, u_pattern_br_a / u_texsize, imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = / u_texsize, u_pattern_br_b / u_texsize, color2 = pos2);\\n\\n gl_FragColor = mix(color1, color2, u_mix) * gl_FragColor = mapbox: define main() {\\n #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n\\n v_pos_a = u_scale_a * a_pos);\\n v_pos_b = u_scale_b * mapbox: define base\\n#pragma mapbox: define mapbox: define color\\n\\nvoid main() {\\n #pragma mapbox: initialize base\\n #pragma mapbox: initialize height\\n #pragma mapbox: initialize color\\n\\n gl_FragColor = gl_FragColor = mapbox: define base\\n#pragma mapbox: define mapbox: define color\\n\\nvoid main() {\\n #pragma mapbox: initialize base\\n #pragma mapbox: initialize height\\n #pragma mapbox: initialize color\\n\\n = base = max(0.0, base);\\n height = max(0.0, height);\\n\\n = mod(normal.x, 2.0);\\n\\n gl_Position = u_matrix * vec4(a_pos, > 0.0 ? height : base, 1);\\n\\n // Relative luminance (how dark/bright surface color?)\\n colorvalue = color.r * 0.2126 + color.g * 0.7152 + color.b * 0.0722;\\n\\n v_color = vec4(0.0, 0.0, 0.0, 1.0);\\n\\n // Add slight ambient lighting no extrusions totally black\\n ambientlight = vec4(0.03, 0.03, 0.03, 1.0);\\n += // Calculate cos(theta), where theta angle between surface diffuse light ray\\n directional = / 16384.0, u_lightpos), 0.0, 1.0);\\n\\n // Adjust directional that\\n // range values narrower\\n // lower light intensity\\n // surface colors\\n directional = mix((1.0 - max((1.0 - colorvalue + 1.0), // Add gradient along z axis side surfaces\\n (normal.y != 0.0) {\\n directional *= clamp((t + base) * pow(height / 150.0, 0.5), mix(0.7, 0.98, 1.0 - 1.0);\\n }\\n\\n // Assign final based surface + ambient light color, diffuse light directional, light color\\n // lower bounds adjusted hue light\\n // shading tinted complementary (opposite) light color\\n v_color.r += clamp(color.r * directional * mix(0.0, 0.3, 1.0 - 1.0);\\n v_color.g += clamp(color.g * directional * mix(0.0, 0.3, 1.0 - 1.0);\\n v_color.b += clamp(color.b * directional * mix(0.0, 0.3, 1.0 - sampler2D mapbox: define base\\n#pragma mapbox: define height\\n\\nvoid main() {\\n #pragma mapbox: initialize base\\n #pragma mapbox: initialize height\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = / u_texsize, u_pattern_br_a / u_texsize, imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = / u_texsize, u_pattern_br_b / u_texsize, color2 = pos2);\\n\\n mixedColor = mix(color1, color2, u_mix);\\n\\n gl_FragColor = mixedColor * gl_FragColor = mapbox: define base\\n#pragma mapbox: define height\\n\\nvoid main() {\\n #pragma mapbox: initialize base\\n #pragma mapbox: initialize height\\n\\n = edgedistance = base = max(0.0, base);\\n height = max(0.0, height);\\n\\n = mod(normal.x, 2.0);\\n z = > 0.0 ? height : base;\\n\\n gl_Position = u_matrix * vec4(a_pos, z, 1);\\n\\n pos = normal.x == 1.0 && normal.y == 0.0 && normal.z == 16384.0\\n ? a_pos // extrusion top\\n : z * // extrusion side\\n\\n v_pos_a = u_scale_a * pos);\\n v_pos_b = u_scale_b * pos);\\n\\n v_lighting = vec4(0.0, 0.0, 0.0, 1.0);\\n directional = / 16383.0, u_lightpos), 0.0, 1.0);\\n directional = mix((1.0 - max((0.5 + 1.0), (normal.y != 0.0) {\\n directional *= clamp((t + base) * pow(height / 150.0, 0.5), mix(0.7, 0.98, 1.0 - 1.0);\\n }\\n\\n v_lighting.rgb += * u_lightcolor, mix(vec3(0.0), vec3(0.3), 1.0 - u_lightcolor), sampler2D v_pos;\\n\\nvoid main() {\\n gl_FragColor = v_pos) * gl_FragColor = v_pos;\\n\\nvoid main() {\\n gl_Position = u_matrix * vec4(a_pos * u_world, 0, 1);\\n\\n v_pos.x = a_pos.x;\\n v_pos.y = 1.0 - sampler2D coord, bias) {\\n // Convert encoded elevation meters\\n = coord) * 255.0;\\n (data.r + data.g * 256.0 + data.b * 256.0 * 256.0) / main() {\\n epsilon = 1.0 / // queried pixels:\\n // // | | | |\\n // | | b | c |\\n // | | | |\\n // // | | | |\\n // | d | e | f |\\n // | | | |\\n // // | | | |\\n // | g | h | i |\\n // | | | |\\n // = + -epsilon.y), 0.0);\\n b = + vec2(0, -epsilon.y), 0.0);\\n c = + -epsilon.y), 0.0);\\n d = + 0), 0.0);\\n e = 0.0);\\n f = + 0), 0.0);\\n g = + epsilon.y), 0.0);\\n h = + vec2(0, epsilon.y), 0.0);\\n i = + epsilon.y), 0.0);\\n\\n // here divide x y slopes 8 * pixel size\\n // where pixel size (aka meters/pixel) is:\\n // circumference world / (pixels per tile * tiles)\\n // equivalent to: 8 * / (512 * pow(2, u_zoom))\\n // reduced to: pow(2, 19.25619978527 - u_zoom)\\n // want vertically exaggerate hillshading though, otherwise\\n // barely noticeable low zooms. this, multiply some\\n // scale factor pow(2, (u_zoom - u_maxzoom) * a) where arbitrary value\\n // Here a=0.3 works expression below. see \\n // nickidlugash's awesome breakdown info\\n // exaggeration = u_zoom 0.0 ? 1.0 : -1.0);\\n\\n intensity = u_light.x;\\n // We add PI property match global light object, adds PI/2 light's azimuthal\\n // position property account 0deg corresponding north/the top viewport style spec\\n // original shader written accept - 90) azimuthal.\\n azimuth = u_light.y + PI;\\n\\n // We scale slope exponentially based intensity, calculation similar to\\n // exponential interpolation function style spec:\\n // // higher intensity values create opaque hillshading.\\n base = 1.875 - intensity * 1.75;\\n maxValue = 0.5 * PI;\\n scaledSlope = intensity != 0.5 ? ((pow(base, slope) - 1.0) / (pow(base, maxValue) - 1.0)) * maxValue : slope;\\n\\n // accent calculated cosine slope while shade calculated sine\\n // accent color's rate change eases while shade color's eases out.\\n accent = // We multiply both accent shade clamped intensity value\\n // intensities >= 0.5 additionally affect values\\n // while intensity values 0.0 ? ANTIALIASING : 0.0);\\n outset = gapwidth + halfwidth * (gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset2 = offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n = u_matrix * vec4(dist / u_ratio, 0.0, 0.0);\\n gl_Position = u_matrix * vec4(pos + offset2 / u_ratio, 0.0, 1.0) + // calculate much perspective view squishes stretches extrude\\n = = / gl_Position.w * v_gamma_scale = / v_width2 = vec2(outset, mapbox: define blur\\n#pragma mapbox: define sampler2D main() {\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset (v_width2.t) fading out\\n // (v_width2.s)\\n blur2 = (blur + 1.0 / * alpha = clamp(min(dist - (v_width2.t - blur2), v_width2.s - dist) / blur2, 0.0, 1.0);\\n\\n // For gradient lines, v_lineprogress ratio along entire line,\\n // scaled [0, 2^15), gradient ramp stored texture.\\n = 0.5));\\n\\n gl_FragColor = * (alpha * gl_FragColor = attribute conveying progress along scaled [0, 2^15)\\n#define 32767.0\\n\\n// distance over edge fades out.\\n// Retina devices smaller distance avoid ANTIALIASING 1.0 / / 2.0\\n\\n// floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale mapbox: define blur\\n#pragma mapbox: define mapbox: define mapbox: define mapbox: define width\\n\\nvoid main() {\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize gapwidth\\n #pragma mapbox: initialize offset\\n #pragma mapbox: initialize width\\n\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n\\n v_lineprogress = / 4.0) + a_data.w * 64.0) * 2.0 / pos = // x it's round cap, otherwise\\n // y points up, -1 points down\\n = v_normal = normal;\\n\\n // these applied JS native code bases.\\n // moved them shader clarity simplicity.\\n gapwidth = gapwidth / 2.0;\\n halfwidth = width / 2.0;\\n offset = -1.0 * offset;\\n\\n inset = gapwidth + (gapwidth > 0.0 ? ANTIALIASING : 0.0);\\n outset = gapwidth + halfwidth * (gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset2 = offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n = u_matrix * vec4(dist / u_ratio, 0.0, 0.0);\\n gl_Position = u_matrix * vec4(pos + offset2 / u_ratio, 0.0, 1.0) + // calculate much perspective view squishes stretches extrude\\n = = / gl_Position.w * v_gamma_scale = / v_width2 = vec2(outset, sampler2D mapbox: define blur\\n#pragma mapbox: define main() {\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset (v_width2.t) fading out\\n // (v_width2.s)\\n blur2 = (blur + 1.0 / * alpha = clamp(min(dist - (v_width2.t - blur2), v_width2.s - dist) / blur2, 0.0, 1.0);\\n\\n x_a = / 1.0);\\n x_b = / 1.0);\\n\\n // v_normal.y midpoint line, -1 lower edge, upper edge\\n // clamp width outset between half pattern height plus padding (2.0)\\n // ensure don't sample outside designated symbol sprite sheet.\\n // 0.5 added shift component bounded between interpolation of\\n // texture coordinate\\n y_a = 0.5 + (v_normal.y * 0.0, + 2.0) / 2.0) / y_b = 0.5 + (v_normal.y * 0.0, + 2.0) / 2.0) / pos_a = / u_texsize, u_pattern_br_a / u_texsize, vec2(x_a, y_a));\\n pos_b = / u_texsize, u_pattern_br_b / u_texsize, vec2(x_b, y_b));\\n\\n = pos_a), pos_b), u_fade);\\n\\n gl_FragColor = * alpha * gl_FragColor = floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale 2.0\\n\\n// distance over edge fades out.\\n// Retina devices smaller distance avoid ANTIALIASING 1.0 / / mapbox: define blur\\n#pragma mapbox: define mapbox: define mapbox: define mapbox: define width\\n\\nvoid main() {\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize offset\\n #pragma mapbox: initialize gapwidth\\n #pragma mapbox: initialize width\\n\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * pos = // x it's round cap, otherwise\\n // y points up, -1 points down\\n = v_normal = normal;\\n\\n // these applied JS native code bases.\\n // moved them shader clarity simplicity.\\n gapwidth = gapwidth / 2.0;\\n halfwidth = width / 2.0;\\n offset = -1.0 * offset;\\n\\n inset = gapwidth + (gapwidth > 0.0 ? ANTIALIASING : 0.0);\\n outset = gapwidth + halfwidth * (gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset2 = offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n = u_matrix * vec4(dist / u_ratio, 0.0, 0.0);\\n gl_Position = u_matrix * vec4(pos + offset2 / u_ratio, 0.0, 1.0) + // calculate much perspective view squishes stretches extrude\\n = = / gl_Position.w * v_gamma_scale = / v_linesofar = a_linesofar;\\n v_width2 = vec2(outset, sampler2D mapbox: define color\\n#pragma mapbox: define blur\\n#pragma mapbox: define mapbox: define width\\n#pragma mapbox: define main() {\\n #pragma mapbox: initialize color\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize width\\n #pragma mapbox: initialize floorwidth\\n\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset (v_width2.t) fading out\\n // (v_width2.s)\\n blur2 = (blur + 1.0 / * alpha = clamp(min(dist - (v_width2.t - blur2), v_width2.s - dist) / blur2, 0.0, 1.0);\\n\\n sdfdist_a = v_tex_a).a;\\n sdfdist_b = v_tex_b).a;\\n sdfdist = mix(sdfdist_a, sdfdist_b, u_mix);\\n alpha *= smoothstep(0.5 - u_sdfgamma / floorwidth, 0.5 + u_sdfgamma / floorwidth, sdfdist);\\n\\n gl_FragColor = * (alpha * gl_FragColor = floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale 2.0\\n\\n// distance over edge fades out.\\n// Retina devices smaller distance avoid ANTIALIASING 1.0 / / mapbox: define color\\n#pragma mapbox: define blur\\n#pragma mapbox: define mapbox: define mapbox: define mapbox: define width\\n#pragma mapbox: define main() {\\n #pragma mapbox: initialize color\\n #pragma mapbox: initialize blur\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize gapwidth\\n #pragma mapbox: initialize offset\\n #pragma mapbox: initialize width\\n #pragma mapbox: initialize floorwidth\\n\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * pos = // x it's round cap, otherwise\\n // y points up, -1 points down\\n = v_normal = normal;\\n\\n // these applied JS native code bases.\\n // moved them shader clarity simplicity.\\n gapwidth = gapwidth / 2.0;\\n halfwidth = width / 2.0;\\n offset = -1.0 * offset;\\n\\n inset = gapwidth + (gapwidth > 0.0 ? ANTIALIASING : 0.0);\\n outset = gapwidth + halfwidth * (gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist =outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset2 = offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n = u_matrix * vec4(dist / u_ratio, 0.0, 0.0);\\n gl_Position = u_matrix * vec4(pos + offset2 / u_ratio, 0.0, 1.0) + // calculate much perspective view squishes stretches extrude\\n = = / gl_Position.w * v_gamma_scale = / v_tex_a = * / floorwidth, normal.y * + u_tex_y_a);\\n v_tex_b = * / floorwidth, normal.y * + v_width2 = vec2(outset, sampler2D sampler2D main() {\\n\\n // read cross-fade colors parent tiles\\n color0 = v_pos0);\\n color1 = v_pos1);\\n (color0.a > 0.0) {\\n color0.rgb = color0.rgb / color0.a;\\n }\\n (color1.a > 0.0) {\\n color1.rgb = color1.rgb / color1.a;\\n }\\n = mix(color0, color1, u_fade_t);\\n color.a *= u_opacity;\\n rgb = color.rgb;\\n\\n // spin\\n rgb = vec3(\\n dot(rgb, dot(rgb, dot(rgb, // saturation\\n average = (color.r + color.g + color.b) / 3.0;\\n rgb += (average - rgb) * // contrast\\n rgb = (rgb - 0.5) * + 0.5;\\n\\n // brightness\\n u_high_vec = u_low_vec = gl_FragColor = u_low_vec, rgb) * color.a, gl_FragColor = main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n // We Int16 texture position coordinates give us enough precision for\\n // fractional coordinates. We 8192 scale texture coordinates buffer\\n // arbitrarily high preserve adequate precision rendering.\\n // also same EXTENT our tile buffer pos coordinates,\\n // math modifying either consistent.\\n v_pos0 = / 8192.0) - 0.5) / u_buffer_scale ) + 0.5;\\n v_pos1 = (v_pos0 * + sampler2D mapbox: define main() {\\n #pragma mapbox: initialize opacity\\n\\n alpha = opacity * gl_FragColor = v_tex) * gl_FragColor = PI = bool bool u_size_t; // interpolate between zoom stops size composite u_size; // size both zoom feature bool mapbox: define bool bool main() {\\n #pragma mapbox: initialize opacity\\n\\n a_pos = a_offset = a_tex = a_data.xy;\\n a_size = a_data.zw;\\n\\n segment_angle = size;\\n && {\\n size = mix(a_size[0], a_size[1], u_size_t) / 10.0;\\n } else && {\\n size = a_size[0] / 10.0;\\n } else && {\\n size = u_size;\\n } else {\\n size = u_size;\\n }\\n\\n projectedPoint = u_matrix * vec4(a_pos, 0, 1);\\n = // See comments distance_ratio = ?\\n / :\\n / = clamp(\\n 0.5 + 0.5 * 0.0, // Prevents oversized near-field symbols tiles\\n 4.0);\\n\\n size *= fontScale = u_is_text ? size / 24.0 : size;\\n\\n = 0.0;\\n {\\n // See comments = u_matrix * vec4(a_pos + vec2(1, 0), 0, 1);\\n\\n = / b = / = atan((b.y - a.y) / b.x - a.x);\\n }\\n\\n angle_sin = + angle_cos = + mat2 = -1.0 * angle_sin, angle_sin, projected_pos = * 0.0, 1.0);\\n gl_Position = * / + * (a_offset / 32.0 * fontScale), 0.0, 1.0);\\n\\n v_tex = a_tex / u_texsize;\\n fade_opacity = fade_change = > 0.5 ? u_fade_change : v_fade_opacity = max(0.0, min(1.0, + SDF_PX 8.0\\n#define EDGE_GAMMA bool mapbox: define mapbox: define mapbox: define mapbox: define mapbox: define sampler2D bool main() {\\n #pragma mapbox: initialize fill_color\\n #pragma mapbox: initialize halo_color\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize halo_width\\n #pragma mapbox: initialize halo_blur\\n\\n tex = v_data0.xy;\\n gamma_scale = v_data1.x;\\n size = v_data1.y;\\n fade_opacity = fontScale = u_is_text ? size / 24.0 : size;\\n\\n = fill_color;\\n gamma = EDGE_GAMMA / (fontScale * buff = (256.0 - 64.0) / 256.0;\\n (u_is_halo) {\\n = halo_color;\\n gamma = (halo_blur * 1.19 / SDF_PX + EDGE_GAMMA) / (fontScale * buff = (6.0 - halo_width / fontScale) / SDF_PX;\\n }\\n\\n dist = tex).a;\\n gamma_scaled = gamma * gamma_scale;\\n alpha = - gamma_scaled, buff + gamma_scaled, dist);\\n\\n gl_FragColor = * (alpha * opacity * gl_FragColor = PI = contents a_size vary based property value\\n// For constants, a_size disabled.\\n// For source functions, bind per vertex: evaluated current feature.\\n// For composite functions:\\n// [ feature),\\n// feature) ]\\nuniform bool bool u_size_t; // interpolate between zoom stops size composite u_size; // size both zoom feature mapbox: define mapbox: define mapbox: define mapbox: define mapbox: define bool bool bool main() {\\n #pragma mapbox: initialize fill_color\\n #pragma mapbox: initialize halo_color\\n #pragma mapbox: initialize opacity\\n #pragma mapbox: initialize halo_width\\n #pragma mapbox: initialize halo_blur\\n\\n a_pos = a_offset = a_tex = a_data.xy;\\n a_size = a_data.zw;\\n\\n segment_angle = size;\\n\\n && {\\n size = mix(a_size[0], a_size[1], u_size_t) / 10.0;\\n } else && {\\n size = a_size[0] / 10.0;\\n } else && {\\n size = u_size;\\n } else {\\n size = u_size;\\n }\\n\\n projectedPoint = u_matrix * vec4(a_pos, 0, 1);\\n = // label pitched map, layout done pitched space,\\n // makes labels distance smaller relative viewport space.\\n // We counteract part effect multiplying perspective ratio.\\n // label isn't pitched map, layout viewport space,\\n // makes labels distance larger relative features around\\n // them. We counteract part effect dividing perspective ratio.\\n distance_ratio = ?\\n / :\\n / = clamp(\\n 0.5 + 0.5 * 0.0, // Prevents oversized near-field symbols tiles\\n 4.0);\\n\\n size *= fontScale = u_is_text ? size / 24.0 : size;\\n\\n = 0.0;\\n {\\n // Point labels map' horizontal respect tile units\\n // To figure angle projected space, draw short horizontal tile\\n // space, project it, measure angle projected space.\\n = u_matrix * vec4(a_pos + vec2(1, 0), 0, 1);\\n\\n = / b = / = atan((b.y - a.y) / b.x - a.x);\\n }\\n\\n angle_sin = + angle_cos = + mat2 = -1.0 * angle_sin, angle_sin, projected_pos = * 0.0, 1.0);\\n gl_Position = * / + * (a_offset / 32.0 * fontScale), 0.0, 1.0);\\n gamma_scale = tex = a_tex / u_texsize;\\n fade_opacity = fade_change = > 0.5 ? u_fade_change : = max(0.0, min(1.0, + v_data0 = vec2(tex.x, tex.y);\\n v_data1 = size, mapbox: ([\\w]+) ([\\w]+) ([\\w]+) \"+n+\" \"+i+\" \"+n+\" \"+i+\" \"+n+\" \"+i+\" \"+a+\" = \"+n+\" \"+o+\" \"+n+\" \"+i+\" \"+n+\" \"+i+\" \"+a+\" = \"+n+\" \"+i+\" \"+a+\" = \"+n+\" \"+o+\" \"+n+\" \"+i+\" \"+n+\" \"+i+\" \"+a+\" = \"+n+\" \"+i+\" \"+a+\" = rr Qe)er(rr);var Er(e,r,n){var t=new 0===n&&void Error(\"failed invert 1;var r(r,n,i){var Jr(t){return 61:case 107:case 171:case 189:case 109:case positive number, Object keys 'bottom', 'left', 'right', e){var k=m*m;function T(t){var | Error(\"maxZoom greater minZoom\");var n=new on;var instanceof ln))throw Error(\"Invalid type: 'container' String en)t[a]=new n=new n=new r=new r=new e=new Error(\"maxZoom greater current 0===n)return s 0===n)return vn(t,e,r){var i 27 41\");var device does support fullscreen r){var instanceof e(new r=new r};var l(t){var c(t,s){var s;return n(t){return t)return 1=0)return specify vertex creation specify cell creation specify phase Invalid boundary s){var l){var c){var \"+n),s?new n=[\"'use b(e,r){var o=\"__l\"+ a=\"__l\"+ n.push(\"var strict\";var strict\";var o(t,e){return s(){var [2,1,0];}else [1,0,2];}}else [2,0,1];}else a.push(\"var function 0===r){r=new i=new t||\"up\"in i};var u(t,e){var strict\";var r?r+\"\":\" e=new a(e,a,o){var circular dependency. Please, check o=new a?r:function references a=new references i}return t(e,r){return \"+r+\"is t[r]}}function a(t,e){return strict\";var l left Left\",top:\"y top Top\",width:\"w width W height W bottom right e=[];return 0:return r||[];case 1:return 2:return f(t,r){var l};var Array(g),m=new t-e});var r};var u(t,e){for(var r=new u=y[a];void null;return s=1;a;){var s}};return u(t,n){var n;var v(){if(d){var Zero-length segment detected; epsilon probably too small too r=1;r0){var strict\";var extension should enabled\");var position, direction, lineOffset, lineWidth, scale, scaleFract, translate, main() = / pixelOffset = lineWidth * lineOffset + (capSize + lineWidth) * dxy = -step(.5, direction.xy) * error.xz + vec2(-.5)) * position = position + pos = (position + translate) * (positionFract + * (position + translate) * (positionFract + * += pixelOffset / = vec4(pos * 2. - 1., 0, main() = *= minus src minus dst e)return u=x[c];return colors cap capsize line-width width position t[0]){var a=0;a 0. && baClipping 0. && abClipping cutoff + .5) -= - .5, cutoff + .5, == 1.) = endCutoff.xy, (distToEnd cutoff + .5) -= - .5, cutoff + .5, = / dashSize) * .5 + .25;\\n\\tfloat dash = vec2(t, = *= alpha * opacity * GLSLIFY 1\\n\\nattribute position, scale, scaleFract, translate, pixelRatio, id;\\nuniform MAX_LINES = 256.;\\n\\nvoid main() {\\n\\tfloat depth = (MAX_LINES - 4. - id) / position = position * scale + translate\\n + positionFract * scale + + position * scaleFract\\n + positionFract * = vec4(position * 2.0 - 1.0, depth, = / *= GLSLIFY 1\\n\\nvarying main() = points lineWidth lineWidths line-width linewidth width stroke-width strokewidth linejoin join dashes dasharray dash-array colour stroke colors colours stroke-color fill-color crease overlap close closed-path hole 1.0 + delta) -= smoothstep(1.0 - delta, 1.0 + delta, borderRadius = ratio = - delta, borderRadius + delta, = mix(fragColor, *= alpha * = GLSLIFY 1\\n\\nattribute x, y, xFract, size, colorId, scale, scaleFract, translate, sampler2D maxSize = fragColor, isDirect = (paletteSize.x e[0]){for(var a;if(t instanceof Uint8Array||t instanceof s(){function 5120:n=new 5121:n=new 5122:n=new 5123:n=new 5124:n=new 5125:n=new 5126:n=new null}return s}var e||(e=new t&&t._elements instanceof g(t){for(var t}function L(t){for(var t=0;return n(t,e){var f}var h=new a=m();return for(var u(t){var h(t){return m(e){var a(t,e){for(var t=0;return a=i[t];return a||(a=new n(t){if(t i){var a){var c=a[t];return e?new o=t;t=new e(e,a){if(t r){var s})}else if(t n){var n(t,n){return i(t){return r.def('\"',t,'\" o(){function t=0;return o(e,r){var c=new blend.equation stencil.func stencil.opBack viewport scissor.box minus src minus src minus dst minus dst minus constant minus constant alpha u(){var null;var r(e){var tt(t,l);else t=0;t=r)return n}function u(t){return e=new \",e);var s=new o;n=-(i+a)}var i(n(t))};var i}function u(t,e){for(var r=new r}function x(t){for(var e=m(t);;){var t=T[0];return w(t,e){var r=T[t];return T=[],A=new l}else if(c)return l}else if(c)return c;return a[0]-s[0]};var i(t,e){var t;var r}function i=p.index;else strict\";var a(t,e){var o(t,e,r,n){var i[e];var unexpected failed parse named argument failed parse named argument mixing positional named placeholders (yet) n(t,r){return strict\";var Error(\"First argument should should string b=new Array(y),d=0;d c)|0 d=new Array(r),g=new Array(r),v=new Array(r),m=new r};var strict\";var should valid svg path n;var n=!1;var e=new m=new t(e,r,i){var i=i||{};var \":{data:new p=new a}function t){var r={};for(var e={};for(var r e}(S);function C(t){return o(t){var e=t1)for(var i})}}var Error(\"n Error(\"already h(t){return p(t){return d(t){return g(t){return v(t){return m(t){return y(t){return x(t){return b(t){return o?new _(t){return null}return t}).join(\" \");var \",\"italic bold \"):\"bold n}function b(t,e){var _(t,e,r,n){var n=y(e);return n?r o?r o&&delete p,d=new al-ahad\",\"Yawm {0} {0} {0} {0} mix {0} {1} format date another position name position literal position text found dd M MM d, d M d M d M d M yyyy\",RSS:\"D, d M l){y(\"m\");var a=this;return var _inline_1_da = - var _inline_1_db = - >= 0) !== (_inline_1_db >= 0)) {\\n + 0.5 + 0.5 * (_inline_1_da + _inline_1_db) / (_inline_1_da - }\\n r=[];return 1,1 0,-2A2,2 0,1 strict\";var strict\";var o(t){var s(t,e){var strict\";var o(t,e){var z();var z();var strict\";var t}var a?\"rgba(\"+s+\", i=n(t);return t){var 0!==i&&void 0!==a){var strict\";var strict\";var 0;var strict\";var strict\";var r(t,e){var o(t,i){var r}function strict\";var strict\";var f(){var h(t){return r;try{r=new strict\";var strict\";var t){var 0!==u,d=void e=void 0!==x,w=void 0!==b;return E=.5;function C(t,e,r,i){var \")}).split(\" \")}).split(\" scale(\"+e+\", strict\";var 1,1 0,1 \"+a+\",\"+a+\" \"+a+\",\"+a+\" \"+r+\",\"+r+\" \"+r+\",\"+r+\" 1,1 0,1 1,1 0,1 strict\";var l(t,e,r,i){var t.id});var o.remove();var strict\";var strict\";var strict\";var o(t){return d(t){var A(t,e,r){var x,b,_=\"top delete T(t,e){return Array(g);var w(t,e){return strict\";var T(t,e,r){var t.remove();var A(t,e){var t;for(var \";return t}function M(t,e){var S(t,e,r){var if(l){var E(t){var strict\";var y(t,e,r){var x(t,e,r){var i=m(void A=m(void m(t,e,r,n){var r[1]}return o}function y(t){return strict\";var u(t,e){var v8h2v-8 h8v-2h-8 v-8h-2 if(P){var h2 v-18 v2 h-18 d(t,e,r){var g(t,e){var extra params segment 1,1 0,1 r S(t,e){var E(t,e){var C(t,e,r){var L(t,e){var r(r,i){return strict\";var p(t){return c(t,e){return t){var ms \"+t+\" calendar \"+r)}var c=new e=new o*o+s*s}var 0;var n[r];var h(e){var Error(\"No DOM element id '\"+t+\"' exists page.\");return Error(\"DOM element provided null strict\";var f(t,e){var r=t;return c;var e=a(t);return p(t){return r=new failed n;function i(){return r={};return strict\";var property strict\";var instanceof if(!(void c(t,e){return binary r=e%1;return strict\";var strict\";var s(t,e){return error tex O(),void e();var \");var u(){c++;var s=1;s doesnt match end tag . Pretending did unexpected end tag null;var n&&E(n)}var r=void E(t){return e(t);var C(t,e,r){var i(e,r){return 1px l(t){var strict\";var n={};function s e=n[t];return e&&e.timer?new n[t];else for(var e strict\";var strict\";var enter Colorscale title\":\"Click enter Colorscale enter Colorscale title\":\"Click enter Colourscale %b %e %X %-d, strict\";var previous rejected promises t.scene1);var array edits incompatible other edits\",f);var full array edit if(void & removal incompatible edits same full object edit Error(\"each index \"+r+\" Error(\"gd.data e)throw required Error(\"current indices equal Error(\"gd.data Error(\"update key:value r)throw Error(\"indices integer array \"+a+\" array length equal indices array Error(\"when maxPoints set key:value object contain 1:1 corrispondence keys traces update d t[e]}}function 0);var G(t,e,r){var i c Y(t,e){var i e){var o $(t,e){var Y r;return l(t){return c(t,e){var r=0;return t()}}return m(t){return addFrames accepts frames numeric names, numbers areimplicitly cast Error(\"gd.data e)throw Error(\"traces t;var t=a[i]}else t=a}}return t}function k(t){return T(t){return t(e){for(var r h(){var t=l;return u(),t}return i=h();for(var strict\";var w(t){var x(t,e,r){var t(e,r){for(var strict\";var d(t){return!(t Error(\"Height width should pixel Error(\"Image format jpeg, png, svg webp.\");var g={};function v(t,r){return S(){return E(){return strict\";var e}}var strict\";var u=new V(t,e,r){var r;function n(t){return t.dtick){var error: t+o*e;var dtick dtick Y(t,e){var X(t,e){var 0}function Z(t,e){var zoom back V(t){var strict\";var strict\";var y(t){return t._id}function S(t){var E(t,e,r){var strict\";var m(t){return y(t){return r={},n=0;n g(e,r){var strict\";var o(t,e){var 0===t[r]&&void v(t){return n(t){var i(t){return strict\";var u(){}var m(t){return i(t,r){for(var C(t,e){var z(t,e){var I(t,e){var D(t,e){var strict\";var u(t,e){return f(t,e,r){var h(t,e){var i(r){var p(t,e){var y(t){return x(r){var n=e(r);return d(t,e){var strict\";var strict\";var e=0;e/g,\" l(t){var n=new a(t,e);return strict\";var Sans Regular, Arial Unicode MS strict\";var r(r,i){return strict\";var g(t){var v(t){return p=s.map=new b(){var - _(t,e){var o(t){for(var i=0;i0){var h l=void delete i[e],delete m d)g[m]||delete d[m];for(var y M S(t,e,r){var n=!1;var l(){return t)return e,n,i={};for(e i}return r=c(t);return e&&delete I=(new + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + 0px\",\"1px -1px\",\"-1px 1px\",\"1px \"+t+\" W(t,e){return \"+n+\" \"+n+\" \"+n+\" u=\"t: \"+c.t+\", r: l;var r t)r r r=e||6;return t)return null;var r(){var n.mode,delete r}};return strict\";var s;function h(r,s){return i(t,e){return n=e[r];return d(t,e,r,n){var o(r,n){return strict\";var D(t){var e={};return P(t,e){var R(t,e){return F(t,e){return N(i,a){var zoom back V(t,e){var \"+d+\" \"+g));var _=(new strict\";var m(t){for(var x(t){return e}return r;return o;return A(e,r,n){var i}var c(t){var e=o?r:n;return _=0;m(\"percent strict\";var strict\";var strict\";var strict\";var 0, 0, strict\";var s(t,e,r){var i l(t,e){return c(t){return t)return s;s=e+\"0\"in \\xb1 strict\";var s(t,e,r,o){var u(t,e,r,a){var null;var i=1/0;var a=-1/0;var strict\";var b.tickvals;var I(n){var D(n){var strict\";var strict\";var strict\";var f(e,r){var e>0&&void converged strict\";var strict\";var strict\";var strict\";var c(t,e){for(var strict\";var strict\";var invalid specified inequality contours, clipping strict\";var loop contour?\");var g(t){return newendpt vert. perimeter strict\";var if(h){var strict\";var strict\";var strict\";var strict\";var u(r,i){return strict\";var k(t){return newendpt vert. perimeter strict\";var a=!1;function o(r,a){return s=0;s strict\";var left\",\"top center\",\"top strict\";var strict\";var strict\";var l(r,a){return strict\";var strict\";var r(r,a){return strict\";var u(){var scale scale strict\";var iterated no strict\";var i.error(\"Error hovering heatmap, pointNumber [row,col], didn't converge strict\";var l=0;la){var d(t,e,r){var P(t,e){return if(k>0){var F(t,e,r,n){var strict\";var strict\";var strict\";var strict\";var p(t){for(var f}function f(t,e,r,i){var v(t){return strict\";var strict\";var h(r,i){return strict\";var u(t,e,r,i){var t.color});var -1px 1px 2px, \"+I+\" 1px 1px 2px, \"+I+\" 1px -1px 2px, \"+I+\" -1px -1px 0, f(t){return t.key}function h(t){var p(t,e){return \"Courier New\", \"));var \"Courier New\", \\u2229 \"+p+\"): | color): | \"+p+\"): \"Courier New\", r=[];return S(t){var z(t){for(var \";return P(t){var u f(t){var h=new y,x=new strict\";var strict\";var strict\";var c(t,e){return f(t,e){return w(t,e){return T(t){for(var strict\";var strict\";var o(t){return traces support \"+u+\" dimensions strict\";var GLSLIFY 1\\n\\nattribute p0, p1, p2, p3,\\n p4, p5, p6, p7,\\n p8, p9, pa, pb,\\n pc, pd, pf;\\n\\nuniform dim1A, dim2A, dim1B, dim2B, dim1C, dim2C, dim1D, dim2D,\\n loA, hiA, loB, hiB, loC, hiC, loD, resolution,\\n sampler2D sampler2D mask;\\nuniform unit_1 = vec4(1, 1, 1, 1);\\n\\nfloat val(mat4 p, v) {\\n v) * unit_1, axisY(\\n x,\\n d[4],\\n dim1A, dim2A, dim1B, dim2B, dim1C, dim2C, dim1D, dim2D\\n ) {\\n\\n y1 = val(d[0], dim1A) + val(d[1], dim1B) + val(d[2], dim1C) + val(d[3], dim1D);\\n y2 = val(d[0], dim2A) + val(d[1], dim2B) + val(d[2], dim2C) + val(d[3], dim2D);\\n y1 * (1.0 - x) + y2 * x;\\n}\\n\\nconst int bitsPerByte = 8;\\n\\nint mod2(int a) {\\n - * (a / 2);\\n}\\n\\nint mod8(int a) {\\n - 8 * (a / 8);\\n}\\n\\nvec4 zero = vec4(0, 0, 0, 0);\\nvec4 unit_0 = vec4(1, 1, 1, 1);\\nvec2 xyProjection = vec2(1, 1);\\n\\nmat4 mclamp(mat4 m, lo, hi) {\\n lo[0], hi[0]),\\n clamp(m[1], lo[1], hi[1]),\\n clamp(m[2], lo[2], hi[2]),\\n clamp(m[3], lo[3], mshow(mat4 p, lo, hi) {\\n mclamp(p, lo, hi) == p;\\n}\\n\\nbool d[4],\\n loA, hiA, loB, hiB, loC, hiC, loD, hiD\\n ) {\\n\\n mshow(d[0], loA, hiA) &&\\n mshow(d[1], loB, hiB) &&\\n mshow(d[2], loC, hiC) &&\\n mshow(d[3], loD, d[4], sampler2D mask, height) {\\n bool result = true;\\n int valY, valueY, scaleX;\\n int hit, bitmask, valX;\\n for(int i = 0; i T(t,e,r){var E(t,e){return 255, 255, 0)\");var E(t,e){for(var 1px 1px #fff, -1px -1px 1px #fff, 1px -1px 1px #fff, -1px 1px 1px strict\";var 0===l[s]){var i(t,e,r){var strict\";var left\",\"top center\",\"top right\",\"middle left\",\"bottom left\",\"top center\",\"top right\",\"middle left\",\"bottom strict\";var strict\";var u(t){return f(t,e){var c;var g(t,e){return v(t,e){var m(t,e){var y(t,e){var x(t){var r}function b(t,e){for(var strict\";var strict\";var strict\";var strict\";var 0, for(r=new P=!1;return r=c(e);return strict\";var r(r,a){return p(r,a){return m(t,e){return _(t,e){return strict\";var y(){var t=.5;return \"+i.targetX+\" \"+i.targetX+\" \"+c+\",\"+h+\" \"+l+\",\"+f+\" k(t){return 0)\":\"matrix(0 0)\")}function M(t){return S(t){return 0)\":\"matrix(0 0)\"}function E(t){return 1)\":\"scale(-1 1)\"}function C(t){return L(t){return O(t,e,r,a){var o(){var strict\";var v(r,i){return strict\";var strict\";var strict\";var H(e){var q(t,e,r,n){var st(t,e){return 0)}function s}}function ct(t){var strict\";var strict\";var strict\";var y(t){return $(t){return J(t){return K(t){return Q(t){return t.id}function Q}function scatter strict\";var y(t){return x(t,e){return b(t){return p[t]}function o=0;o=0){var o}function k(t,e){var = strict\";var strict\";var f(t,e){var strict\";var d(r,i){return 1/0;var u(t){return strict\";var s=a[0];if(void a;var strict\";var c=l[0];if(void l;var strict\";var strict\";var strict\";var strict\";var strict\";var d(t){var g(t,e){var g(t,e){var h.remove();var d}}(t);return x(t,e){var r;return k(t){return T(t,e,r){var A(t,e,r){var r;return strict\";var o(t,e,r){var strict\";var strict\";var strict\";var r}function strict\";var t/E*m});var r=A[t];return strict\";var r&&r.match(/[ strict\";var s(r,a){return m=(\" function(){var e,r})}function I(t,e){for(var r}function D(t,e){for(var g(t){return strict\";var a=!1;function o(r,a){return strict\";var e=h(t);return e=h(t);return e=h(t);return e=h(t);return = 'local'}; {font: (typeof require !== 'undefined') { paths: { 'plotly': } }); { window._Plotly = Plotly; }); } In\u00a0[3]: def payload): url = response = requests.get( url=url, params=payload ) == 200: # - success!') else: None In\u00a0[4]: payload = { 'metrics': 'PriceUSD,'+ 'TxTfrValUSD', 'start': '2016-01-01', } # PriceUSD TxTfrValUSD utilised yet. Because work needs expanded order complete, keep them here now. asset_list = ['btc', 'ltc', 'bch', 'bsv', 'doge'] = {} asset asset_list: data[asset] = payload) In\u00a0[5]: dataframes = {} cols = ['PriceUSD', 'TxTfrValUSD'] asset data.keys(): values = [ each['values'] index = [ each['time'] df = columns = cols) df.index = col df.columns: df[col] = # create fields df['TxCount'] = df.TxTfrValUSD / = / = df In\u00a0[6]: # take look wrangled data: Out[6]: .dataframe tbody tr { middle; } .dataframe tbody tr th { top; } .dataframe thead th { text-align: right; } PriceUSD TxTfrValMedUSD TxTfrValUSD TxCount 2019-07-14 131.077983 1198.889057 0.879414 1.194010e+08 99593.000016 1363.281771 2019-05-29 193.318255 11679.327829 39.889202 5.360111e+08 45894.000000 292.794223 2019-03-28 63.633667 4749.332321 2.107293 6.684210e+07 14074.000000 2253.759666 2018-12-06 104.833018 47784.404159 25.002851 4.480266e+08 9376.000000 1911.158216 2019-08-20 145.397527 403.290224 1.017783 4.721077e+07 117063.999986 396.243941 Out[6]: .dataframe tbody tr { middle; } .dataframe tbody tr th { top; } .dataframe thead th { text-align: right; } PriceUSD TxTfrValMedUSD TxTfrValUSD TxCount 2018-09-17 6259.378141 6375.290054 63.354108 3.529992e+09 553699.0 100.629466 2018-03-08 9334.330053 13564.972440 115.393462 6.573545e+09 484597.0 117.554082 2018-09-18 6341.494595 6596.250810 65.237872 3.774480e+09 572216.0 101.110760 2017-10-18 5577.949350 12797.567565 68.015674 1.002400e+10 783274.0 188.156154 2018-01-21 11392.308625 13715.375223 161.642277 8.149868e+09 594214.0 84.850173 Out[6]: .dataframe tbody tr { middle; } .dataframe tbody tr th { top; } .dataframe thead th { text-align: right; } PriceUSD TxTfrValMedUSD TxTfrValUSD TxCount 2018-02-17 0.007081 2667.709156 1.382312 1.623514e+08 60858.0 1929.889309 2019-02-26 0.001952 353.988959 0.807753 2.240715e+07 63299.0 438.239326 2019-03-22 0.002017 200.227768 0.443784 1.414069e+07 70623.0 451.182435 2018-08-14 0.002247 184.665415 0.516715 1.255374e+07 67981.0 357.383769 2017-04-09 0.000385 235.941139 0.234514 9.458172e+06 40087.0 1006.084710 Compare daily mean median USD transaction BTC since January 2016\u00b6 In\u00a0[7]: btc_mean = go.Scatter( name='BTC mean', ) btc_median = go.Scatter( name='BTC median' ) = [btc_mean, btc_median] layout = go.Layout( title=\"BTC median mean transaction values day\", value'), ) fig = layout=layout) py.iplot(fig, Out[7]: chart above shows\u00a0that: daily mean transaction higher daily median two averages are\u00a0correlated From 2016 present, mean approximately orders magnitude higher median. relationship appears consistent across previous 4 years. Note: During last 4 years, USD BTC increased ~400USD currently ~10000USD. impact changing USD price coins mean median should investigated. easily achieved TxTfrValUSD PriceUSD metrics. We also calculate Plot ratio daily mean median USD transaction values asset since January 2016\u00b6 In\u00a0[8]: def name): go.Scatter( name=name ) = asset) asset layout = go.Layout( title=\"Ratio daily mean median transaction value\", ) fig = layout=layout) py.iplot(fig, Out[8]: Note: Except BTC, series above very \u201cchoppy\u201d. chart were shown clients consider smoothing series e.g. 7 day moving average. However, might obscure features initial exploration chart above shows BTC lowest ratio mean median daily transaction value. suggests compared other blockchains relatively strong organic\u00a0use. less influenced by\u00a0whales. MMR lower Point 3 suggests wide regular user base total daily transaction volumes should analysed across 5 chains futher strengthen rebutt Using ratio proxy measure organic use, chain second most organic is\u00a0Litecoin. Since start 2019, influence whales Dogecoin network Of two contentious hard forks, Bitcoin Cash shows two distinct phases different in\u00a0each: From inception August 2017 November 2018, influence whales increased steady rate. At coins genesis, there appears been large organic user base transacting daily, bringing median transaction within 50 - 100x mean daily transaction value. lower Bitcoin\u2019s, had much consistent higher MMR 120 -\u00a0200. After November 2018, ratio increases average approximately 500 approximately 10,000. stark abrupt change daily ratio, suggests that\u00a0either organic drastically decreased,\u00a0or BCH very suddenly started being facilitate very large transfers relatively few\u00a0users. As January 2019, Dogecoin appears widespread organic either BCH BSV, despite status \u201cjoke\u201d blockchain. However DOGE had higher MMR BTC LTC in\u00a02019. Next Steps\u00b6This brief investigation developed over course afternoon, project brief recommending 4 hours work. In order applied commercial context, analyis should expanded tested least Test central assumption analysis true. Possible approaches could\u00a0include: Removing exchange outflows data. Could done known exchange addresses (exchanges aggregate organic retail Quantifying influence \u201cchange\u201d transactions - aggregate should nil day-to-day \u201ccash\u201d transactions, whales moving entire balance address there no \u201cchange\u201d amount. Depending metric calculated may may For BTC LTC, lightning networks distorting results hiding organic low For BTC, liquid sidechain hiding activity whales extent \u201chealthiest\u201d 5 Can infer where whales \u201cnormal\u201d users live, analyzing transactions? People much likely transaction midday midnight, investigate geographic clustering. e.g. Is BTC \u201cwestern\u201d chain, whilst BCH organic in\u00a0Asia? An analysis daily transaction volume (in USD terms) essential analysis. It provide context interpret significance differences between chain differences bewtween time\u00a0frames. Similarly, comparing hash power dedicated mining blocks chain indicate commercial interests, abrupt changes hash power possibly correlated changes mean-median ratio (MMR). { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , , , , , ]","category":"Technical/Data"},{"title":"A faster\u00a0shell","url":"shell.html","body":"Opening shell annoyingly slow. Not terrible, enough notice. Its a\u00a0niggle. wanted find components were causing most delay, measure long took launch shell. Even though shells might appear part low level \u2018guts\u2019 computer, shell just executable treated as\u00a0such. To measure startup speed shell,\u00a0do: i $(seq 10); /usr/bin/time $SHELL -i -c exit; done shows takes 0.84 seconds start zsh - terrible, not\u00a0great: You compare performance different shells replacing $SHELL zsh, bash, fish etc. Here results BASH instead zsh - 9.3x faster! (but without useful tools plugins): Now measure long takes start, useful know proccesses causing greatest delays. done something zsh -xv enables verbose output xtrace. creates tonne output, doesnt inlcude timestamps. All really want summary much subproccess required run, i.e. order Add zmodload zsh/zprof start .zshrc zprof very end. Now start zsh see the\u00a0following: Next steps - run faster, asyncronously, at\u00a0all\u2026 Update: biggest cause slow loading. Using lazy loading option decreased loading by\u00a00.3s","tag":"[, , , , ]","category":"Technical/Developer Tools"},{"title":"Bitcoin\u00a0Lightning","url":"bitcoin-lightning.html","body":"One largest obstacles (second privacy opinion) widespread adoption Bitcoin limited volume. Bitcoin cannot faciliate payments fast enough such compete Visa or\u00a0Mastercard. most interesting solution problem Lightning protocol - separate protocol sits ontop Bitcoin protocol (a so-called \u2018Layer 2\u2019 solution). Lightning uses hashed locked contracts (HTLCs) trustlessly privately move transactions off-chain. allows payments faster, cheaper frequent. It also interesting implications There lot resources Lightning network is, why it\u2019s neccesary works. There also several good guides available set maintain node. Raspberry Pi external hdd. It took few attempts, mostly it\u2019s first working unix operating system tried move swap file disk wasnt formmated as\u00a0ext4\u2026 Anyway, I\u2019ve opened closed channels, connected peers, made transactions. even bought stickers You find node these\u00a0details: Alias: Public Key: IP address: 85.145.183.145 Port: 9735 Some Lightning Lightning Interesting things to\u00a0do","tag":"[, , ]","category":"Technical/Cryptocurrencies"},{"title":"Sync a BTC node,\u00a0quickly","url":"sync-bitcoin-core-node.html","body":"In order run own bitcoin node, lightning node, you\u2019ll download entire bitcoin blockchain validate it. takes ages magnetic disk due random access speed contents To remove bottleneck, move chainstate directory SSD (its few GB) symlink bitcoin directory. More details Bitcoin wiki. When sync complete, replace symlink actual","tag":"[, , , ]","category":"Technical/Cryptocurrencies"},{"title":"Bakke-Rij","url":"bakkerij.html","body":"recently began working coworking space, sharing office unit another entrepreneur. What makes coworking space unique it\u2019s conversion industrial bakery coworking space. Where machinery once stood, converted shipping containers glass walls become offices startups skylights, glass walls bright colors create light airy atmosphere, space seems popular designers founders working creative industries. It\u2019s energetic space creative feel to\u00a0it.","tag":"[, , ]","category":"Non-technical/Entrepreneurship"},{"title":"Prediction\u00a0Markets","url":"prediction.html","body":"Predicting port traffic Background A prediction market allows people bet unknown future event. For example, \u201cWhat Euro-Dollar exchange rate date\u00a0X?\u201d. In several common forecasting scenarios, prediction markets been accurate polls, expert opinions, statistical methods1 therefore prediction models useful observers (anybody who interested outcome) just market\u2019s participants. Prediction markets categorical events (a specific event either does doesn\u2019t happen) scalar events (when outcome between range values). predefined source truth outcomes being predicted called an\u00a0Oracle. Prediction markets enables participants purchase shares tokens tied outcome specific future event. Once event occurred, holders tokens representing actual outcome receive reward predefined value. creates incentive hold tokens corresponding correct outcome, market dynamics supply demand allow price reflect perceived probabilities different outcomes. Helpfully, price token corresponds relative probability outcome occurring allows simple interpretation results. reward holding share corresponding correct outcome $1, present price share 50 cents, market\u2019s estimate likelihood outcome occurring is\u00a050%. Shares traded continuously. As trading occurs over probability different outcomes change information becomes known, changing price shares quantify\u00a0this. An\u00a0example Let\u2019s describe work an\u00a0example: There large degree uncertainty2 around Britain continue trade other European countries exits EU March 29, 2019. A prediction market likely better predictor outcome any other\u00a0method. adequate agreement isn\u2019t achieved, Britain\u2019s port Dover certainly experience long delays large traffic jams. Therefore prediction market asking \u201cHow vehicles admitted Britain port Dover between 00:00 23:59 March 29 2019?\u201d give useful prediction outcome Britain\u2019s trade negotiations - key component sticking point Each token prediction market correspond different quantities vehicles entering port3 - example there four (or more) categories; Less 8000, between 8000 11000, between 11000 14000, 14000. relative price share category correspond relative probabilities vehicles lower otherwise expected, (around 12000) likely due impact Brexit thus market serve useful proxy predicting kind Brexit will\u00a0occur. Stakeholder incentives are\u00a0aligned One reason prediction markets work well aggregate information disparate sources price shows impartial assessment most likely outcome aggregated level confidence participants have. Since no obliged participate, those believe valuable information gives them competitive advantage. creates mechanism moves good quality information prediction market, resulting prices reflecting probability range of\u00a0outcomes. In our example, people relevant information include port employees, business owners UK Europe, politicians, civil servants, business analysts, bankers, etc. Whilst clear any these roles may useful information judgement outcome, clear useful participants role relative others. By allowing participant bid shares different categories want, participant\u2019s confidence their information be\u00a0quantified. In way, prediction markets align incentives market participants observers. market large enough becomes prohibitively expensive distort market promote poor quality information, including information designed create FUD (Fear, Uncertainty, Doubt), fake news, Prediction markets nothing new, political betting being predictions early 1500s. However adoption internet decentralised networks now allow prediction markets widely cheaply ever before. Gnosis building platform Ethereum blockchain others build applications harness power By lowering cost complexity creating prediction market, observers benefit high quality impartial predictive information future events, market participants rewarded accurate assessments likely outcomes. enable better decision making empower observers previously unobtainable insight. In our example, market created funded any organisation benefit knowing results prediction market. port Dover itself, news organisations, market research firms. Any these businesses benefit K. J. Arrow, R. Forsythe, M. Gorham, R. Hahn, R. Hanson, J. O. Ledyard, S. Levmore, R. Litan, P. Milgrom, F. D. Nelson, G. R. Neumann, M. Ottaviani, T. C. Schelling, R. J. Shiller, V. L. Smith, E. Snowberg, C. R. Sunstein, P. C. Tetlock, P. E. Tetlock, H. R. Varian, J. Wolfers, E. Zitzewitz. promise prediction markets. Science, 320(5878), 2008.\u00a0\u21a9 For example Data","tag":"[, , , , ]","category":"Technical/Cryptocurrencies"},{"title":"What I\u2019m\u00a0reading","url":"reading.html","body":"Articles Mental models A comprehensive list organised around different disciplines. It long read probably most easy apply tangibly useful articles I\u2019ve read\u00a0recently. Life short - Is life actually short, always want time, no matter much could\u00a0have? Invisible asymptotes - A well written long look various facets Factors scratch - Investing: A unified framework explain factors\u00a0work. tragic - \u201c\u2026But think highlights potential disconnects between mental health & business, publicity & success, success & happiness. internet seem intimate ultimately it\u2019s thin view individual\u2019s Vim after 15\u00a0years Cryptocurrency regulations around the\u00a0world On 2008 financial crisis - \u201cI\u2019m sure it\u2019s possible action both necessary disaster, essence Podcasts Jill Carlson \u201cWhat Bitcoin Did\u201d podcast. \u201cFor first there no longer monopoly creation monetary systems, really What Bitcoin\u00a0Did.\u201d Georges St-Pierre Joe Rogan podcast. A long candid conversation world\u2019s best\u00a0athletes. Ricardo Spagni a.k.a Fluffypony Monero vs Bitcoin, EOS, current bear market, Tari, and\u00a0ASICs. Resources Lots data\u00a0sets","tag":"[]","category":"Non-technical/Family"},{"title":"Ry\u2019s Git\u00a0Tutorial","url":"rys-git-tutorial.html","body":"For tracking changes collection files, Git ubiquitous solution. It\u2019s free, robust, comprehensive, there plethora resources easy to\u00a0find. usually find commands difficult remember though, concepts Git built often seem me. means spend lot searching answers trying remember Git experiment project without fear losing any hard won\u00a0progress. Ry\u2019s Git Tutorial Ryan Hodson best way learn Git come across. Its simple, practical, clear. reader learns Git yy creating maintaining simple website. gives Git commands meaningful context, makes them lot easier remember the\u00a0future. tutorial first published 2012 website originally hosted examples no longer exists. Each tutorial chapter starts link download project files point, reader doesn\u2019t start beginning jump any part guide. Unfortunately these links dead\u00a0now. Therefore I\u2019m hosting tutorial here continues useful. author get touch, please do. I\u2019d keep great resource available others benefit from\u00a0it. Download .epub file here Download example files module\u00a0below: Chapter 2: Chapter 3: Branches\u00a0I Chapter 4: Branches II Chapter 5:\u00a0Rebasing Chapter 6: Chapter 7:\u00a0Remotes Chapter 8: Chapter 9: Chapter 10: Chapter 11: Tips &\u00a0Tricks Chapter 12:\u00a0Plumbing end","tag":"[, , , ]","category":"Technical/Developer Tools"},{"title":"Neighbours","url":"neighbours.html","body":"A useful model I\u2019ve come across states takes three generations society deny something previously considered true. first generation studies experiences something leads particular belief. second generation inherits belief assumes true, doesn\u2019t arrive belief through their own critical thought. third generation questions assumption, realises most holders belief good basis their belief, disregards\u00a0it. belief people responsibility look after other treat other minimum level respect seems following this\u00a0route. That humans inherently deserve degree respect dignity simply human self-evident. In times comfort excess ignored, times calamity aftermath disasters becomes undeniable obvious. partly disasters reveal our instinct justice our frailty face of\u00a0misfortune. Life experienced through lens mind, perception mostly governed fundamental circumstances desires. trappings prosperous society allows reality covered veneer soft arguments, rejected favor viewpoint says superseded these supposedly basic\u00a0origins. Good leaders should know better. They should study history self-aware. In past forgotten reality been forced relearn great cost. Are forget, again, our children live My grandfathers generation saw damage sectarian systems bring, were forced answer questions around much respect people deserve people. As consequences different views systems became evident, fathers generation assumed answers self-evident, consequences previous \u201cforgetting\u201d were still\u00a0clear. Who clearly articulating now? This\u00a0year? When discuss taxation, social mobility, migration, military intervention, why start assumed self-evident truth people inherently valuable important? Humans metrics, cannot entirely evaluated Horton, title character \u201cHorton Hears Who\u201d Dr. Zeus, understood this. He went great lengths protect tiny weak people who-ville. We teach truth our children, demonstrate adults. Jesus also understood it. He said should love our neighbours, explained our neighbours people come across who our\u00a0help. wonder forgetting humans inherently worthy respect prerequisite for\u00a0declining; standards of\u00a0governance peace Which makes me think self defeating deception. When choose disregard group humans inconvenient help them, elevating our needs above theirs. seems create chains events where","tag":"[, ]","category":"Non-technical/Family"},{"title":"How to buy\u00a0Bitcoin","url":"buying-btc.html","body":"Recently few friends asked me buy Bitcoin. I\u2019m financial advisor, here few things come to\u00a0mind: Don\u2019t invest can\u2019t afford to\u00a0lose. price falls 50%, able wait whilst Write down the\u00a0following: How much afford invest? Consider much cash over next year, long take recover any losses,\u00a0etc. How long want invest\u00a0for? How much profit want make? Don\u2019t You get good identifying ignoring following, even your\u00a0friends: Hype Fake\u00a0news Fear, Uncertainty, Doubt (FUD) Don\u2019t trust previous point really important, By putting something care risky situation (it risky) experience anxiety excitement. You control psychology identity other people trying manipulate you. useful areas of\u00a0life. Investing good mental exercise money intensely psychological quality it, crypto currencies most intense trading experience there right\u00a0now. Almost no clue what\u2019s happening. Conventional economists traders certainly don\u2019t. rules haven\u2019t been worked yet. We\u2019ve never had tech before, internet made everything - communication innovation - much quicker. powerful combination factors haven\u2019t seen them play out\u00a0before. Take read fundamentals understand tech much can. Think why people behave certain ways makes bitcoin useful, not. Get started today, take some\u00a0time. YouTube tonne videos, these two sites good detailed: lopp.net Twitter lot current information, also lot bots scammers spreading hype FUD (see point\u00a04). you\u2019re going lose sleep over investment, invest\u00a0less. Don\u2019t buy high. Do research, wait price correct. Prices fall. chart top page shows 20 day 55 day moving average compared daily price. My opinion early January price returned between 20 day 55 day average before beginning rise\u00a0again. Coinbase user friendly reputable exchange, there other good exchanges\u00a0too. Don\u2019t financial decisions you\u2019re feeling rushed. Check you\u2019ve bought Bitcoin other don\u2019t store them exchange. Transfer them wallet control. don\u2019t own private key, don\u2019t own asset. don\u2019t know means, google (Point\u00a08). Leave comment think I\u2019ve missed something you\u00a0disagree.","tag":"[]","category":"Technical/Cryptocurrencies"},{"title":"Live near the\u00a0ocean","url":"ocean.html","body":"California Dorset Acapulco Dublin","tag":"[]","category":"Non-technical/Family"},{"title":"Pangea","url":"pangea.html","body":"The\u00a0problem In countries ability create legally binding agreements available average citizens. Legal services often unaffordable opaque, service providers corrupt. Legal services of\u00a0disruption. The\u00a0solution Pangea Bitnation (who consult for) intends address problem empowering people self-organise self-govern. We building platform called Pangea allows users create, notarise arbitrate contracts according jurisdiction party joins voluntarily, irrespective their Pangea smart phone app looks feels chat app, back-end (called Panthalassa) encrypted mesh network hooked Rewarded doing good, empowered On Pangea, people incentivised good citizens receiving rewards doing good, rather being coerced threat punishment bad\u00a0behaviour. platform fulfil vast unmet need, particularly countries whose legal systems function poorly. On Pangea, user voluntarily chooses jurisdiction part of. Contracts notarised, executed arbitrated according jurisdiction. Users voluntarily join decentralised borderless voluntary nation (DBVN) receive tokens (Pangea Arbitration Tokens) reward good behaviour. tokens tradable payment Pangea notarisation Combining store access legal\u00a0services Societies cannot escape their currency stores value. They also cannot escape their create reliable enforceable agreements (contracts) each\u00a0other. Generating Bitcoin through proof work occurs individuals believe Bitcoin continuously \u2014 meet ongoing transact decentralised Generating PAT being good citizen occur individuals believe Pangea continuously \u2014 meet ongoing create enforceable agreements voluntary geographically agnostic (and Comments There much still say Pangea platform mechanisms function. Please give feedback ask questions comments. To find more, visit website.","tag":"[, ]","category":"Technical/Cryptocurrencies"},{"title":"Bitcoin compared to\u00a0gold","url":"bitcoin-vs-gold.html","body":"A safe haven asset something buy during economic uncertainty. Historically, safest asset buy been gold. anything inherently special gold, people believe best long term method storing\u00a0value. People believe gold special assume future other people believe it\u2019s\u00a0special. Criteria safe haven\u00a0asset A safe-haven asset fulfil Price isn\u2019t controlled any single party, including state bank. market spread beyond reach any organisation. important asset issued, controlled backed organisation tied health Supply isn\u2019t controlled any single party, including state, bank anyone else - exists naturally rate it\u2019s produced traded beyond control any Supply limited. effort required create asset naturally limits the\u00a0supply. asset doesn\u2019t wear or\u00a0expire. It\u2019s prohibitively expensive to\u00a0fake. Almost everyone considers precious and\u00a0valuable. It stored transported simply. It\u2019s delicate or\u00a0volatile. For these reasons, historical consensus, people been happy gold store times economic uncertainty long durations. Other assets also meets these requirements Bitcoin compared to\u00a0gold Consider why gold good safe haven asset long term store. For reasons above, bitcoin better, except one: At present, people consider precious valuable, market small. change confidence awareness increases, eco-system services fundamentals A decentralised network ensures Bitcoin can\u2019t regulated controlled single government organisation. network can\u2019t turned off or\u00a0controlled. present future rate supply publicly available inviolable. increases market efficiency creates rational pricing market where rate supply Supply naturally limited proof Bitcoin doesn\u2019t corrode wear\u00a0out. Bitcoin impossible to\u00a0fake. Bitcoin stored transported easily gold. - remember 24 words transport bitcoin effortlessly where ever you\u00a0go. Read\u00a0more article, published week after wrote post, looks different factors consider evaluating Bitcoin\u2019s value. It goes lot detail, relative I\u2019ve seen","tag":"[, , ]","category":"Technical/Cryptocurrencies"},{"title":"Hardware\u00a0Wallets","url":"wallet.html","body":"What A hardware wallet (HW wallet) physical device stores information required access digital currency assets. It plugged computer via USB order initiate confirm transactions Bitcoin, Ethereum other digital asset They secure method storing cryptographic data. They secure compromised computer. All needed access funds HW wallet (in addition device itself) PIN code user chooses. A single HW wallet store multiple currencies HW wallets easier solution remembering good password, safer storing file computer or\u00a0online. best known hardware wallet brands Ledger Trezor. The\u00a0problem HW wallets technically great, their size shape creates bad user experience. A good hardware wallet should convenient multiple times day, credit card\u00a0is. Current hardware wallets don\u2019t fit (money) wallet people don\u2019t want carry any objects their pockets. They too big bad\u00a0shape. HW wallets look might belong keyring, it\u2019s inconvenient insecure attach credit card keyring same true HW wallet. might store keys hook door, never leave wallet there overnight. often want keep keys money separate keys I\u2019m near house, where don\u2019t buy stuff, money I\u2019m away house where don\u2019t want keep bank cards cash together safe place, don\u2019t want carry around dongle well. It\u2019s easier separate dongle lost stolen something fit next credit card wallet. inconvenience barrier enjoying advantages The\u00a0goal Create HW wallet size shape credit card, 3 times thicker credit card still fit wallet. It\u00a0needs display - low resolution b&w\u00a0display two more\u00a0buttons plug USB\u00a0port securely sign transactions","tag":"[, , , ]","category":"Technical/Cryptocurrencies"},{"title":"Trading digital\u00a0assets","url":"algo-trading.html","body":"Table import data3\u00a0\u00a0Format data4\u00a0\u00a0Asset - \u00a34.2\u00a0\u00a0Ethereum - \u00a34.3\u00a0\u00a0Ethereum - - \u00a34.5\u00a0\u00a0Litecoin - BTC5\u00a0\u00a0SMA gains w/ different SMA through combination sma1 sma26\u00a0\u00a0Next steps: In\u00a0[1]: import HTML function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document </script> <font> analysis made Python. you'd see code used, click <a ''') Out[1]: function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document analysis made Python. you\u2019d see code used, click here. window.onload = function() { code_toggle(); }; notebook shows process investigating price history Bitcoin, Ethereum Litecoin Simple Moving noticed 7 day 30 day SMAs cross other occasionally, wondered profitable generate heat map show profitability varies across different pairs of\u00a0SMAs. For given SMA pair show trading algorithms performance between two\u00a0dates. Setup import data\u00b6Setup involves importing python packages required changing default notebook settings. Plotly figures rather simpler method visualising whilst creating notebook offline Plotly options. other visualisation packages I\u2019ll set figures appear below code cell called plot\u00a0command. price downloaded Quandl. In order keep Quandl Plot.ly credentials private, keep account credentials separate .py\u00a0file. Pickle package get_data() functions download Quandl once store locally .pkl file. quicker downloading every (re)run the\u00a0notebook. In\u00a0[2]: ## Setup - libraries %matplotlib inline import os import pickle import quandl import plt import pandas pd import datetime dt import numpy np import credentials # keep quandl plot.ly api keys private import plotly #import plotly.offline py import plotly.plotly py import go import ff #from import Axes3D exports, module) {/** * plotly.js v1.28.3 * Copyright 2012-2017, Plotly, Inc. * All rights reserved. * Licensed under MIT license */ t;return function a(o,!0);var u=new Error(\"Cannot find module i(t,e){return t.y-e.y}var r(t){return r(t){return u(){function t(t,e){return e(t,e){return c(t){return h(t){return t.value}var t(t){var \"+s+\",\"+c+\" \"+o+\",\"+u+\" e=.5;return n(t){var n=a(t,new e?e:1,r=r||\": \";var n(t,e){for(var r=new instanceof function y(t){var e}function b(t,e,r,n){var e)throw argument expected unwanted i}var r=new t};var e=[];for(var r n(t){for(var n(t){return n(t){var i=new e=t|t-1;return i}function l(t){for(var e=new e}function ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff ffffffff 00000000 00000000 ffffffff ffffffff fffffffe ffffffff t){var greater instanceof safely store 53 n(void array length 26;var e=t,r=0;return 0;for(var t&&t>=0);var t&&t>=0);var a(1);for(var t&&t>=0);var works positive a(0),mod:new a(0)};var i,o,s;return i=new a(1),o=new a(0),s=new a(0),l=new i=new a(1),o=new f;return A[t];var p;else m;else Error(\"Unknown prime \"+t);e=new g}return works works red works works red l}}}function s(t){return l(t,e){return 1:return s(t);case 3:return Invalid n(t,e,r){var \"+r);var n(t,e){var i=\"for(var i=n[t];return var P=C+1;PZ)throw typed array length\");var e=new e)throw Error(\"If encoding specified first argument l(t)}return t)throw argument instanceof t)throw argument allocate Buffer larger maximum size: bytes\");return 0|t}function instanceof 0;for(var 0:return v(t,e,r){var n=!1;if((void hex E(n)}function E(t){var access beyond buffer argument Buffer a}function U(t){for(var a}function H(t){return i}function Y(t){return t!==t}var t=new browser lacks typed array (Uint8Array) support required `buffer` v5.x. Use `buffer` v4.x require old browser 0;for(var ... range 0;for(var 0)}var write outside buffer encoding: Error(\"Invalid string. Length multiple i(t){return a(t){var o(t){return i(t,e){return a(t,e){for(var i(g,d,v,h),new n(t){var i(t,e){for(var r=new s}function m(t,e,r){var i=new n(t){var strict\";var t;var Error(f+\" map requires nshades least size i(t,e,r,i){var 0}return n(t,e){return t-e}function i(t,e){var 0:return 0;case 1:return t[0]-e[0];case 2:return 3:var i;var 4:var n(t){var t}function i(t){return a(t){return o(t){return null}var null;var a}return a}return i(t){var e=new i=0;i0)throw Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array args\")}else Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array index\")}else Error(\"cwise: Too arguments pre() Error(\"cwise: Too arguments body() Error(\"cwise: Too arguments post() block\");return n(t,e,r){var l(t,e){for(var w=new cwise routine n(t){var e=[\"'use strict'\",\"var function (!(\"+l.join(\" && \")+\")) throw Error('cwise: Arrays same {\"),e.push(\"if (!(\"+u.join(\" && \")+\")) throw Error('cwise: Arrays same i(t,e,r){var m,v=new t;var e=[];for(var r e=[];for(var r e=[];for(var r n&&void e(t,e){var r}function r(){}function n(t){var e;return y(t){return b(t){return Error(\"unknown type: i(t,e){for(var r,n,i=new i(){if(s){var t(t){var r(t){var Array(o),l=new this;var 1:do{o=new 2:do{o=new 3:do{o=new t=[];return s(){var l(){for(var a(t){return n}}}function l(t){return u(t){for(var e}function c(t,e){for(var r p(t){return f(t)in this._&&delete v(){var t=[];for(var e t}function g(){var t=0;for(var e t}function y(){for(var x(t){return t}function function(){var w(t,e){if(e t)return Z(t,e){return J(t,e){var K(t){var vt(t){return gt(t){return yt(t){return _t(t){return wt(t){return kt(t,e,r){var Ot(){for(var t}function Ft(){for(var Nt(t){var b=u&&h;return Bt(t){return t+\"\"}function n(e){var e}function Gt(t,e,r){var le(t){var ce(t){for(var ge(t){var ye(t,e){return we(t){var ke(t,e){return y}}function Fe(t){return Re(){var r=e;return r(t){var a(t,e){return o(t,e){var l(t){for(var c(i,a){return Je(){function s}function 1,1 1,1 $e(){function t(t,n){var er(){function t(t,e){var rr(t){function s}function nr(t){function r(e){return n(e){function a(r,n){var k}function ir(t){var sr(t){return t})()}function lr(t){function e(t){return i(){return ur(t){return r(t,e){var Vr(t,e){var n;var s;var Hr(t,e){var Vr(r,e);var Gr(t){for(var r}function wn(t,e){var kn(t){return An(t){return 1;var Zn(t,e){var n}function bi(t){return xi(t,e){return _i(t,e){return Ei(t){function Ni(t){return t.y})}function Bi(t){return Ui(t){var Vi(t){var qi(t,e){var a(t){return o(t)}var o,s;return Qi(t,e){return $i(t,e){return a(t){return o(e){return t(i(e))}return _a(t){function e(e){function Ma(t){return ka(t){for(var Aa(t){for(var p[n]:delete t[r],1}var io(t){return n(e){return t(e)}function i(t,r){var r};var t;var e=new b;if(t)for(var h(){function f(){function t(){var r(){var n(){var o;if(i)return i=!1,a;var e=new ms={\"-\":\"\",_:\" %b %e %X this.s}};var bs=new e(e,r){var t(){var e(){return }var t(e,r,n,i){var c}function e(t){for(var r}function t(t,a){var t(t,e){for(var i(t,e,r,n){var \"+e}function 0,0 \"+n}var t(t,i){var \"+l[2]+\" \"+l[3]}var 0,\"+e+\" \"+e+\",\"+e+\" a(){function v(){var l;var t;e||(e=t);var e}function s(t){var l(t,e,r,n){var u(t,e,r){var n=t;do{var n}function l=t;do{for(var h(t,e,r,n){var r}function m(t,e,r,n){var v(t){var t}function x(t,e){return w(t,e){return k(t,e){var A(t,e){return n(t,e){var e){e=0;for(var warning: possible EventEmitter memory leak detected. %d listeners added. Use increase function\");var n=!1;return e=typeof o(t,e,r,n){var \"+i+\"=== typeof s(t,e){return e.length> 1; (a[m] === v) true; (a[m] > v) j = m - 1; else i = m + 1;}return false; }(\"+n+\", u(t){return p\"}function h(t,e){return c[1]){var s[e][t];var i(t){return a(t,e){return r}var 0)}function d(t){for(var m(t){return t=[];return t=[];return 1:return 2:return this.tree;var e=new i=0;i0)return Error(\"Can't update empty node!\");var r=new s(t){for(var z%d-%d-%d (features: %d, points: %d, simplified: down parent tile down\");var i(t,e,r){var s}function i(t,e,r,n){var s(t,e){var r=new i(t);return e(e,r,n){if(n t){var U=g,V=_,k=0;k 0.0) {\\n nPosition = mix(bounds[0], bounds[1], 0.5 * (position + 1.0));\\n gl_Position = projection * view * model * 1.0);\\n } else {\\n gl_Position = }\\n colorChannel = GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = colorChannel.x * colors[0] + \\n colorChannel.y * colors[1] +\\n colorChannel.z * vectorizing d=new o(t,e,r,n){var s;var r}function a(t,e){for(var r=0;rr)throw resizing buffer, specify a(t,e){for(var Invalid webgl buffer, either Invalid usage buffer, either gl.STATIC_DRAW t&&void Cannot specify offset resizing Error(\"gl-fbo: Can't resize FBO, invalid Error(\"gl-fbo: Parameters too large Error(\"gl-fbo: Multiple draw buffer extension Error(\"gl-fbo: Context does support \"+s+\" draw buffers\")}}var Error(\"gl-fbo: Context does support floating point h=!0;\"depth\"in Error(\"gl-fbo: Shape vector length 2\");var null;var 0.25) {\\n discard;\\n }\\n gl_FragColor = GLSLIFY 1\\n\\nattribute aHi, aLo, pick0, scaleHi, translateHi, scaleLo, translateLo, pickA, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n = width * * vec2(dHi.y, -dHi.x)) / gl_Position = vec4(p + n, 0, 1);\\n pickA = pick0;\\n pickB = GLSLIFY 1\\n\\nuniform pickA, pickB;\\n\\nvoid main() {\\n fragId = 0.0);\\n if(pickB.w > pickA.w) {\\n fragId.xyz = pickB.xyz;\\n }\\n\\n fragId += fragId.y += floor(fragId.x / 256.0);\\n fragId.x -= floor(fragId.x / 256.0) * 256.0;\\n\\n fragId.z += floor(fragId.y / 256.0);\\n fragId.y -= floor(fragId.y / 256.0) * 256.0;\\n\\n fragId.w += floor(fragId.z / 256.0);\\n fragId.z -= floor(fragId.z / 256.0) * 256.0;\\n\\n gl_FragColor = fragId / GLSLIFY 1\\n\\nattribute aHi, aLo, scaleHi, translateHi, scaleLo, translateLo, projectValue, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n if(dHi.y e+n;var null;var FLOAT_MAX) {\\n vec4(127.0, 128.0, 0.0, 0.0) / 255.0;\\n } else if(v \"+t[1]+\", \"+t[2]+\", t=new e=new r=new \"+t[1]+\", n=\"precision GLSLIFY 1\\n\\nuniform f_id;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n gl_FragColor = vec4(pickId, GLSLIFY 1\\n\\nattribute position, uv;\\n\\nuniform model\\n , view\\n , eyePosition\\n , f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n m_position = model * vec4(position, 1.0);\\n t_position = view * m_position;\\n gl_Position = projection * t_position;\\n f_color = color;\\n f_normal = normal;\\n f_data = position;\\n f_eyeDirection = eyePosition - position;\\n = lightPosition - position;\\n f_uv = GLSLIFY 1\\n\\nfloat x, roughness) {\\n NdotH = max(x, 0.0001);\\n cos2Alpha = NdotH * NdotH;\\n tan2Alpha = (cos2Alpha - 1.0) / cos2Alpha;\\n roughness2 = roughness * roughness;\\n denom = * roughness2 * cos2Alpha * cos2Alpha;\\n exp(tan2Alpha / roughness2) / roughness,\\n fresnel) {\\n\\n VdotN = 0.0);\\n LdotN = 0.0);\\n\\n //Half angle vector\\n H = + //Geometric term\\n NdotH = H), 0.0);\\n VdotH = H), 0.000001);\\n LdotH = H), 0.000001);\\n G1 = (2.0 * NdotH * VdotN) / VdotH;\\n G2 = (2.0 * NdotH * LdotN) / LdotH;\\n G = min(1.0, min(G1, G2));\\n \\n //Distribution term\\n D = //Fresnel term\\n F = pow(1.0 - VdotN, fresnel);\\n\\n //Multiply terms done\\n G * F * D / max(3.14159265 * VdotN, roughness\\n , fresnel\\n , kambient\\n , kdiffuse\\n , kspecular\\n , sampler2D f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n N = L = V = \\n {\\n N = -N;\\n }\\n\\n specular = V, N, roughness, fresnel);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n surfaceColor = f_color * f_uv);\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = litColor * GLSLIFY 1\\n\\nattribute uv;\\n\\nuniform model, view, f_uv;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_color = color;\\n f_data = position;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute uv;\\nattribute model, view, f_uv;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n }\\n gl_PointSize = pointSize;\\n f_color = color;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n pointR = - if(dot(pointR, pointR) > 0.25) {\\n discard;\\n }\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n gl_PointSize = pointSize;\\n }\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute model, view, main() {\\n gl_Position = projection * view * model * vec4(position, GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = i(t){for(var null;for(var function(){var E=new s(\"\",\"Invalid attribute \"+h+\": s(\"\",\"Unknown attribute \"+h+\": \"+f);var s(\"\",\"Invalid attribute \"+h+\": n(t){return i(t,e){for(var r=new s(\"\",\"Invalid uniform dimension matrix \"+name+\": s(\"\",\"Unknown uniform \"+name+\": \"+r)}var s(\"\",\"Invalid vector \"+name+\": r=[];for(var e){var r}function h(e){for(var n=[\"return function s(\"\",\"Invalid s(\"\",\"Invalid uniform dimension matrix \"+name+\": \"+t);return i(r*r,0)}throw s(\"\",\"Unknown uniform \"+name+\": \"+t)}}function i){var p(t){var r=0;r1){l[0]in u=1;u1)for(var l=0;l=0){var t||t}function s(t){function r(){for(var u=0;u 1.0) {\\n discard;\\n }\\n baseColor = color, step(radius, gl_FragColor = * baseColor.a, GLSLIFY 1\\n\\nattribute mat3 main() {\\n hgPosition = matrix * vec3(position, 1);\\n gl_Position = 0, gl_PointSize = pointSize;\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var instanceof instanceof null;var n(t,e,r,n){var GLSLIFY 1\\n\\n\\nvec4 posHi, posLo, scHi, scLo, trHi, trLo) {\\n vec4((posHi + trHi) * scHi\\n \\t\\t\\t//FIXME: thingy does give noticeable precision gain, test\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * scLo\\n , 0, positionHi, size, char, 64-bit form scale scaleHi, scaleLo, translateHi, sampler2D charColor, main() {\\n charColor = vec2(color.x / 255., 0));\\n borderColor = vec2(color.y / 255., 0));\\n\\n gl_PointSize = size * pixelRatio;\\n pointSize = size * charId = char;\\n borderWidth = border;\\n\\n gl_Position = positionHi, positionLo,\\n scaleHi, scaleLo,\\n translateHi, pointCoord = viewBox.xy + (viewBox.zw - viewBox.xy) * * .5 + GLSLIFY 1\\n\\nuniform sampler2D charsStep, pixelRatio, main() {\\n\\tvec2 pointUV = (pointCoord - + pointSize * .5) / = 1. - texCoord = ((charId + pointUV) * charsStep) / dist = alpha\\n\\tif (dist t;){var w.push(new i(){var a(t,e){var e=void null;var characters maximum texture size. Try reducing x=0;x 1.0) {\\n discard;\\n }\\n baseColor = color, alpha = 1.0 - pow(1.0 - baseColor.a, fragWeight);\\n gl_FragColor = * alpha, GLSLIFY 1\\n\\nvec4 pfx_1_0(vec2 scaleHi, scaleLo, translateHi, translateLo, positionHi, positionLo) {\\n + translateHi) * scaleHi\\n + (positionLo + translateLo) * scaleHi\\n + (positionHi + translateHi) * scaleLo\\n + (positionLo + translateLo) * scaleLo, 0.0, positionHi, scaleHi, scaleLo, translateHi, main() {\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n gl_Position = scaleLo, translateHi, translateLo, positionHi, positionLo);\\n gl_PointSize = pointSize;\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var e(e,r){return e n(t,e){var r)return r[t];for(var o=r.gl d(t){var null;var a(t,e){return E=new i(t,e){var r=new n(t);return 0.0 ||\\n || {\\n discard;\\n }\\n\\n N = V = L = {\\n N = -N;\\n }\\n\\n specular = V, N, roughness);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n //decide interpolate \\u2014 vertex fragment\\n surfaceColor = .5) * vec2(value, value)) + step(.5, vertexColor) * vColor;\\n\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = mix(litColor, contourColor, contourTint) * GLSLIFY 1\\n\\nattribute uv;\\nattribute f;\\n\\nuniform mat3 model, view, height, sampler2D value, kill;\\nvarying eyeDirection, main() {\\n dataCoordinate = permutation * vec3(uv.xy, height);\\n worldPosition = model * 1.0);\\n\\n clipPosition = projection * view * clipPosition.z = clipPosition.z + zOffset;\\n\\n gl_Position = = f;\\n kill = -1.0;\\n = = uv.zw;\\n\\n vColor = vec2(value, value));\\n\\n //Don't lighting contours\\n surfaceNormal = vec3(1,0,0);\\n eyeDirection = vec3(0,1,0);\\n lightDirection = GLSLIFY 1\\n\\nuniform value, kill;\\nvarying v) {\\n vh = 255.0 * v;\\n upper = floor(vh);\\n lower = fract(vh);\\n vec2(upper / 255.0, floor(lower * 16.0) / main() {\\n if(kill > 0.0 ||\\n || {\\n discard;\\n }\\n ux = / shape.x);\\n uy = / shape.y);\\n gl_FragColor = vec4(pickId, ux.x, uy.x, ux.y + i(t){var o(t,e){var invalid coordinates Invalid texture size\");return s(t,e){return Invalid ndarray, 2d 3d\");var Invalid shape Invalid shape pixel Incompatible texture format Invalid texture Floating point textures supported platform\");var s=u(t);return s=u(t);return f(t,e){var Invalid texture size\");var Invalid shape Invalid shape pixel b=u(t);return Error(\"gl-vao: Too vertex n(t,e,r){var i=new n(t){for(var n(t,e){var n(t,e,r){var instanceof a=new a(t,e){return o(t){for(var e=[\"function orient(){var orient\");var n=new a(t,e){var o(t,e){var s(t,e){var i}}function c(t,e){for(var s(this,t);var s(this,t);var b}for(var r}return n}return l}function i(t,e,r,n){var n(t,e){var r;if(h(t)){var Error('Unknown function -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n x_a = / 1.0);\\n x_b = / 1.0);\\n y_a = 0.5 + (v_normal.y * v_linewidth.s / y_b = 0.5 + (v_normal.y * v_linewidth.s / pos_a = vec2(x_a, y_a));\\n pos_b = vec2(x_b, y_b));\\n\\n = pos_a), pos_b), u_fade);\\n\\n alpha *= u_opacity;\\n\\n gl_FragColor = * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n v_linesofar = // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n sdfdist_a = v_tex_a).a;\\n sdfdist_b = v_tex_b).a;\\n sdfdist = mix(sdfdist_a, sdfdist_b, u_mix);\\n alpha *= smoothstep(0.5 - u_sdfgamma, 0.5 + u_sdfgamma, sdfdist);\\n\\n gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n v_tex_a = * normal.y * + u_tex_y_a);\\n v_tex_b = * normal.y * + // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define mapbox: define mapbox: define v_pos;\\n\\nvoid main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n dist = length(v_pos - alpha = 0.0, dist);\\n gl_FragColor = outline_color * (alpha * gl_FragColor = lowp\\n#define mapbox: define mapbox: define main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D v_pos;\\n\\nvoid main() {\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n // find distance outline alpha dist = length(v_pos - alpha = 0.0, dist);\\n \\n\\n gl_FragColor = mix(color1, color2, u_mix) * alpha * gl_FragColor = lowp\\n#define v_pos;\\n\\nvoid main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D main() {\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n gl_FragColor = mix(color1, color2, u_mix) * gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / lowp\\n#define sampler2D sampler2D main() {\\n\\n // read cross-fade colors parent tiles\\n color0 = v_pos0);\\n color1 = v_pos1);\\n = color0 * u_opacity0 + color1 * u_opacity1;\\n rgb = color.rgb;\\n\\n // spin\\n rgb = vec3(\\n dot(rgb, dot(rgb, dot(rgb, // saturation\\n average = (color.r + color.g + color.b) / 3.0;\\n rgb += (average - rgb) * // contrast\\n rgb = (rgb - 0.5) * + 0.5;\\n\\n // brightness\\n u_high_vec = u_low_vec = gl_FragColor = u_low_vec, rgb), gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos0 = / 32767.0) - 0.5) / u_buffer_scale ) + 0.5;\\n v_pos1 = (v_pos0 * + lowp\\n#define sampler2D sampler2D main() {\\n alpha = v_fade_tex).a * u_opacity;\\n gl_FragColor = v_tex) * gl_FragColor = lowp\\n#define matrix vertex bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n extrude = * (a_offset / 64.0);\\n {\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * } else {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define sampler2D sampler2D main() {\\n dist = v_tex).a;\\n fade_alpha = gamma = u_gamma * alpha = - gamma, u_buffer + gamma, dist) * gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define PI = matrix vertex bool bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n // map\\n // map | viewport\\n {\\n angle = ? (a_data[1] / 256.0 * 2.0 * PI) : u_bearing;\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, asin, -1.0 * asin, acos);\\n offset = RotationMatrix * a_offset;\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * // viewport\\n // map\\n } else {\\n // foreshortening factor apply pitched maps\\n // label goes horizontal vertical angle\\n // goes 0% foreshortening around 70% pitchfactor = 1.0 - cos(u_pitch * sin(u_pitch * 0.75));\\n\\n lineangle = a_data[1] / 256.0 * 2.0 * PI;\\n\\n // lineangle position points a,b along line\\n // project points calculate label angle projected space\\n // calculation allows labels rendered unskewed pitched maps\\n = u_matrix * vec4(a_pos, 0, 1);\\n b = u_matrix * vec4(a_pos + 0, 1);\\n angle = - b[0]/b[3] - a[0]/a[3]);\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, -1.0 * asin, asin, acos);\\n\\n offset = RotationMatrix * 1.0) * a_offset);\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n gl_Position.z += z * // viewport\\n // viewport\\n } else {\\n extrude = * (a_offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_gamma_scale = (gl_Position.w - 0.5);\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define main() {\\n\\n alpha = 0.5;\\n\\n gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0) * alpha;\\n\\n > u_zoom) {\\n gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0) * alpha;\\n }\\n\\n (u_zoom >= v_max_zoom) {\\n gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0) * alpha * 0.25;\\n }\\n\\n >= u_maxzoom) {\\n gl_FragColor = vec4(0.0, 0.0, 1.0, 1.0) * alpha * 0.2;\\n lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos + a_extrude / u_scale, 0.0, 1.0);\\n\\n v_max_zoom = a_data.x;\\n = values, const t) {\\n (t 7)return[new been deprecated v8\")];if(!(l \"%s\" strict\";var a(l,e,\"array expected, %s a(l,e,\"array length %d expected, length %d r?[new been deprecated v8\")]:[];var n(e,r,\"object expected, %s found\",a)];var o=[];for(var s start \"@\"'));return strict\";var [%s], %s strict\";var t(e){var n(l,s,\"array expected, %s n(l,s,'\"$type\" cannot operator n(l,s,'filter array operator \"%s\" 3 expected, %s key cannot functions functions strict\";var url include \"{fontstack}\" url include \"{range}\" strict\";var n(c,r,'either \"type\" \"ref\" i(e,r,\"%s greater maximum strict\";var n(e,r,\"object expected, %s f r){var property n(e,r,'missing required property strict\";var i(e,o,'unknown property strict\";var n(r,e,'\"type\" e)for(var c a(t){return Sans Unicode MS M=new n){for(var symbols being rendered tile. See glyphs being rendered tile. See exceeds allowed extent, reduce vector tile buffer size\")}return Error(\"Invalid LngLat object: (\"+t+\", x(){return y(){return point(){return instanceof 0===s&&void a(void Error(\"failed invert strict\";var n={\" strict\";var s(t){return l(t,e,r,n){var o=(new n(t,e){return mapbox: ([\\w]+) ([\\w]+) ([\\w]+) a=new n?e(new Error(\"Input valid GeoJSON t.data)return e(new Error(\"Input valid GeoJSON e(new Error(\"Input valid GeoJSON e=0;ee)){var y;for(y p)c[y]=!0;var i(t,e,i){var r(t,r){return delete e(t);var n=new o(new e=new tile source layer \"'+M+'\" does vector tile spec v2 therefore may rendering g(t,L);var F B n=new t.time>=(new t=new i;var strict\";var Error(\"Invalid o[e]}throw Error(\"Invalid r Error('Source layer does exist source \"'+e.id+'\" specified style layer t.id});for(var Error(\"Style done Error(\"There no source ID\");var delete instanceof this;var 0===e)throw Error(\"There no layer ID\");for(var r this;var 0===i||void 0===a?void strict\";var i(t){return t.value}var r,n;for(var i t){var for(n 0===e)delete 0===e)delete o}var strict\";var t){var this.grid=new a}if(r){var _=u;for(var a}}}return r=new r(\"glyphs > 65535 i=!t&&new l(new c(new g(e,r){var y(e,r){var i(0,0));return M a)t[M]=new strict\";var t){var | n(){}var i(t){return 61:case 107:case 171:case 189:case 109:case t=0,e=0;return t=new null!==t&&void Error(\"maxZoom between current minZoom 20, t,e={};return instanceof e;if(t instanceof instanceof c?t:new i(this,e);var Error(\"Failed initialize s if(void if(void n(t){var r=new n(t){for(var e=0;e1)for(var delete error c(t,e,r){var f(t,e){for(var null;var delete Error(\"An API access token required Mapbox GL. See Error(\"Use public access token (pk.*) Mapbox GL JS, secret access token (sk.*). See t}function i(t){return a(t){return t;var n(t){function v[n];void t=0;t=1)return 1;var t={};for(var e =0.22.0 =0.22.0 No README run build-docs # invoked publisher publishing docs mb-pages --debug --standalone mapboxgl > && tap --no-coverage build --github --format html -c --theme ./docs/_theme --output --debug -t unassertify --plugin [minifyify --map --output --standalone mapboxgl > && tap --no-coverage --debug -t envify > --ignore-path .gitignore js test bench diff --name-only mb-pages HEAD -- | awk '{print | xargs build-token watch-dev watch-bench build-token watch-bench build-token watch-dev run build-min && npm run build-docs && jekyll serve --no-cache --localhost --port 9966 --index index.html .\",test:\"npm run lint && tap --reporter dot test/js/*/*.js && node && watchify bench/index.js --plugin [minifyify --no-map] -t [babelify --presets react] -t unassertify -t envify -o bench/bench.js --debug --standalone mapboxgl -o n=new r=new r(t){var n(t,n){var i(t){return t)return t){var 1=0)return V=1;V specify vertex creation specify cell creation specify phase strict\";var n(t){if(t l)return l[t];for(var Invalid boundary dst;};return l){var u){var c){var \"+s),u){var p=new p=new p()}function for(var o=0;o1)for(var f(e,r){var s=\"__l\"+ i=\"__l\"+ _=[\"'use L=new L=new L(r)}function s(t,e){var r=[\"'use [2,1,0];}else [1,0,2];}}else [2,0,1];}else function o=new 0===t){var 0===r){r=new o(t,e){var s(t,e){return a(t,e){var i=new t||\"up\"in strict\";var r=void 0!==r?r+\"\":\" e(t,e){for(var t}function o)throw path.resolve t)throw path.join n(t){for(var Error(\"Given varint doesn't fit bytes\");var o(t,e,r){var s(t,e){for(var type: n(t){var 0:return r||[];case 1:return 2:return Array(t);var r}var r(t,e){var Array(a),new n(t,e){for(var a(t){for(var t-e});var instanceof i(t){return a(t){for(var a=1;i;){var l(t){for(var c(t){return d(t){var u(m)}function p(t){var 0x80 (not basic code x});else for(_ n(t,e){return o;var o};var n(t,e){for(var n&&void e(t){var e=new Error(\"(regl) \"+t);throw n(t){return t?\": i(t,r,i){t r||e(\"unknown parameter possible values: parameter type\"+n(r)+\". typed parameter type\"+n(i)+\". expected \"+r+\", got \"+typeof t)}function parameter type, nonnegative shader source string\",a);var \"+t+\": r=0;e(c(\"| compiling \"+s+\" shader, linking program vertex shader, fragment shader i(t){return M(t,r){var n=m();e(t+\" command called \"+n))}function A(t,e,r,i){t e||M(\"unknown parameter possible values: parameter type\"+n(r)+\". expected \"+e+\", got \"+typeof texture format renderbuffer format L(t,e){return z(t,e,n){var pixel arguments document,\"must manually specify webgl context outside DOM supported, try upgrading browser graphics drivers name string\");var $(t){var et(t,e){var _e:r=new we:r=new Me:r=new ke:r=new Ae:r=new Te:r=new Se:r=new null}return n=0;n0){var t[0]){var buffer data\")}else shape\");var buffer p=new n(a);return d=[];return t=0;return t&&t._buffer instanceof a(t){var e||(e=new Ge:case Xe:case Ze:case element bit element buffers supported, enable first\");var vertex count buffer a}var t&&t._elements instanceof pt(t){for(var At(t){return Tt(t,e){var Or:case Fr:case Rr:case jr:var texture type, specify typed St(t,e){return for(var s}return o*r*n}function texture texture unpack n){var enable extension order floating point enable extension order 16-bit floating point enable extension order depth/stencil texture extension extension d(e,r,i){var m(){return K.pop()||new h}function y(t,e,r){var b(t,e){var e){var e){var e){var e){var e){var i(t,e){var arguments format c=new T(nr);return format C=new z=new I(){for(var for(var P={\"don't care\":$r,\"dont mipmap mipmap mipmap mipmap s3tc dxt1\":Mr,\"rgba s3tc dxt1\":kr,\"rgba s3tc dxt3\":Ar,\"rgba s3tc atc\":Sr,\"rgba atc explicit atc interpolated pvrtc pvrtc pvrtc pvrtc etc1\"]=Pr);var r=B[e];return null});return texture shape z||\"colors\"in render targets buffer enable order floating point framebuffer enable order 16-bit floating point framebuffer enable 16-bit render enable order 32-bit floating point format format extension u=d=1;var for(D=new attachment \"+a+\" attachments much same bits per depth attachment framebuffer stencil attachment framebuffer depth-stencil attachment framebuffer resize framebuffer currently use\");var i;for(var shape framebuffer d||\"colors\"in render targets buffer format l=1;var a(t){var t=0;return vertex fragment shader\",n);var a=i[t];return a||(a=new o(o){var create webgl context order read pixels drawing cannot read framebuffer allowed types 'uint8' framebuffer allowed 'uint8'\"));var arguments buffer regl.read() too s(t){var r;return l(t){return l}function jt(t){return Nt(t){return Bt(){function t(t){for(var r(){function n(){var e=a();return n(){var m(t){return v(t,e,r){var g(t,e,r){var y(){var ei:var ri:return ni:return ii:return ai:return c={};return n=e.id(t);if(n c)return c[n];var b(t){var r){var if(Di n){var e}function x(t,e){var r){var i=r[Pi];return framebuffer n){var a=n[Pi];return framebuffer null}function n(t){if(t i){var a){var \"+t)});var e?new s=o;o=new w(t){function r(t){if(t i){var r});return n.id=r,n}if(t a){var o=a[t];return null}var r(t,r){if(t n){var i){var s=i[t];return n){var i){var o=i[Ri];return n){var t=n[ji];return Be[t]})}if(ji i){var r=i[ji];return \"+n,\"invalid primitive, Aa}):new n){var vertex t})}if(Ni i){var r=i[Ni];return vertex s?new vertex offset/element buffer too l=new k(t,e){var o(e,n){if(t r){var o})}else if(t i){var vi:case si:case oi:case Ai:case hi:case Ci:case xi:case wi:case Mi:case pi:return flag fi:return \"+i,\"invalid \"+t+\", di:return attachment framebuffer sent uniform uniform a[r],\"invalid uniform missing uniform T(t,r){var a&&a,\"invalid attribute offset attribute divisor attribute parameter \"'+r+'\" attribute pointer \"'+t+'\" (valid parameters r)return r[s];var '+a+\"&&(typeof dynamic attribute if(\"constant\" \"+a+'.constant === S(t){var a(t){var parameter L(t,e,r){var C(t,e,r,n){var z(t,e,r){var n=m(e);if(!(n r.state)){var c,h;if(n I(t,e,r,n){var if(mt(u)){var l(t){var ua:case da:case ga:return 2;case ca:case pa:case ya:return 3;case ha:case ma:case ba:return 1}}function attribute i(i){var a=c[i];return a(){function o(){function vertex vertex vertex i(t){return n(e){var n=r.draw[e] s(t){function e(t){var args args e(t){if(t r){var e=r[t];delete delete l(t,e){var regl.clear no buffer takes object cancel frame callback h(){var callback function\");var event, Kt={\"[object renderbuffer renderbuffer arguments renderbuffer r(){return i(t){var s(){return p.pop()||new o}function u(t,e,r){var c(){var t(){var requires least argument; got none.\");var e.href;var \",e);var s=new o;n=-(i+a)}var null;var n(t){return n(t){for(var R;};return i(t){var e=s[t];return strict\";\"use n(t){for(var i}function h(t,e){for(var r=new r}function r=new l(e)}function u(t){for(var e=s(t);;){var t=k[0];return f(t,e){var r=k[t];return n(t,e){var l}else if(u)return l}else if(u)return u;return i(t,e){return t.y-e}function a(t,e){for(var r=null;t;){var t;var r}function l(t){for(var n=d.index;else n(t,e){var i(t,e,r,n){var o(t,e){for(var r}function s(t,e){for(var m}function s[t];for(var unexpected failed parse named argument failed parse named argument mixing positional named placeholders (yet) s[t]=n}var n(t){for(var Array(e),n=new Array(e),i=new Array(e),a=new Array(e),o=new Array(e),s=new x=new u(t){return c(t){var h(t){return f(t){var d(t,e){for(var r t}function p(t){return t.x}function m(t){return t.y}var time\");var r=\"prepare \"+t.length+\" %d clusters c)|0 p=new Array(r),m=new Array(r),v=new Array(r),g=new p=new o}function s}function T(t){return n=z(t);return t){var r={};for(var i e={};for(var r n(t,e){var i(t,e){var s/6}return 1}var n&&void e(t,e){var for(a=0,n=new n})}}var s;var Error(\"n Error(\"already s(t){return l(t){return u(t){return c(t){return h(t){return f(t){return d(t){return p(t){return m(t){return x?new v(t){return n(t)}var null}return t=0;tn)return instanceof n)return t;var i=new n;return a(t){return instanceof o(t,e){return s(t,e){return 'url' string, \"+typeof t);var i(t,e){var a(t,e){var o(t,e){return t}function s(t){var e={};return a;var v=e.name?\": c(e)}var o+\": \"+s}function d(t,e,r){var n=0;return \")+\" \"+t.join(\",\\n \")+\" \"+t.join(\", \")+\" p(t){return t}function v(t){return g(t){return t}function t}function t}function _(t){return 0===t}function w(t){return M(t)&&\"[object k(t){return M(t)&&\"[object A(t){return instanceof t}function S(t){return t||void 0===t}function E(t){return L(t){return t=a)return Error(\"unknown command if(7!==r)throw Error(\"unknown command i(t){for(var e}var Error(\"feature index String too long (sorry, get fixed later)\");var l(t){for(var e(t){var e=n(t);return e?u r(t,e){var o(t){var i?u i&&delete t){var r?r[0]:\"\"}var n?!r&&en)throw al-ahad\",\"Yawm {0} {0} {0} {0} mix {0} {1} a(t,e){return ;var format date another position name position literal position text found dd M MM d, d M d M d M d M yyyy\",RSS:\"D, d M a=this;return var _inline_1_da = - var _inline_1_db = - >= 0) !== (_inline_1_db >= 0)) {\\n + 0.5 + 0.5 * (_inline_1_da + _inline_1_db) / (_inline_1_da - }\\n n(t,e){var r=[];return strict\";var u(r,i){return i(t,e){var E.remove();var null;var strict\";var c();var t}function i(t){var e=x[t];return a(t){return calendar system `\"+t+\"` date data.\"}var i={};return t}var i?\"rgba(\"+s+\", n=i(t);return t){var A(e,r){var T(){var strict\";var strict\";var strict\";var strict\";var strict\";var strict\";var n(){var e(e){return r;try{r=new strict\";var i(t,e,r,n){var a(t){var n.remove();var \")}).split(\" \")}).split(\" scale(\"+e+\", n,i,a;return strict\";var 1,1 0,1 \"+a+\",\"+a+\" \"+a+\",\"+a+\" \"+r+\",\"+r+\" \"+r+\",\"+r+\" 1,1 0,1 1,1 0,1 n(t,e,r,n){var t.id});var strict\";var strict\";var i(t,e,r){var r(t){var r.remove();var r(e,r,o){var if(i[r]){var o;if(void strict\";var n(t){var n(r){return strict\";var n(t){for(var \");var i(t,e){var click legend isolate individual l(t){var u(t){var strict\";var r[1]}return i}function i(t){return t[0]}var h(t){var f(t){var d(t){var n(t,e){var i(t){for(var n(t){for(var 0}}var o(t,e){var 1,1 0,1 extra params segment t(e).replace(\" strict\";var strict\";var u(r,i){return r(t,e){return l(t,e,r){var u(t,e,r){var c(t,e){var n(){return p(t,e){var g(t,e){return y(t,e){return b(t,e,r){var x(t,e){var _(t){for(var r(t,e){return strict\";var strict\";var strict\";var t){var t)return n}function l(t){return u(t){return c(t){return d\")}function h(t){return d, yyyy\")}var t.getTime};var r={};return n=new a(t){return o(t){for(var r={};return n(){return strict\";var for(var c(t){return property r(t,e){var instanceof RegExp){var o(t,e){return t>=e}var binary r=e%1;return n(t){var e=i(t);return n(t,e){return i(t){return \")}function a(t,e,r){var error tex null;var r=0;r1)for(var i=1;i doesnt match end tag . Pretending did s}function c(t,e,r){var o(),void e();var 0,\":\"],k=new t(t,e){return n(t){var i(){var 1px strict\";var strict\";var n(t,e){for(var r=new Error(\"No DOM element id '\"+t+\"' exists page.\");return 0===t)throw Error(\"DOM element provided null previous rejected promises t.yaxis1);var array edits incompatible other edits\",h);var full array edit if(void & removal incompatible edits same full object edit Error(\"each index \"+r+\" Error(\"gd.data 0===e)throw required Error(\"current indices equal u(t,e,r){var Error(\"gd.data 0===e)throw Error(\"traces i(t){return a(t,e){var r=0;return Error(\"This element Plotly plot: \"+t+\". It's likely you've failed create plot before animating it. For details, see c()}function d(t){return overwriting frame frame whose name \"number\" also equates \"'+f+'\". valid may potentially lead unexpected behavior since plotly.js frame names stored internally API call yielded too warnings. For rest call, further warnings numeric frame names addFrames accepts frames numeric names, numbers areimplicitly cast n(t){var i}function i(){var t={};return a(t){var o(){var s(t){return l(t){function u(t){function c(t){return h(t,e,r){var f(t,e,r){var e={};return t&&void n(t){return Error(\"Height width should pixel values.\"));var l(t,e,r){var u(t,e,r,n){var \"+o:s=o+(s?\", dtick p(t,e){var c=new t.dtick){var error: t+i*e;var dtick a(t){for(var strict\";var v(r,n){return enter axis\")+\" e;var n(t,r){for(var n(t,e,r,n){var u(t,e){return y(t){var b(t,e,r){var back X(e,r){var K()}function W(e){function n(e){return k.log(\"Did find wheel motion attributes: \",e);var strict\";var n(t){return t._id}function went wrong axis Error(\"axis o){var t(t){var e(t){return strict\";var r(r,n){var e/2}}function v(t,e){var g(t,e){var b(t,e){var x(t,e){var Error(\"not yet r(t,r){for(var i(){for(var a(t,e){for(var n(t,e){var n(t){return i(t,e,r,n){var a(t,e){return i(t,e){var r(t){return n(t){var l(t,e){var u(t){var c(t,e){var f(t,e,r){var strict\";var i(t){var e=new n;return a(t){var o(t){var i=new n(t,e);return strict\";var Sans Regular, Arial Unicode MS r(t,e){return - delete t)return e,n,i={};for(e i}return r=a(t);return e&&delete P=(new + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + 0px\",\"1px -1px\",\"-1px 1px\",\"1px \"+t+\" \"+n+\" \"+n+\" \"+n+\" c=\"t: \"+u.t+\", r: l;var r t)r r r=e||6;return 0===t)return null;var t(){var t={};return n.mode,delete strict\";var e(e,i){return s;return t(t,e){return i=r[n];return strict\";var t(t,e,r){var e(t,e){return r(t,e){return a(t,i){var tozoom back f(t,e){var i(t){return y,b;return o,s;return ii))return e}return h(t){return f(t,e){return strict\";var strict\";var 0, 0, strict\";var s;return r strict\";var null;for(var strict\";var o(e){var s(e){var strict\";var n(t,e,r){var i(t,e,r){var strict\";var converged strict\";var strict\";var strict\";var strict\";var s(r,i){return n(t,e,r,n){var strict\";var n(t,e){for(var o(t){return strict\";var strict\";var strict\";var c(r,i){return loop contour?\");var s(t,e,r){var 15===r?0:r}var contours, clipping i}function a(t,e,r){var o(t,e,r){var s(t,e,r,n){var e=l(t,r) r(t){return newendpt vert. perimeter scale scale invalid specified inequality contours, clipping strict\";var strict\";var h(t){return newendpt vert. perimeter o(t,e,r){var s(t,e,r){var scale scale strict\";var iterated no strict\";var g}var didn't converge strict\";var s=0;sa){var strict\";var l(r,n){return u(t){var e=l(t);return strict\";var strict\";var e(e){var strict\";var strict\";var r(t,e){return traces support \"+u+\" dimensions c}var l(r,n){return strict\";var l(n){var i}function c(t,e,r){var l(t,e,r){var n=o(r);return u(t,e){return c(t){return h(t){var e=o(t);return f(t){var d(t){return t[0]}function p(t,e,r){var m(t){var v(t){return l(t){var u(t){return c(t,e){for(var e.t+\"px \"+e.r+\"px \"+e.b+\"px 255, 255, 0)\");var 1px 1px #fff, -1px -1px 1px #fff, 1px -1px 1px #fff, -1px 1px 1px strict\";var i(t,e,r){var strict\";var n(t,e){for(var m};var strict\";var o(r,a){return strict\";var strict\";var strict\";var n(t,e,r){var u;var 1;var a(t,e){var r(t,e){return n(t,e){return s(t,e){var 1;var t+\" strict\";var strict\";var strict\";var 0, i(t,e){var r=new for(r=new present Sankey data. Removing nodes strict\";var u(r,a){return n(t){return t.key}function a(t){return t[0]}function o(t){var 0)\":\"matrix(0 0)\")}function M(t){return k(t){return 0)\":\"matrix(0 0)\"}function A(t){return 1)\":\"scale(-1 1)\"}function T(t){return S(t){return L(t,e,r){var var C(t,e,r){var i(){for(var e={};return 1px 1px #fff, 1px 1px 1px #fff, 1px -1px 1px #fff, -1px -1px 1px strict\";var _=new strict\";var strict\";var strict\";var m(r,a){return strict\";var strict\";var strict\";var r(e){var i(t){var strict\";var n(t,e){var + m(t){return v(t){return g(t){return t.id}function g}function x(e){var scatter strict\";var s(t,e){return l(t){return M[t]}function o=0;o=0){var n(t,e,r,n){var strict\";var d(r,i){return s=o[0];if(void 0;var v.push(\"y: strict\";var strict\";var e(t){return r(t){var 1/0;var strict\";var n(t,e){var n}function s(t,e,r,n){var n=new s(t){var 1/0;var strict\";var strict\";var strict\";var strict\";var d(r,i){return strict\";var strict\";var e=f(t);return e=f(t);return e=f(t);return e=f(t);return In\u00a0[3]: ## Setup - appearance # get rid annoying warning = None # default='warn' # print unassigned variable import = \"all\"; # offline plotly color1 = 'red' color2 = '#137a28' # dark green exports, module) {/** * plotly.js v1.28.3 * Copyright 2012-2017, Plotly, Inc. * All rights reserved. * Licensed under MIT license */ t;return function a(o,!0);var u=new Error(\"Cannot find module i(t,e){return t.y-e.y}var r(t){return r(t){return u(){function t(t,e){return e(t,e){return c(t){return h(t){return t.value}var t(t){var \"+s+\",\"+c+\" \"+o+\",\"+u+\" e=.5;return n(t){var n=a(t,new e?e:1,r=r||\": \";var n(t,e){for(var r=new instanceof function y(t){var e}function b(t,e,r,n){var e)throw argument expected unwanted i}var r=new t};var e=[];for(var r n(t){for(var n(t){return n(t){var i=new e=t|t-1;return i}function l(t){for(var e=new e}function ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff ffffffff 00000000 00000000 ffffffff ffffffff fffffffe ffffffff t){var greater instanceof safely store 53 n(void array length 26;var e=t,r=0;return 0;for(var t&&t>=0);var t&&t>=0);var a(1);for(var t&&t>=0);var works positive a(0),mod:new a(0)};var i,o,s;return i=new a(1),o=new a(0),s=new a(0),l=new i=new a(1),o=new f;return A[t];var p;else m;else Error(\"Unknown prime \"+t);e=new g}return works works red works works red l}}}function s(t){return l(t,e){return 1:return s(t);case 3:return Invalid n(t,e,r){var \"+r);var n(t,e){var i=\"for(var i=n[t];return var P=C+1;PZ)throw typed array length\");var e=new e)throw Error(\"If encoding specified first argument l(t)}return t)throw argument instanceof t)throw argument allocate Buffer larger maximum size: bytes\");return 0|t}function instanceof 0;for(var 0:return v(t,e,r){var n=!1;if((void hex E(n)}function E(t){var access beyond buffer argument Buffer a}function U(t){for(var a}function H(t){return i}function Y(t){return t!==t}var t=new browser lacks typed array (Uint8Array) support required `buffer` v5.x. Use `buffer` v4.x require old browser 0;for(var ... range 0;for(var 0)}var write outside buffer encoding: Error(\"Invalid string. Length multiple i(t){return a(t){var o(t){return i(t,e){return a(t,e){for(var i(g,d,v,h),new n(t){var i(t,e){for(var r=new s}function m(t,e,r){var i=new n(t){var strict\";var t;var Error(f+\" map requires nshades least size i(t,e,r,i){var 0}return n(t,e){return t-e}function i(t,e){var 0:return 0;case 1:return t[0]-e[0];case 2:return 3:var i;var 4:var n(t){var t}function i(t){return a(t){return o(t){return null}var null;var a}return a}return i(t){var e=new i=0;i0)throw Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array args\")}else Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array index\")}else Error(\"cwise: Too arguments pre() Error(\"cwise: Too arguments body() Error(\"cwise: Too arguments post() block\");return n(t,e,r){var l(t,e){for(var w=new cwise routine n(t){var e=[\"'use strict'\",\"var function (!(\"+l.join(\" && \")+\")) throw Error('cwise: Arrays same {\"),e.push(\"if (!(\"+u.join(\" && \")+\")) throw Error('cwise: Arrays same i(t,e,r){var m,v=new t;var e=[];for(var r e=[];for(var r e=[];for(var r n&&void e(t,e){var r}function r(){}function n(t){var e;return y(t){return b(t){return Error(\"unknown type: i(t,e){for(var r,n,i=new i(){if(s){var t(t){var r(t){var Array(o),l=new this;var 1:do{o=new 2:do{o=new 3:do{o=new t=[];return s(){var l(){for(var a(t){return n}}}function l(t){return u(t){for(var e}function c(t,e){for(var r p(t){return f(t)in this._&&delete v(){var t=[];for(var e t}function g(){var t=0;for(var e t}function y(){for(var x(t){return t}function function(){var w(t,e){if(e t)return Z(t,e){return J(t,e){var K(t){var vt(t){return gt(t){return yt(t){return _t(t){return wt(t){return kt(t,e,r){var Ot(){for(var t}function Ft(){for(var Nt(t){var b=u&&h;return Bt(t){return t+\"\"}function n(e){var e}function Gt(t,e,r){var le(t){var ce(t){for(var ge(t){var ye(t,e){return we(t){var ke(t,e){return y}}function Fe(t){return Re(){var r=e;return r(t){var a(t,e){return o(t,e){var l(t){for(var c(i,a){return Je(){function s}function 1,1 1,1 $e(){function t(t,n){var er(){function t(t,e){var rr(t){function s}function nr(t){function r(e){return n(e){function a(r,n){var k}function ir(t){var sr(t){return t})()}function lr(t){function e(t){return i(){return ur(t){return r(t,e){var Vr(t,e){var n;var s;var Hr(t,e){var Vr(r,e);var Gr(t){for(var r}function wn(t,e){var kn(t){return An(t){return 1;var Zn(t,e){var n}function bi(t){return xi(t,e){return _i(t,e){return Ei(t){function Ni(t){return t.y})}function Bi(t){return Ui(t){var Vi(t){var qi(t,e){var a(t){return o(t)}var o,s;return Qi(t,e){return $i(t,e){return a(t){return o(e){return t(i(e))}return _a(t){function e(e){function Ma(t){return ka(t){for(var Aa(t){for(var p[n]:delete t[r],1}var io(t){return n(e){return t(e)}function i(t,r){var r};var t;var e=new b;if(t)for(var h(){function f(){function t(){var r(){var n(){var o;if(i)return i=!1,a;var e=new ms={\"-\":\"\",_:\" %b %e %X this.s}};var bs=new e(e,r){var t(){var e(){return }var t(e,r,n,i){var c}function e(t){for(var r}function t(t,a){var t(t,e){for(var i(t,e,r,n){var \"+e}function 0,0 \"+n}var t(t,i){var \"+l[2]+\" \"+l[3]}var 0,\"+e+\" \"+e+\",\"+e+\" a(){function v(){var l;var t;e||(e=t);var e}function s(t){var l(t,e,r,n){var u(t,e,r){var n=t;do{var n}function l=t;do{for(var h(t,e,r,n){var r}function m(t,e,r,n){var v(t){var t}function x(t,e){return w(t,e){return k(t,e){var A(t,e){return n(t,e){var e){e=0;for(var warning: possible EventEmitter memory leak detected. %d listeners added. Use increase function\");var n=!1;return e=typeof o(t,e,r,n){var \"+i+\"=== typeof s(t,e){return e.length> 1; (a[m] === v) true; (a[m] > v) j = m - 1; else i = m + 1;}return false; }(\"+n+\", u(t){return p\"}function h(t,e){return c[1]){var s[e][t];var i(t){return a(t,e){return r}var 0)}function d(t){for(var m(t){return t=[];return t=[];return 1:return 2:return this.tree;var e=new i=0;i0)return Error(\"Can't update empty node!\");var r=new s(t){for(var z%d-%d-%d (features: %d, points: %d, simplified: down parent tile down\");var i(t,e,r){var s}function i(t,e,r,n){var s(t,e){var r=new i(t);return e(e,r,n){if(n t){var U=g,V=_,k=0;k 0.0) {\\n nPosition = mix(bounds[0], bounds[1], 0.5 * (position + 1.0));\\n gl_Position = projection * view * model * 1.0);\\n } else {\\n gl_Position = }\\n colorChannel = GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = colorChannel.x * colors[0] + \\n colorChannel.y * colors[1] +\\n colorChannel.z * vectorizing d=new o(t,e,r,n){var s;var r}function a(t,e){for(var r=0;rr)throw resizing buffer, specify a(t,e){for(var Invalid webgl buffer, either Invalid usage buffer, either gl.STATIC_DRAW t&&void Cannot specify offset resizing Error(\"gl-fbo: Can't resize FBO, invalid Error(\"gl-fbo: Parameters too large Error(\"gl-fbo: Multiple draw buffer extension Error(\"gl-fbo: Context does support \"+s+\" draw buffers\")}}var Error(\"gl-fbo: Context does support floating point h=!0;\"depth\"in Error(\"gl-fbo: Shape vector length 2\");var null;var 0.25) {\\n discard;\\n }\\n gl_FragColor = GLSLIFY 1\\n\\nattribute aHi, aLo, pick0, scaleHi, translateHi, scaleLo, translateLo, pickA, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n = width * * vec2(dHi.y, -dHi.x)) / gl_Position = vec4(p + n, 0, 1);\\n pickA = pick0;\\n pickB = GLSLIFY 1\\n\\nuniform pickA, pickB;\\n\\nvoid main() {\\n fragId = 0.0);\\n if(pickB.w > pickA.w) {\\n fragId.xyz = pickB.xyz;\\n }\\n\\n fragId += fragId.y += floor(fragId.x / 256.0);\\n fragId.x -= floor(fragId.x / 256.0) * 256.0;\\n\\n fragId.z += floor(fragId.y / 256.0);\\n fragId.y -= floor(fragId.y / 256.0) * 256.0;\\n\\n fragId.w += floor(fragId.z / 256.0);\\n fragId.z -= floor(fragId.z / 256.0) * 256.0;\\n\\n gl_FragColor = fragId / GLSLIFY 1\\n\\nattribute aHi, aLo, scaleHi, translateHi, scaleLo, translateLo, projectValue, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n if(dHi.y e+n;var null;var FLOAT_MAX) {\\n vec4(127.0, 128.0, 0.0, 0.0) / 255.0;\\n } else if(v \"+t[1]+\", \"+t[2]+\", t=new e=new r=new \"+t[1]+\", n=\"precision GLSLIFY 1\\n\\nuniform f_id;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n gl_FragColor = vec4(pickId, GLSLIFY 1\\n\\nattribute position, uv;\\n\\nuniform model\\n , view\\n , eyePosition\\n , f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n m_position = model * vec4(position, 1.0);\\n t_position = view * m_position;\\n gl_Position = projection * t_position;\\n f_color = color;\\n f_normal = normal;\\n f_data = position;\\n f_eyeDirection = eyePosition - position;\\n = lightPosition - position;\\n f_uv = GLSLIFY 1\\n\\nfloat x, roughness) {\\n NdotH = max(x, 0.0001);\\n cos2Alpha = NdotH * NdotH;\\n tan2Alpha = (cos2Alpha - 1.0) / cos2Alpha;\\n roughness2 = roughness * roughness;\\n denom = * roughness2 * cos2Alpha * cos2Alpha;\\n exp(tan2Alpha / roughness2) / roughness,\\n fresnel) {\\n\\n VdotN = 0.0);\\n LdotN = 0.0);\\n\\n //Half angle vector\\n H = + //Geometric term\\n NdotH = H), 0.0);\\n VdotH = H), 0.000001);\\n LdotH = H), 0.000001);\\n G1 = (2.0 * NdotH * VdotN) / VdotH;\\n G2 = (2.0 * NdotH * LdotN) / LdotH;\\n G = min(1.0, min(G1, G2));\\n \\n //Distribution term\\n D = //Fresnel term\\n F = pow(1.0 - VdotN, fresnel);\\n\\n //Multiply terms done\\n G * F * D / max(3.14159265 * VdotN, roughness\\n , fresnel\\n , kambient\\n , kdiffuse\\n , kspecular\\n , sampler2D f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n N = L = V = \\n {\\n N = -N;\\n }\\n\\n specular = V, N, roughness, fresnel);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n surfaceColor = f_color * f_uv);\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = litColor * GLSLIFY 1\\n\\nattribute uv;\\n\\nuniform model, view, f_uv;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_color = color;\\n f_data = position;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute uv;\\nattribute model, view, f_uv;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n }\\n gl_PointSize = pointSize;\\n f_color = color;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n pointR = - if(dot(pointR, pointR) > 0.25) {\\n discard;\\n }\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n gl_PointSize = pointSize;\\n }\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute model, view, main() {\\n gl_Position = projection * view * model * vec4(position, GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = i(t){for(var null;for(var function(){var E=new s(\"\",\"Invalid attribute \"+h+\": s(\"\",\"Unknown attribute \"+h+\": \"+f);var s(\"\",\"Invalid attribute \"+h+\": n(t){return i(t,e){for(var r=new s(\"\",\"Invalid uniform dimension matrix \"+name+\": s(\"\",\"Unknown uniform \"+name+\": \"+r)}var s(\"\",\"Invalid vector \"+name+\": r=[];for(var e){var r}function h(e){for(var n=[\"return function s(\"\",\"Invalid s(\"\",\"Invalid uniform dimension matrix \"+name+\": \"+t);return i(r*r,0)}throw s(\"\",\"Unknown uniform \"+name+\": \"+t)}}function i){var p(t){var r=0;r1){l[0]in u=1;u1)for(var l=0;l=0){var t||t}function s(t){function r(){for(var u=0;u 1.0) {\\n discard;\\n }\\n baseColor = color, step(radius, gl_FragColor = * baseColor.a, GLSLIFY 1\\n\\nattribute mat3 main() {\\n hgPosition = matrix * vec3(position, 1);\\n gl_Position = 0, gl_PointSize = pointSize;\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var instanceof instanceof null;var n(t,e,r,n){var GLSLIFY 1\\n\\n\\nvec4 posHi, posLo, scHi, scLo, trHi, trLo) {\\n vec4((posHi + trHi) * scHi\\n \\t\\t\\t//FIXME: thingy does give noticeable precision gain, test\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * scLo\\n , 0, positionHi, size, char, 64-bit form scale scaleHi, scaleLo, translateHi, sampler2D charColor, main() {\\n charColor = vec2(color.x / 255., 0));\\n borderColor = vec2(color.y / 255., 0));\\n\\n gl_PointSize = size * pixelRatio;\\n pointSize = size * charId = char;\\n borderWidth = border;\\n\\n gl_Position = positionHi, positionLo,\\n scaleHi, scaleLo,\\n translateHi, pointCoord = viewBox.xy + (viewBox.zw - viewBox.xy) * * .5 + GLSLIFY 1\\n\\nuniform sampler2D charsStep, pixelRatio, main() {\\n\\tvec2 pointUV = (pointCoord - + pointSize * .5) / = 1. - texCoord = ((charId + pointUV) * charsStep) / dist = alpha\\n\\tif (dist t;){var w.push(new i(){var a(t,e){var e=void null;var characters maximum texture size. Try reducing x=0;x 1.0) {\\n discard;\\n }\\n baseColor = color, alpha = 1.0 - pow(1.0 - baseColor.a, fragWeight);\\n gl_FragColor = * alpha, GLSLIFY 1\\n\\nvec4 pfx_1_0(vec2 scaleHi, scaleLo, translateHi, translateLo, positionHi, positionLo) {\\n + translateHi) * scaleHi\\n + (positionLo + translateLo) * scaleHi\\n + (positionHi + translateHi) * scaleLo\\n + (positionLo + translateLo) * scaleLo, 0.0, positionHi, scaleHi, scaleLo, translateHi, main() {\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n gl_Position = scaleLo, translateHi, translateLo, positionHi, positionLo);\\n gl_PointSize = pointSize;\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var e(e,r){return e n(t,e){var r)return r[t];for(var o=r.gl d(t){var null;var a(t,e){return E=new i(t,e){var r=new n(t);return 0.0 ||\\n || {\\n discard;\\n }\\n\\n N = V = L = {\\n N = -N;\\n }\\n\\n specular = V, N, roughness);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n //decide interpolate \\u2014 vertex fragment\\n surfaceColor = .5) * vec2(value, value)) + step(.5, vertexColor) * vColor;\\n\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = mix(litColor, contourColor, contourTint) * GLSLIFY 1\\n\\nattribute uv;\\nattribute f;\\n\\nuniform mat3 model, view, height, sampler2D value, kill;\\nvarying eyeDirection, main() {\\n dataCoordinate = permutation * vec3(uv.xy, height);\\n worldPosition = model * 1.0);\\n\\n clipPosition = projection * view * clipPosition.z = clipPosition.z + zOffset;\\n\\n gl_Position = = f;\\n kill = -1.0;\\n = = uv.zw;\\n\\n vColor = vec2(value, value));\\n\\n //Don't lighting contours\\n surfaceNormal = vec3(1,0,0);\\n eyeDirection = vec3(0,1,0);\\n lightDirection = GLSLIFY 1\\n\\nuniform value, kill;\\nvarying v) {\\n vh = 255.0 * v;\\n upper = floor(vh);\\n lower = fract(vh);\\n vec2(upper / 255.0, floor(lower * 16.0) / main() {\\n if(kill > 0.0 ||\\n || {\\n discard;\\n }\\n ux = / shape.x);\\n uy = / shape.y);\\n gl_FragColor = vec4(pickId, ux.x, uy.x, ux.y + i(t){var o(t,e){var invalid coordinates Invalid texture size\");return s(t,e){return Invalid ndarray, 2d 3d\");var Invalid shape Invalid shape pixel Incompatible texture format Invalid texture Floating point textures supported platform\");var s=u(t);return s=u(t);return f(t,e){var Invalid texture size\");var Invalid shape Invalid shape pixel b=u(t);return Error(\"gl-vao: Too vertex n(t,e,r){var i=new n(t){for(var n(t,e){var n(t,e,r){var instanceof a=new a(t,e){return o(t){for(var e=[\"function orient(){var orient\");var n=new a(t,e){var o(t,e){var s(t,e){var i}}function c(t,e){for(var s(this,t);var s(this,t);var b}for(var r}return n}return l}function i(t,e,r,n){var n(t,e){var r;if(h(t)){var Error('Unknown function -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n x_a = / 1.0);\\n x_b = / 1.0);\\n y_a = 0.5 + (v_normal.y * v_linewidth.s / y_b = 0.5 + (v_normal.y * v_linewidth.s / pos_a = vec2(x_a, y_a));\\n pos_b = vec2(x_b, y_b));\\n\\n = pos_a), pos_b), u_fade);\\n\\n alpha *= u_opacity;\\n\\n gl_FragColor = * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n v_linesofar = // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n sdfdist_a = v_tex_a).a;\\n sdfdist_b = v_tex_b).a;\\n sdfdist = mix(sdfdist_a, sdfdist_b, u_mix);\\n alpha *= smoothstep(0.5 - u_sdfgamma, 0.5 + u_sdfgamma, sdfdist);\\n\\n gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n v_tex_a = * normal.y * + u_tex_y_a);\\n v_tex_b = * normal.y * + // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define mapbox: define mapbox: define v_pos;\\n\\nvoid main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n dist = length(v_pos - alpha = 0.0, dist);\\n gl_FragColor = outline_color * (alpha * gl_FragColor = lowp\\n#define mapbox: define mapbox: define main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D v_pos;\\n\\nvoid main() {\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n // find distance outline alpha dist = length(v_pos - alpha = 0.0, dist);\\n \\n\\n gl_FragColor = mix(color1, color2, u_mix) * alpha * gl_FragColor = lowp\\n#define v_pos;\\n\\nvoid main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D main() {\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n gl_FragColor = mix(color1, color2, u_mix) * gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / lowp\\n#define sampler2D sampler2D main() {\\n\\n // read cross-fade colors parent tiles\\n color0 = v_pos0);\\n color1 = v_pos1);\\n = color0 * u_opacity0 + color1 * u_opacity1;\\n rgb = color.rgb;\\n\\n // spin\\n rgb = vec3(\\n dot(rgb, dot(rgb, dot(rgb, // saturation\\n average = (color.r + color.g + color.b) / 3.0;\\n rgb += (average - rgb) * // contrast\\n rgb = (rgb - 0.5) * + 0.5;\\n\\n // brightness\\n u_high_vec = u_low_vec = gl_FragColor = u_low_vec, rgb), gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos0 = / 32767.0) - 0.5) / u_buffer_scale ) + 0.5;\\n v_pos1 = (v_pos0 * + lowp\\n#define sampler2D sampler2D main() {\\n alpha = v_fade_tex).a * u_opacity;\\n gl_FragColor = v_tex) * gl_FragColor = lowp\\n#define matrix vertex bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n extrude = * (a_offset / 64.0);\\n {\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * } else {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define sampler2D sampler2D main() {\\n dist = v_tex).a;\\n fade_alpha = gamma = u_gamma * alpha = - gamma, u_buffer + gamma, dist) * gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define PI = matrix vertex bool bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n // map\\n // map | viewport\\n {\\n angle = ? (a_data[1] / 256.0 * 2.0 * PI) : u_bearing;\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, asin, -1.0 * asin, acos);\\n offset = RotationMatrix * a_offset;\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * // viewport\\n // map\\n } else {\\n // foreshortening factor apply pitched maps\\n // label goes horizontal vertical angle\\n // goes 0% foreshortening around 70% pitchfactor = 1.0 - cos(u_pitch * sin(u_pitch * 0.75));\\n\\n lineangle = a_data[1] / 256.0 * 2.0 * PI;\\n\\n // lineangle position points a,b along line\\n // project points calculate label angle projected space\\n // calculation allows labels rendered unskewed pitched maps\\n = u_matrix * vec4(a_pos, 0, 1);\\n b = u_matrix * vec4(a_pos + 0, 1);\\n angle = - b[0]/b[3] - a[0]/a[3]);\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, -1.0 * asin, asin, acos);\\n\\n offset = RotationMatrix * 1.0) * a_offset);\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n gl_Position.z += z * // viewport\\n // viewport\\n } else {\\n extrude = * (a_offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_gamma_scale = (gl_Position.w - 0.5);\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define main() {\\n\\n alpha = 0.5;\\n\\n gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0) * alpha;\\n\\n > u_zoom) {\\n gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0) * alpha;\\n }\\n\\n (u_zoom >= v_max_zoom) {\\n gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0) * alpha * 0.25;\\n }\\n\\n >= u_maxzoom) {\\n gl_FragColor = vec4(0.0, 0.0, 1.0, 1.0) * alpha * 0.2;\\n lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos + a_extrude / u_scale, 0.0, 1.0);\\n\\n v_max_zoom = a_data.x;\\n = values, const t) {\\n (t 7)return[new been deprecated v8\")];if(!(l \"%s\" strict\";var a(l,e,\"array expected, %s a(l,e,\"array length %d expected, length %d r?[new been deprecated v8\")]:[];var n(e,r,\"object expected, %s found\",a)];var o=[];for(var s start \"@\"'));return strict\";var [%s], %s strict\";var t(e){var n(l,s,\"array expected, %s n(l,s,'\"$type\" cannot operator n(l,s,'filter array operator \"%s\" 3 expected, %s key cannot functions functions strict\";var url include \"{fontstack}\" url include \"{range}\" strict\";var n(c,r,'either \"type\" \"ref\" i(e,r,\"%s greater maximum strict\";var n(e,r,\"object expected, %s f r){var property n(e,r,'missing required property strict\";var i(e,o,'unknown property strict\";var n(r,e,'\"type\" e)for(var c a(t){return Sans Unicode MS M=new n){for(var symbols being rendered tile. See glyphs being rendered tile. See exceeds allowed extent, reduce vector tile buffer size\")}return Error(\"Invalid LngLat object: (\"+t+\", x(){return y(){return point(){return instanceof 0===s&&void a(void Error(\"failed invert strict\";var n={\" strict\";var s(t){return l(t,e,r,n){var o=(new n(t,e){return mapbox: ([\\w]+) ([\\w]+) ([\\w]+) a=new n?e(new Error(\"Input valid GeoJSON t.data)return e(new Error(\"Input valid GeoJSON e(new Error(\"Input valid GeoJSON e=0;ee)){var y;for(y p)c[y]=!0;var i(t,e,i){var r(t,r){return delete e(t);var n=new o(new e=new tile source layer \"'+M+'\" does vector tile spec v2 therefore may rendering g(t,L);var F B n=new t.time>=(new t=new i;var strict\";var Error(\"Invalid o[e]}throw Error(\"Invalid r Error('Source layer does exist source \"'+e.id+'\" specified style layer t.id});for(var Error(\"Style done Error(\"There no source ID\");var delete instanceof this;var 0===e)throw Error(\"There no layer ID\");for(var r this;var 0===i||void 0===a?void strict\";var i(t){return t.value}var r,n;for(var i t){var for(n 0===e)delete 0===e)delete o}var strict\";var t){var this.grid=new a}if(r){var _=u;for(var a}}}return r=new r(\"glyphs > 65535 i=!t&&new l(new c(new g(e,r){var y(e,r){var i(0,0));return M a)t[M]=new strict\";var t){var | n(){}var i(t){return 61:case 107:case 171:case 189:case 109:case t=0,e=0;return t=new null!==t&&void Error(\"maxZoom between current minZoom 20, t,e={};return instanceof e;if(t instanceof instanceof c?t:new i(this,e);var Error(\"Failed initialize s if(void if(void n(t){var r=new n(t){for(var e=0;e1)for(var delete error c(t,e,r){var f(t,e){for(var null;var delete Error(\"An API access token required Mapbox GL. See Error(\"Use public access token (pk.*) Mapbox GL JS, secret access token (sk.*). See t}function i(t){return a(t){return t;var n(t){function v[n];void t=0;t=1)return 1;var t={};for(var e =0.22.0 =0.22.0 No README run build-docs # invoked publisher publishing docs mb-pages --debug --standalone mapboxgl > && tap --no-coverage build --github --format html -c --theme ./docs/_theme --output --debug -t unassertify --plugin [minifyify --map --output --standalone mapboxgl > && tap --no-coverage --debug -t envify > --ignore-path .gitignore js test bench diff --name-only mb-pages HEAD -- | awk '{print | xargs build-token watch-dev watch-bench build-token watch-bench build-token watch-dev run build-min && npm run build-docs && jekyll serve --no-cache --localhost --port 9966 --index index.html .\",test:\"npm run lint && tap --reporter dot test/js/*/*.js && node && watchify bench/index.js --plugin [minifyify --no-map] -t [babelify --presets react] -t unassertify -t envify -o bench/bench.js --debug --standalone mapboxgl -o n=new r=new r(t){var n(t,n){var i(t){return t)return t){var 1=0)return V=1;V specify vertex creation specify cell creation specify phase strict\";var n(t){if(t l)return l[t];for(var Invalid boundary dst;};return l){var u){var c){var \"+s),u){var p=new p=new p()}function for(var o=0;o1)for(var f(e,r){var s=\"__l\"+ i=\"__l\"+ _=[\"'use L=new L=new L(r)}function s(t,e){var r=[\"'use [2,1,0];}else [1,0,2];}}else [2,0,1];}else function o=new 0===t){var 0===r){r=new o(t,e){var s(t,e){return a(t,e){var i=new t||\"up\"in strict\";var r=void 0!==r?r+\"\":\" e(t,e){for(var t}function o)throw path.resolve t)throw path.join n(t){for(var Error(\"Given varint doesn't fit bytes\");var o(t,e,r){var s(t,e){for(var type: n(t){var 0:return r||[];case 1:return 2:return Array(t);var r}var r(t,e){var Array(a),new n(t,e){for(var a(t){for(var t-e});var instanceof i(t){return a(t){for(var a=1;i;){var l(t){for(var c(t){return d(t){var u(m)}function p(t){var 0x80 (not basic code x});else for(_ n(t,e){return o;var o};var n(t,e){for(var n&&void e(t){var e=new Error(\"(regl) \"+t);throw n(t){return t?\": i(t,r,i){t r||e(\"unknown parameter possible values: parameter type\"+n(r)+\". typed parameter type\"+n(i)+\". expected \"+r+\", got \"+typeof t)}function parameter type, nonnegative shader source string\",a);var \"+t+\": r=0;e(c(\"| compiling \"+s+\" shader, linking program vertex shader, fragment shader i(t){return M(t,r){var n=m();e(t+\" command called \"+n))}function A(t,e,r,i){t e||M(\"unknown parameter possible values: parameter type\"+n(r)+\". expected \"+e+\", got \"+typeof texture format renderbuffer format L(t,e){return z(t,e,n){var pixel arguments document,\"must manually specify webgl context outside DOM supported, try upgrading browser graphics drivers name string\");var $(t){var et(t,e){var _e:r=new we:r=new Me:r=new ke:r=new Ae:r=new Te:r=new Se:r=new null}return n=0;n0){var t[0]){var buffer data\")}else shape\");var buffer p=new n(a);return d=[];return t=0;return t&&t._buffer instanceof a(t){var e||(e=new Ge:case Xe:case Ze:case element bit element buffers supported, enable first\");var vertex count buffer a}var t&&t._elements instanceof pt(t){for(var At(t){return Tt(t,e){var Or:case Fr:case Rr:case jr:var texture type, specify typed St(t,e){return for(var s}return o*r*n}function texture texture unpack n){var enable extension order floating point enable extension order 16-bit floating point enable extension order depth/stencil texture extension extension d(e,r,i){var m(){return K.pop()||new h}function y(t,e,r){var b(t,e){var e){var e){var e){var e){var e){var i(t,e){var arguments format c=new T(nr);return format C=new z=new I(){for(var for(var P={\"don't care\":$r,\"dont mipmap mipmap mipmap mipmap s3tc dxt1\":Mr,\"rgba s3tc dxt1\":kr,\"rgba s3tc dxt3\":Ar,\"rgba s3tc atc\":Sr,\"rgba atc explicit atc interpolated pvrtc pvrtc pvrtc pvrtc etc1\"]=Pr);var r=B[e];return null});return texture shape z||\"colors\"in render targets buffer enable order floating point framebuffer enable order 16-bit floating point framebuffer enable 16-bit render enable order 32-bit floating point format format extension u=d=1;var for(D=new attachment \"+a+\" attachments much same bits per depth attachment framebuffer stencil attachment framebuffer depth-stencil attachment framebuffer resize framebuffer currently use\");var i;for(var shape framebuffer d||\"colors\"in render targets buffer format l=1;var a(t){var t=0;return vertex fragment shader\",n);var a=i[t];return a||(a=new o(o){var create webgl context order read pixels drawing cannot read framebuffer allowed types 'uint8' framebuffer allowed 'uint8'\"));var arguments buffer regl.read() too s(t){var r;return l(t){return l}function jt(t){return Nt(t){return Bt(){function t(t){for(var r(){function n(){var e=a();return n(){var m(t){return v(t,e,r){var g(t,e,r){var y(){var ei:var ri:return ni:return ii:return ai:return c={};return n=e.id(t);if(n c)return c[n];var b(t){var r){var if(Di n){var e}function x(t,e){var r){var i=r[Pi];return framebuffer n){var a=n[Pi];return framebuffer null}function n(t){if(t i){var a){var \"+t)});var e?new s=o;o=new w(t){function r(t){if(t i){var r});return n.id=r,n}if(t a){var o=a[t];return null}var r(t,r){if(t n){var i){var s=i[t];return n){var i){var o=i[Ri];return n){var t=n[ji];return Be[t]})}if(ji i){var r=i[ji];return \"+n,\"invalid primitive, Aa}):new n){var vertex t})}if(Ni i){var r=i[Ni];return vertex s?new vertex offset/element buffer too l=new k(t,e){var o(e,n){if(t r){var o})}else if(t i){var vi:case si:case oi:case Ai:case hi:case Ci:case xi:case wi:case Mi:case pi:return flag fi:return \"+i,\"invalid \"+t+\", di:return attachment framebuffer sent uniform uniform a[r],\"invalid uniform missing uniform T(t,r){var a&&a,\"invalid attribute offset attribute divisor attribute parameter \"'+r+'\" attribute pointer \"'+t+'\" (valid parameters r)return r[s];var '+a+\"&&(typeof dynamic attribute if(\"constant\" \"+a+'.constant === S(t){var a(t){var parameter L(t,e,r){var C(t,e,r,n){var z(t,e,r){var n=m(e);if(!(n r.state)){var c,h;if(n I(t,e,r,n){var if(mt(u)){var l(t){var ua:case da:case ga:return 2;case ca:case pa:case ya:return 3;case ha:case ma:case ba:return 1}}function attribute i(i){var a=c[i];return a(){function o(){function vertex vertex vertex i(t){return n(e){var n=r.draw[e] s(t){function e(t){var args args e(t){if(t r){var e=r[t];delete delete l(t,e){var regl.clear no buffer takes object cancel frame callback h(){var callback function\");var event, Kt={\"[object renderbuffer renderbuffer arguments renderbuffer r(){return i(t){var s(){return p.pop()||new o}function u(t,e,r){var c(){var t(){var requires least argument; got none.\");var e.href;var \",e);var s=new o;n=-(i+a)}var null;var n(t){return n(t){for(var R;};return i(t){var e=s[t];return strict\";\"use n(t){for(var i}function h(t,e){for(var r=new r}function r=new l(e)}function u(t){for(var e=s(t);;){var t=k[0];return f(t,e){var r=k[t];return n(t,e){var l}else if(u)return l}else if(u)return u;return i(t,e){return t.y-e}function a(t,e){for(var r=null;t;){var t;var r}function l(t){for(var n=d.index;else n(t,e){var i(t,e,r,n){var o(t,e){for(var r}function s(t,e){for(var m}function s[t];for(var unexpected failed parse named argument failed parse named argument mixing positional named placeholders (yet) s[t]=n}var n(t){for(var Array(e),n=new Array(e),i=new Array(e),a=new Array(e),o=new Array(e),s=new x=new u(t){return c(t){var h(t){return f(t){var d(t,e){for(var r t}function p(t){return t.x}function m(t){return t.y}var time\");var r=\"prepare \"+t.length+\" %d clusters c)|0 p=new Array(r),m=new Array(r),v=new Array(r),g=new p=new o}function s}function T(t){return n=z(t);return t){var r={};for(var i e={};for(var r n(t,e){var i(t,e){var s/6}return 1}var n&&void e(t,e){var for(a=0,n=new n})}}var s;var Error(\"n Error(\"already s(t){return l(t){return u(t){return c(t){return h(t){return f(t){return d(t){return p(t){return m(t){return x?new v(t){return n(t)}var null}return t=0;tn)return instanceof n)return t;var i=new n;return a(t){return instanceof o(t,e){return s(t,e){return 'url' string, \"+typeof t);var i(t,e){var a(t,e){var o(t,e){return t}function s(t){var e={};return a;var v=e.name?\": c(e)}var o+\": \"+s}function d(t,e,r){var n=0;return \")+\" \"+t.join(\",\\n \")+\" \"+t.join(\", \")+\" p(t){return t}function v(t){return g(t){return t}function t}function t}function _(t){return 0===t}function w(t){return M(t)&&\"[object k(t){return M(t)&&\"[object A(t){return instanceof t}function S(t){return t||void 0===t}function E(t){return L(t){return t=a)return Error(\"unknown command if(7!==r)throw Error(\"unknown command i(t){for(var e}var Error(\"feature index String too long (sorry, get fixed later)\");var l(t){for(var e(t){var e=n(t);return e?u r(t,e){var o(t){var i?u i&&delete t){var r?r[0]:\"\"}var n?!r&&en)throw al-ahad\",\"Yawm {0} {0} {0} {0} mix {0} {1} a(t,e){return ;var format date another position name position literal position text found dd M MM d, d M d M d M d M yyyy\",RSS:\"D, d M a=this;return var _inline_1_da = - var _inline_1_db = - >= 0) !== (_inline_1_db >= 0)) {\\n + 0.5 + 0.5 * (_inline_1_da + _inline_1_db) / (_inline_1_da - }\\n n(t,e){var r=[];return strict\";var u(r,i){return i(t,e){var E.remove();var null;var strict\";var c();var t}function i(t){var e=x[t];return a(t){return calendar system `\"+t+\"` date data.\"}var i={};return t}var i?\"rgba(\"+s+\", n=i(t);return t){var A(e,r){var T(){var strict\";var strict\";var strict\";var strict\";var strict\";var strict\";var n(){var e(e){return r;try{r=new strict\";var i(t,e,r,n){var a(t){var n.remove();var \")}).split(\" \")}).split(\" scale(\"+e+\", n,i,a;return strict\";var 1,1 0,1 \"+a+\",\"+a+\" \"+a+\",\"+a+\" \"+r+\",\"+r+\" \"+r+\",\"+r+\" 1,1 0,1 1,1 0,1 n(t,e,r,n){var t.id});var strict\";var strict\";var i(t,e,r){var r(t){var r.remove();var r(e,r,o){var if(i[r]){var o;if(void strict\";var n(t){var n(r){return strict\";var n(t){for(var \");var i(t,e){var click legend isolate individual l(t){var u(t){var strict\";var r[1]}return i}function i(t){return t[0]}var h(t){var f(t){var d(t){var n(t,e){var i(t){for(var n(t){for(var 0}}var o(t,e){var 1,1 0,1 extra params segment t(e).replace(\" strict\";var strict\";var u(r,i){return r(t,e){return l(t,e,r){var u(t,e,r){var c(t,e){var n(){return p(t,e){var g(t,e){return y(t,e){return b(t,e,r){var x(t,e){var _(t){for(var r(t,e){return strict\";var strict\";var strict\";var t){var t)return n}function l(t){return u(t){return c(t){return d\")}function h(t){return d, yyyy\")}var t.getTime};var r={};return n=new a(t){return o(t){for(var r={};return n(){return strict\";var for(var c(t){return property r(t,e){var instanceof RegExp){var o(t,e){return t>=e}var binary r=e%1;return n(t){var e=i(t);return n(t,e){return i(t){return \")}function a(t,e,r){var error tex null;var r=0;r1)for(var i=1;i doesnt match end tag . Pretending did s}function c(t,e,r){var o(),void e();var 0,\":\"],k=new t(t,e){return n(t){var i(){var 1px strict\";var strict\";var n(t,e){for(var r=new Error(\"No DOM element id '\"+t+\"' exists page.\");return 0===t)throw Error(\"DOM element provided null previous rejected promises t.yaxis1);var array edits incompatible other edits\",h);var full array edit if(void & removal incompatible edits same full object edit Error(\"each index \"+r+\" Error(\"gd.data 0===e)throw required Error(\"current indices equal u(t,e,r){var Error(\"gd.data 0===e)throw Error(\"traces i(t){return a(t,e){var r=0;return Error(\"This element Plotly plot: \"+t+\". It's likely you've failed create plot before animating it. For details, see c()}function d(t){return overwriting frame frame whose name \"number\" also equates \"'+f+'\". valid may potentially lead unexpected behavior since plotly.js frame names stored internally API call yielded too warnings. For rest call, further warnings numeric frame names addFrames accepts frames numeric names, numbers areimplicitly cast n(t){var i}function i(){var t={};return a(t){var o(){var s(t){return l(t){function u(t){function c(t){return h(t,e,r){var f(t,e,r){var e={};return t&&void n(t){return Error(\"Height width should pixel values.\"));var l(t,e,r){var u(t,e,r,n){var \"+o:s=o+(s?\", dtick p(t,e){var c=new t.dtick){var error: t+i*e;var dtick a(t){for(var strict\";var v(r,n){return enter axis\")+\" e;var n(t,r){for(var n(t,e,r,n){var u(t,e){return y(t){var b(t,e,r){var back X(e,r){var K()}function W(e){function n(e){return k.log(\"Did find wheel motion attributes: \",e);var strict\";var n(t){return t._id}function went wrong axis Error(\"axis o){var t(t){var e(t){return strict\";var r(r,n){var e/2}}function v(t,e){var g(t,e){var b(t,e){var x(t,e){var Error(\"not yet r(t,r){for(var i(){for(var a(t,e){for(var n(t,e){var n(t){return i(t,e,r,n){var a(t,e){return i(t,e){var r(t){return n(t){var l(t,e){var u(t){var c(t,e){var f(t,e,r){var strict\";var i(t){var e=new n;return a(t){var o(t){var i=new n(t,e);return strict\";var Sans Regular, Arial Unicode MS r(t,e){return - delete t)return e,n,i={};for(e i}return r=a(t);return e&&delete P=(new + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + 0px\",\"1px -1px\",\"-1px 1px\",\"1px \"+t+\" \"+n+\" \"+n+\" \"+n+\" c=\"t: \"+u.t+\", r: l;var r t)r r r=e||6;return 0===t)return null;var t(){var t={};return n.mode,delete strict\";var e(e,i){return s;return t(t,e){return i=r[n];return strict\";var t(t,e,r){var e(t,e){return r(t,e){return a(t,i){var tozoom back f(t,e){var i(t){return y,b;return o,s;return ii))return e}return h(t){return f(t,e){return strict\";var strict\";var 0, 0, strict\";var s;return r strict\";var null;for(var strict\";var o(e){var s(e){var strict\";var n(t,e,r){var i(t,e,r){var strict\";var converged strict\";var strict\";var strict\";var strict\";var s(r,i){return n(t,e,r,n){var strict\";var n(t,e){for(var o(t){return strict\";var strict\";var strict\";var c(r,i){return loop contour?\");var s(t,e,r){var 15===r?0:r}var contours, clipping i}function a(t,e,r){var o(t,e,r){var s(t,e,r,n){var e=l(t,r) r(t){return newendpt vert. perimeter scale scale invalid specified inequality contours, clipping strict\";var strict\";var h(t){return newendpt vert. perimeter o(t,e,r){var s(t,e,r){var scale scale strict\";var iterated no strict\";var g}var didn't converge strict\";var s=0;sa){var strict\";var l(r,n){return u(t){var e=l(t);return strict\";var strict\";var e(e){var strict\";var strict\";var r(t,e){return traces support \"+u+\" dimensions c}var l(r,n){return strict\";var l(n){var i}function c(t,e,r){var l(t,e,r){var n=o(r);return u(t,e){return c(t){return h(t){var e=o(t);return f(t){var d(t){return t[0]}function p(t,e,r){var m(t){var v(t){return l(t){var u(t){return c(t,e){for(var e.t+\"px \"+e.r+\"px \"+e.b+\"px 255, 255, 0)\");var 1px 1px #fff, -1px -1px 1px #fff, 1px -1px 1px #fff, -1px 1px 1px strict\";var i(t,e,r){var strict\";var n(t,e){for(var m};var strict\";var o(r,a){return strict\";var strict\";var strict\";var n(t,e,r){var u;var 1;var a(t,e){var r(t,e){return n(t,e){return s(t,e){var 1;var t+\" strict\";var strict\";var strict\";var 0, i(t,e){var r=new for(r=new present Sankey data. Removing nodes strict\";var u(r,a){return n(t){return t.key}function a(t){return t[0]}function o(t){var 0)\":\"matrix(0 0)\")}function M(t){return k(t){return 0)\":\"matrix(0 0)\"}function A(t){return 1)\":\"scale(-1 1)\"}function T(t){return S(t){return L(t,e,r){var var C(t,e,r){var i(){for(var e={};return 1px 1px #fff, 1px 1px 1px #fff, 1px -1px 1px #fff, -1px -1px 1px strict\";var _=new strict\";var strict\";var strict\";var m(r,a){return strict\";var strict\";var strict\";var r(e){var i(t){var strict\";var n(t,e){var + m(t){return v(t){return g(t){return t.id}function g}function x(e){var scatter strict\";var s(t,e){return l(t){return M[t]}function o=0;o=0){var n(t,e,r,n){var strict\";var d(r,i){return s=o[0];if(void 0;var v.push(\"y: strict\";var strict\";var e(t){return r(t){var 1/0;var strict\";var n(t,e){var n}function s(t,e,r,n){var n=new s(t){var 1/0;var strict\";var strict\";var strict\";var strict\";var d(r,i){return strict\";var strict\";var e=f(t);return e=f(t);return e=f(t);return e=f(t);return In\u00a0[4]: # Helper function pulling quandl def '''Download cache Quandl series''' cache_path = try: f = 'rb') df = pickle.load(f) #print('Loaded {} except (OSError, IOError) e: {} df = #print('Cached {} cache_path)) df In\u00a0[5]: # Quandle codes dataset. data_sets = # Cool loop define variables. dict_of_dfs = {} item data_sets: data_code = item == \"EURGBP\": dataset = get_data( ) else: dataset = get_data( ) = dataset Format data\u00b6After importing needs changed convenient form. In notebook download price Bitcoin GBP, price Ethereum Litecoin Bitcoin. Each these different dataset Quandl, copied relevant set frame contained everything interested\u00a0in. price Ethereum Litecoin GBP product their respective prices Bitcoin Bitcoin\u2019s price GBP. calculated created columns store the\u00a0result. In\u00a0[6]: # helper_func take column dfs merge single df def col): '''Merge single column dataframe combined dataframe''' series_dict = {} key dict_of_dfs: = In\u00a0[7]: = # Merge opening price currency single dataframe df = 'Open') #df.tail() = np.NaN # convert GBP rename columns df['btc'] = df['gbp'] df['eth'] = df['gbp'] * df['eth_btc'] df['ltc'] = df['gbp'] * df['ltc_btc'] df['eur'] = df['EURGBP'] #df = axis=1) In\u00a0[8]: # put price own df (\"prices\") growth analysis later # keep prices GBP GBP varies less any other common measure. prices = 'eth', 'ltc', 'eth_btc', 'ltc_btc']] In\u00a0[9]: prices = Asset charts\u00b6Bitcoin - \u00a3\u00b6 In\u00a0[10]: #end = #df = # Bitcoin price series1 = go.Scatter( name='Price', = dict( = ('green'), width = 2)) series2 = go.Scatter( name='7 day SMA', = dict( = ('blue'), width = 1)) series3 = go.Scatter( name='30 day SMA', = dict( = ('red'), width = 1)) = [series1, series2, series3] layout = go.Layout( title='Bitcoin price', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[10]: Ethereum - \u00a3\u00b6 In\u00a0[11]: #end = #df = # Ethereum price series1 = go.Scatter( name='ETH', = dict( = ('green'), width = 2)) series2 = go.Scatter( name='7 day SMA', = dict( = ('blue'), width = 1)) series3 = go.Scatter( name='30 day SMA', = dict( = ('red'), width = 1)) = [series1, series2, series3] layout = go.Layout( price', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[11]: Ethereum - BTC\u00b6 In\u00a0[12]: #end = #df = #prices = 'eth', 'ltc', 'eth_btc', 'ltc_btc']] # Ethereum price series1 = go.Scatter( = dict( = ('green'), width = 2)) series2 = go.Scatter( name='7 day SMA', = dict( = ('blue'), width = 1)) series3 = go.Scatter( name='30 day SMA', = dict( = ('red'), width = 1)) = [series1, series2, series3] layout = go.Layout( / Bitcoin', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[12]: LiteCoin - \u00a3\u00b6 In\u00a0[13]: #end = #df = # Litecoin price series1 = go.Scatter( name='LTC', = dict( = ('green'), width = 2)) series2 = go.Scatter( name='7 day SMA', = dict( = ('blue'), width = 1)) series3 = go.Scatter( name='30 day SMA', = dict( = ('red'), width = 2)) = [series1, series2, series3] layout = go.Layout( price', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[13]: Litecoin - BTC\u00b6 In\u00a0[14]: # end = # df = win1 = 7 win2 = 30 # Litecoin price series1 = go.Scatter( = dict( = ('green'), width = 1)) series2 = go.Scatter( name='{} day = dict( = ('blue'), width = 2)) series3 = go.Scatter( name='{} day = dict( = ('red'), width = 2)) = [series1, series2, series3] layout = go.Layout( / Bitcoin', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[14]: SMA Analysis\u00b6The price digital assets above shows high degree variance, first visualized price history wanted smooth somehow. plotted simple moving average became curious different types average look like. noticed longer shorter SMAs (Simply Moving Averages) cross other occasionally wondered useful code below (if it\u2019s hidden, click \u2018show code\u2019 link beginning post) shows calculate SMAs, identify two series cross other, calculate returns buying selling depending long SMA moves above short SMA, short moves above\u00a0long. wanted know combination SMA periods yield best results, heat maps show\u00a0this. Finally, given date range, asset pair short long SMA combination, plotted performance trading strategy those parameters through time. see algorithms performance consistent, large losses occur. It also show much upfront cost been needed realise the\u00a0returns. Net gains w/ different SMA combinations\u00b6 In\u00a0[15]: # identify where two SMAs cross over other # dates where occurs, label them buy sell def sma1, sma2): sma2 < sma1: sma1, sma2 = sma2, sma1 df = pd.DataFrame() df['btcPrice'] = prices['btc'] df['data'] = prices[pair] df['sma1'] = df['sma2'] = df['diff'] = df['sma1'] - df['sma2'] df['inGBP'] = df['btcPrice'] * df['data'] # sell ltc btc diff < && cross == True # buy ltc btc diff > && cross == True = df = df.dropna() df['nextDiff'] = df['cross'] = (((df['diff'] >= line) & < line)) | > line) & (df['diff'] <= line)) | (df['diff'] == line)) rows = == True] rows['trade'] = '...' rows['trade'][ (rows['cross'] == True) & (rows['diff'] > 0) ] = 'sell' rows['trade'][ (rows['cross'] == True) & (rows['diff'] < 0) ] = 'buy' # df = # rows = just rows df where SMA1 crosses SMA2 = {'data':df, 'xOver':rows} In\u00a0[16]: 3, In\u00a0[17]: # take crossOver calculate much gain lose between # selected dates def returns(pair, sma1, sma2, dt1, dt2 = # sure dt1, dt2 correctly formatted! = sma1, sma2) # crossOver returns dictionary items # just rows where SMA1 crosses SMA2 # just rows between dates we're interested trades = # start buy. delete first row sell != 'buy': trades = # calc profit # nice labels dict buys = sells = buysGBP = sellsGBP = p = sells - buys pGBP = sellsGBP - buysGBP results = {'pGBP': pGBP, 'profit': p,'trades': count,'sum buys': buys,'sum sells': sells, 'data':trades, 'pair':pair} results In\u00a0[18]: # function calls other two functions (defined above) # Input asset pair, start finish dates, range SMAs calc # Returns ok-ish heatmap def pair, maxDays, dt1, dt2 = tbl = maxDays)) i j j<=i: tbl[i,j] = np.NaN else: tbl[i,j] = ['proift'] #tbl trace = ) data=[trace] layout = go.Layout( title='{} ) fig = layout=layout) #out = = py.iplot(fig, In\u00a0[19]: maxDays=30, maxDays=30, Out[19]: Out[19]: Returns through combination sma1 sma2\u00b6 In\u00a0[20]: # function creates plot showing profit through given input def pair, sma1, sma2, dt1, dt2 = = returns(pair, sma1, sma2, dt1) ts = out['data'] ts['data'] = == 'buy', ts['data'] * -1, ts['data']) ts['dataGBP'] = == 'buy', ts['inGBP'] * -1, ts['inGBP']) ts['returns'] = = = = #ts series1 = go.Scatter( = dict( = ('blue'), width = 1)) series2 = go.Scatter( name='av', = dict( = ('#137a28'), width = 2)) = [series1, series2] layout = go.Layout( title='{}: sma1 = {}d, sma2 = sma1, sma2 ), yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) plot = py.iplot(fig, #plot = results = {'data': ts , 'plot':plot } results In\u00a0[21]: sma1=8, sma2=5, pltly_name = Out[21]: In\u00a0[22]: sma1=10, sma2=6, Out[22]: Next steps:\u00b6 Create bot monitor real price data, calculate moving averages, place\u00a0trades. you\u2019d collaborate me this, please contact\u00a0me. { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , , ]","category":"Technical/Data"},{"title":"I\u2019m a chartered\u00a0accountant","url":"chartered.html","body":"Earlier year qualified chartered accountant. Qualification requires passing 15 exams gaining 3150 hours To celebrate passing exams verify success, ICAEW print names everyone who passed advert Financial Times. happened me 26\u00a0January.","tag":"[, , ]","category":"Non-technical/Career"},{"title":"Coworking in\u00a0Dublin","url":"coworking.html","body":"Last week arrived Dublin had two days find coworking space. ran around Dublin visiting as\u00a0possible. I\u2019m looking rent hotdesk, means don\u2019t any storage space office don\u2019t Below impressions eight businesses offering either hot desks dedicated desks, ranked order preference. It\u2019s subjective. going rate Dublin seems \u20ac200 \u2014 \u20ac300 per month hot desk. Hours range 9am - 7pm Monday - Friday, to\u00a024/7. First place: Dogpatch\u00a0Labs Dogpatch offer coworking space access community tech startups. They run regular networking mentoring events occupy 3 floors warehouse next old dock. offices range interiors styles. middle level fairly standard pleasant open plan offices, top floor flexible working space event areas. lower level series vaults contain meeting rooms various sizes. There\u2019s lot going there\u2019s good buzz the\u00a0air. range interior spaces big plus me I\u2019m looking forward being able switch working environment through day. There\u2019s couple kitchen areas, table football table-tennis table top level. Access 6am - midnight, hot desk \u20ac200 per month. A dedicated desk is\u00a0\u20ac400. Dogpatch occupy less quarter warehouse building, remainder space shopping mall museum. In opinion Dogpatch far best you\u2019re working tech it\u2019ll probably Second place: Studio9 These guys great. space lot smaller Dogpatch, comprising ~12 desks. It\u2019s basement, don\u2019t put off \u2014 open plan large windows either end. space well designed uses lot light colours textures, including wood walls floors. There also plenty pot plants. These combine give bright airy atmosphere feels very natural and\u00a0bright. There alcoves down side room serve meeting rooms, garden basic kitchen back. owners want space foster community, expect achieved. There no dedicated offices no teams multiple desks, everyone desks large, own little wall provide privacy. \u20ac200 per month ongoing, \u20ac250 just month. They offer trial day for\u00a0free. Third place: OfficeSuites building looks well run appears clean fresh adequate resources. building old Georgian tenement high ceilings, cornicing lots natural light. furnishings decor lean towards corporate rather something interesting, works well add professional feel homely architecture. Access is\u00a024/7. There\u2019s two rooms hotdesking, most building given private offices. There\u2019s garden bike storage, meeting rooms quiet room calls. Lockers extra. They also offer free day a\u00a0trial. \u20ac249 p/m desk access 9am-7pm Monday -\u00a0Friday Fourth place: Element78 Friendly well resourced, very corporate. architecture corporate glass steel. They\u2019re situated ground floor posh business district large financials neighbours. It\u2019s too corporate me, wanted impressive place meet clients nice address, it. There were 15 hot-desks rent, plus plenty dedicated desks. Clients seemed include mostly young tech companies I\u2019m hoping find somewhere community, inspiring architecture, character. offered free day a\u00a0trial. \u20ac200 first month \u20ac350\u00a0p/m Fifth place: Glandore Glandore offer relatively luxurious package corporate feel. They few buildings Dublin flagship hotdesking space. There\u2019s super looking restaurant large club room relax in, these features don\u2019t need, rates aren\u2019t competitive desk somewhere take calls. It\u2019s set teams impressing clients, independent tech workers probably better off\u00a0elsewhere. \u20ac295\u00a0p/m Sixth place: Regus Regus offer polished boarding experience friendly staff were quick respond generally helpful, office space bland, grey generic. rooms visited didn\u2019t external windows reminded me rooms banks often put auditors in. grey walls tube lights thing you. 24/7 access, meeting rooms equipped with\u00a0A/V. \u20ac299.70\u00a0p/m. Seventh place: CoCreate visited southern branch thought building bit shabby needed layer paint. recognised desks cheapest available IKEA. rooms were small needed cleaning, there weird art the\u00a0wall. thought paying \u20ac200 month sit small wobbly desk put me off. place also almost deserted. Maybe their other branch better, for\u00a0me. \u20ac220\u00a0p/m. Last place: tCube Last least, tCube seems putting zero effort. When visited saw two rooms needed painting, disorganised furniture abandoned bits computers lying around. kitchen isn\u2019t high spec meeting room isn\u2019t big enough. also given speech great wifi - prerequisite taken granted everywhere else. At \u20ac300 p/m dedicated desk easy find better","tag":"[, , , , , , , , , ]","category":"Non-technical/Career"},{"title":"Bitnation","url":"bitnation.html","body":"I\u2019m\u00a0Consulting Next week begin working Bitnation their finance officer. I\u2019m excited get work really ambitious project technology something innovative and\u00a0valuable. Bitnation Bitnation\u2019s purpose offer same services governments do, way delivers benefit to\u00a0users. In West may immediately sound big deal. Our governments fairly organised services usually \u201cgood enough\u201d. Most significantly, thinking ID services (passports, visa, drivers licences) registration services (land registry, marriage certificates) service customers - our internet service provider, our In parts world dysfunctional unjust governments represent huge obstacle improving everyday life, progress achievement people hope realise limited of\u00a0this. there viable alternative passport jurisdiction renowned forgery, credit rating acknowledged land holdings despited governments inability maintain credible database, begin travel, trade enjoy benefits citizens western states take for\u00a0granted. I\u2019m excited get skills innovative tech company aiming something Services include secure ID systems, asset registry dispute resolution. Identification (in particular) area full problems, blockchain tech offer really significant improvements. Bitnation wants create platform where voluntary nations created administered, where people choose jurisdictional system part of. widely implemented Jurisdictions offer their own services according their own principles, easy create membership voluntarily, jurisdictions compete attract citizens. should lead improvements users service, intended provide alternative slow, expensive opaque processing methods commonly associated services geographically","tag":"[, , , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Create a Multi-Signature Ethereum wallet using\u00a0Parity","url":"ethereum-parity-multisig-wallet.html","body":"recently set multi-sig Ethereum wallet couldn\u2019t find clear instructions. Here are, hope these instructions useful someone looking get\u00a0started. You\u2019ll way interact Ethereum blockchain order deploy wallet. There several apps use. I\u2019ve Parity found simple and\u00a0quick. Wallets contract there two types wallet, Multi-Sig wallet Watch wallet. An Ethereum account required communicate contract want multi-sig wallet 3 signatories (for example) set least those 3 Ethereum accounts before creating the\u00a0wallet. Parity From their\u00a0website: Integrated directly Web browser, Parity fastest most secure way interacting You bunch stuff Parity including mining Ether, manage accounts, interact different dapps, send/receive different accounts, set contracts. On accounts tab, quickly set wallets. Chrome plugin also get handy notifications transactions confirmed Download open\u00a0Parity For MacOS download install Parity visiting Parity site downloading installer, terminal curl or\u00a0Homebrew. Simple\u00a0option $ bash <(curl -kL) Homebrew Detailed instructions here. brew tap brew install parity --stable installer, open Parity opening app logo the\u00a0menubar. Brew, start Parity parity go following address your\u00a0browser: You should now see something similar to\u00a0this: Add Select Accounts tab top page select \u201c+ Account\u201d. Either create accounts import them preferred method. You don\u2019t import accounts part multi-sig wallet, import create account own wallet create. account large enough Ether balance pay transaction costs deploy multi-sig wallet onto Blockchain. costs tiny, greater than\u00a0zero. Create Once you\u2019ve either created imported account deploy wallet, select \u201c+ Wallet\u201d accounts tab choose \u201cMulti-Sig wallet\u201d. Click\u00a0next. Enter name wallet, want add local description. \u201cFrom account\u201d contract owner account\u00a0will Be Need enough Ether pay execution contract Click \u201c+\u201d button under \u201cOther wallet owners\u201d add address other signatory accounts. You\u2019ll add signatory these accounts also own wallet once is\u00a0deployed. In \u201crequired owners\u201d section, specify accounts approve transaction above daily Use \u201cwallet day limit\u201d set much Ether spent account per day without needing another account approve transaction. Set amount want transactions require approval, turn option off slider right (which just specifies huge\u00a0number). Click \u201cnext\u201d you\u2019ll shown pop-up window approve creation wallet. You enter password account creating wallet, once click \u201cConfirm request\u201d funds creators accounts deploy contract chain create Adding existing Once wallet created deployed, you\u2019ll add other parity clients other signatories confirm transactions, view wallets balance. done adding watch\u00a0wallet. Process: Accounts tab > + Wallet > Watch wallet > enter address other signatories now able view wallet\u2019s balance, get notifications pending confirmations, able Managing Anyone put funds wallet, just account. Just send Ether At top page click \u201cEdit\u201d change local name description the\u00a0wallet. \u201cSettings\u201d allows add remove owners (signatories) wallet change required approvals wallet day limit. change these settings changes executed blockchain account requesting change therefore pay required funds. Depending settings being changed, other accounts approve changes before \u201cForget\u201d remove multi-sig wallet accounts\u00a0tab. Moving funds Click \u201cTransfer\u201d wallet management window (pictured above) begin withdrawing funds the\u00a0wallet. Select token want transfer - Ethereum \u201cSender address\u201d - specify account wants withdraw funds \u201cRecipient address\u201d - specify account receive the\u00a0funds. \u201cAmount transfer\u201d - specify much want transfer. amount greater remaining daily limit get warning bar telling transaction require confirmation other wallet\u00a0owners. want specify maximum transaction fee (a payment lower fee confirmed slowly usual) tick \u201cadvanced sending options\u201d\u00a0box. Clicking \u201csend\u201d bring confirmation stage where enter password account requesting the\u00a0transfer. approval other wallet owners required also Parity, see their approval required two ways: signer tab show there pending request. wallet management window (accessed accounts tab) \u201cpending transactions\u201d section where any confirmation requests shown.","tag":"[, , , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Macro analysis of the Bitcoin\u00a0blockchain","url":"macro-btc.html","body":"Table transaction confirmation block size (daily, MB)4\u00a0\u00a0Average transactions per (1MB) fees earned miners day6\u00a0\u00a0Ratio transaction fees transaction transactions per day8\u00a0\u00a0Bitcoin price9\u00a0\u00a0Ratio unique addresses between series In\u00a0[1]: import HTML function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document </script> <font> analysis made Python. you'd see code used, click <a ''') Out[1]: function code_toggle() { (code_show){ } else { } code_show =! code_show } $( document analysis made Python. you\u2019d see code used, click here. window.onload = function() { code_toggle(); }; In\u00a0[2]: ## Steup - libraries import quandl import plt import pandas pd import datetime dt import numpy np import credentials # keep quandl plot.ly api keys private import plotly.plotly py import plotly #from import Scatter, Layout import go #from import * In\u00a0[3]: ## Setup - appearance # get rid annoying warning = None # default='warn' # print unassigned variable import = \"all\"; # offline plotly color1 = '#137a28' # dark green color2 = '#b3d1b9' # light transparent green exports, module) {/** * plotly.js v1.28.3 * Copyright 2012-2017, Plotly, Inc. * All rights reserved. * Licensed under MIT license */ t;return function a(o,!0);var u=new Error(\"Cannot find module i(t,e){return t.y-e.y}var r(t){return r(t){return u(){function t(t,e){return e(t,e){return c(t){return h(t){return t.value}var t(t){var \"+s+\",\"+c+\" \"+o+\",\"+u+\" e=.5;return n(t){var n=a(t,new e?e:1,r=r||\": \";var n(t,e){for(var r=new instanceof function y(t){var e}function b(t,e,r,n){var e)throw argument expected unwanted i}var r=new t};var e=[];for(var r n(t){for(var n(t){return n(t){var i=new e=t|t-1;return i}function l(t){for(var e=new e}function ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff ffffffff 00000000 00000000 ffffffff ffffffff fffffffe ffffffff t){var greater instanceof safely store 53 n(void array length 26;var e=t,r=0;return 0;for(var t&&t>=0);var t&&t>=0);var a(1);for(var t&&t>=0);var works positive a(0),mod:new a(0)};var i,o,s;return i=new a(1),o=new a(0),s=new a(0),l=new i=new a(1),o=new f;return A[t];var p;else m;else Error(\"Unknown prime \"+t);e=new g}return works works red works works red l}}}function s(t){return l(t,e){return 1:return s(t);case 3:return Invalid n(t,e,r){var \"+r);var n(t,e){var i=\"for(var i=n[t];return var P=C+1;PZ)throw typed array length\");var e=new e)throw Error(\"If encoding specified first argument l(t)}return t)throw argument instanceof t)throw argument allocate Buffer larger maximum size: bytes\");return 0|t}function instanceof 0;for(var 0:return v(t,e,r){var n=!1;if((void hex E(n)}function E(t){var access beyond buffer argument Buffer a}function U(t){for(var a}function H(t){return i}function Y(t){return t!==t}var t=new browser lacks typed array (Uint8Array) support required `buffer` v5.x. Use `buffer` v4.x require old browser 0;for(var ... range 0;for(var 0)}var write outside buffer encoding: Error(\"Invalid string. Length multiple i(t){return a(t){var o(t){return i(t,e){return a(t,e){for(var i(g,d,v,h),new n(t){var i(t,e){for(var r=new s}function m(t,e,r){var i=new n(t){var strict\";var t;var Error(f+\" map requires nshades least size i(t,e,r,i){var 0}return n(t,e){return t-e}function i(t,e){var 0:return 0;case 1:return t[0]-e[0];case 2:return 3:var i;var 4:var n(t){var t}function i(t){return a(t){return o(t){return null}var null;var a}return a}return i(t){var e=new i=0;i0)throw Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array args\")}else Error(\"cwise: pre() block may reference array Error(\"cwise: post() block may reference array index\")}else Error(\"cwise: Too arguments pre() Error(\"cwise: Too arguments body() Error(\"cwise: Too arguments post() block\");return n(t,e,r){var l(t,e){for(var w=new cwise routine n(t){var e=[\"'use strict'\",\"var function (!(\"+l.join(\" && \")+\")) throw Error('cwise: Arrays same {\"),e.push(\"if (!(\"+u.join(\" && \")+\")) throw Error('cwise: Arrays same i(t,e,r){var m,v=new t;var e=[];for(var r e=[];for(var r e=[];for(var r n&&void e(t,e){var r}function r(){}function n(t){var e;return y(t){return b(t){return Error(\"unknown type: i(t,e){for(var r,n,i=new i(){if(s){var t(t){var r(t){var Array(o),l=new this;var 1:do{o=new 2:do{o=new 3:do{o=new t=[];return s(){var l(){for(var a(t){return n}}}function l(t){return u(t){for(var e}function c(t,e){for(var r p(t){return f(t)in this._&&delete v(){var t=[];for(var e t}function g(){var t=0;for(var e t}function y(){for(var x(t){return t}function function(){var w(t,e){if(e t)return Z(t,e){return J(t,e){var K(t){var vt(t){return gt(t){return yt(t){return _t(t){return wt(t){return kt(t,e,r){var Ot(){for(var t}function Ft(){for(var Nt(t){var b=u&&h;return Bt(t){return t+\"\"}function n(e){var e}function Gt(t,e,r){var le(t){var ce(t){for(var ge(t){var ye(t,e){return we(t){var ke(t,e){return y}}function Fe(t){return Re(){var r=e;return r(t){var a(t,e){return o(t,e){var l(t){for(var c(i,a){return Je(){function s}function 1,1 1,1 $e(){function t(t,n){var er(){function t(t,e){var rr(t){function s}function nr(t){function r(e){return n(e){function a(r,n){var k}function ir(t){var sr(t){return t})()}function lr(t){function e(t){return i(){return ur(t){return r(t,e){var Vr(t,e){var n;var s;var Hr(t,e){var Vr(r,e);var Gr(t){for(var r}function wn(t,e){var kn(t){return An(t){return 1;var Zn(t,e){var n}function bi(t){return xi(t,e){return _i(t,e){return Ei(t){function Ni(t){return t.y})}function Bi(t){return Ui(t){var Vi(t){var qi(t,e){var a(t){return o(t)}var o,s;return Qi(t,e){return $i(t,e){return a(t){return o(e){return t(i(e))}return _a(t){function e(e){function Ma(t){return ka(t){for(var Aa(t){for(var p[n]:delete t[r],1}var io(t){return n(e){return t(e)}function i(t,r){var r};var t;var e=new b;if(t)for(var h(){function f(){function t(){var r(){var n(){var o;if(i)return i=!1,a;var e=new ms={\"-\":\"\",_:\" %b %e %X this.s}};var bs=new e(e,r){var t(){var e(){return }var t(e,r,n,i){var c}function e(t){for(var r}function t(t,a){var t(t,e){for(var i(t,e,r,n){var \"+e}function 0,0 \"+n}var t(t,i){var \"+l[2]+\" \"+l[3]}var 0,\"+e+\" \"+e+\",\"+e+\" a(){function v(){var l;var t;e||(e=t);var e}function s(t){var l(t,e,r,n){var u(t,e,r){var n=t;do{var n}function l=t;do{for(var h(t,e,r,n){var r}function m(t,e,r,n){var v(t){var t}function x(t,e){return w(t,e){return k(t,e){var A(t,e){return n(t,e){var e){e=0;for(var warning: possible EventEmitter memory leak detected. %d listeners added. Use increase function\");var n=!1;return e=typeof o(t,e,r,n){var \"+i+\"=== typeof s(t,e){return e.length> 1; (a[m] === v) true; (a[m] > v) j = m - 1; else i = m + 1;}return false; }(\"+n+\", u(t){return p\"}function h(t,e){return c[1]){var s[e][t];var i(t){return a(t,e){return r}var 0)}function d(t){for(var m(t){return t=[];return t=[];return 1:return 2:return this.tree;var e=new i=0;i0)return Error(\"Can't update empty node!\");var r=new s(t){for(var z%d-%d-%d (features: %d, points: %d, simplified: down parent tile down\");var i(t,e,r){var s}function i(t,e,r,n){var s(t,e){var r=new i(t);return e(e,r,n){if(n t){var U=g,V=_,k=0;k 0.0) {\\n nPosition = mix(bounds[0], bounds[1], 0.5 * (position + 1.0));\\n gl_Position = projection * view * model * 1.0);\\n } else {\\n gl_Position = }\\n colorChannel = GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = colorChannel.x * colors[0] + \\n colorChannel.y * colors[1] +\\n colorChannel.z * vectorizing d=new o(t,e,r,n){var s;var r}function a(t,e){for(var r=0;rr)throw resizing buffer, specify a(t,e){for(var Invalid webgl buffer, either Invalid usage buffer, either gl.STATIC_DRAW t&&void Cannot specify offset resizing Error(\"gl-fbo: Can't resize FBO, invalid Error(\"gl-fbo: Parameters too large Error(\"gl-fbo: Multiple draw buffer extension Error(\"gl-fbo: Context does support \"+s+\" draw buffers\")}}var Error(\"gl-fbo: Context does support floating point h=!0;\"depth\"in Error(\"gl-fbo: Shape vector length 2\");var null;var 0.25) {\\n discard;\\n }\\n gl_FragColor = GLSLIFY 1\\n\\nattribute aHi, aLo, pick0, scaleHi, translateHi, scaleLo, translateLo, pickA, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n = width * * vec2(dHi.y, -dHi.x)) / gl_Position = vec4(p + n, 0, 1);\\n pickA = pick0;\\n pickB = GLSLIFY 1\\n\\nuniform pickA, pickB;\\n\\nvoid main() {\\n fragId = 0.0);\\n if(pickB.w > pickA.w) {\\n fragId.xyz = pickB.xyz;\\n }\\n\\n fragId += fragId.y += floor(fragId.x / 256.0);\\n fragId.x -= floor(fragId.x / 256.0) * 256.0;\\n\\n fragId.z += floor(fragId.y / 256.0);\\n fragId.y -= floor(fragId.y / 256.0) * 256.0;\\n\\n fragId.w += floor(fragId.z / 256.0);\\n fragId.z -= floor(fragId.z / 256.0) * 256.0;\\n\\n gl_FragColor = fragId / GLSLIFY 1\\n\\nattribute aHi, aLo, scaleHi, translateHi, scaleLo, translateLo, projectValue, scHi, trHi, scLo, trLo, posHi, posLo) {\\n (posHi + trHi) * scHi\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * main() {\\n p = translateHi, scaleLo, translateLo, aHi, aLo);\\n if(dHi.y e+n;var null;var FLOAT_MAX) {\\n vec4(127.0, 128.0, 0.0, 0.0) / 255.0;\\n } else if(v \"+t[1]+\", \"+t[2]+\", t=new e=new r=new \"+t[1]+\", n=\"precision GLSLIFY 1\\n\\nuniform f_id;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n gl_FragColor = vec4(pickId, GLSLIFY 1\\n\\nattribute position, uv;\\n\\nuniform model\\n , view\\n , eyePosition\\n , f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n m_position = model * vec4(position, 1.0);\\n t_position = view * m_position;\\n gl_Position = projection * t_position;\\n f_color = color;\\n f_normal = normal;\\n f_data = position;\\n f_eyeDirection = eyePosition - position;\\n = lightPosition - position;\\n f_uv = GLSLIFY 1\\n\\nfloat x, roughness) {\\n NdotH = max(x, 0.0001);\\n cos2Alpha = NdotH * NdotH;\\n tan2Alpha = (cos2Alpha - 1.0) / cos2Alpha;\\n roughness2 = roughness * roughness;\\n denom = * roughness2 * cos2Alpha * cos2Alpha;\\n exp(tan2Alpha / roughness2) / roughness,\\n fresnel) {\\n\\n VdotN = 0.0);\\n LdotN = 0.0);\\n\\n //Half angle vector\\n H = + //Geometric term\\n NdotH = H), 0.0);\\n VdotH = H), 0.000001);\\n LdotH = H), 0.000001);\\n G1 = (2.0 * NdotH * VdotN) / VdotH;\\n G2 = (2.0 * NdotH * LdotN) / LdotH;\\n G = min(1.0, min(G1, G2));\\n \\n //Distribution term\\n D = //Fresnel term\\n F = pow(1.0 - VdotN, fresnel);\\n\\n //Multiply terms done\\n G * F * D / max(3.14159265 * VdotN, roughness\\n , fresnel\\n , kambient\\n , kdiffuse\\n , kspecular\\n , sampler2D f_normal\\n , , , f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n N = L = V = \\n {\\n N = -N;\\n }\\n\\n specular = V, N, roughness, fresnel);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n surfaceColor = f_color * f_uv);\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = litColor * GLSLIFY 1\\n\\nattribute uv;\\n\\nuniform model, view, f_uv;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_color = color;\\n f_data = position;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n || \\n {\\n discard;\\n }\\n\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute uv;\\nattribute model, view, f_uv;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n }\\n gl_PointSize = pointSize;\\n f_color = color;\\n f_uv = GLSLIFY 1\\n\\nuniform sampler2D f_uv;\\n\\nvoid main() {\\n pointR = - if(dot(pointR, pointR) > 0.25) {\\n discard;\\n }\\n gl_FragColor = f_color * f_uv) * GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute id;\\n\\nuniform model, view, f_id;\\n\\nvoid main() {\\n || \\n {\\n gl_Position = } else {\\n gl_Position = projection * view * model * vec4(position, 1.0);\\n gl_PointSize = pointSize;\\n }\\n f_id = id;\\n f_position = GLSLIFY 1\\n\\nattribute model, view, main() {\\n gl_Position = projection * view * model * vec4(position, GLSLIFY 1\\n\\nuniform main() {\\n gl_FragColor = i(t){for(var null;for(var function(){var E=new s(\"\",\"Invalid attribute \"+h+\": s(\"\",\"Unknown attribute \"+h+\": \"+f);var s(\"\",\"Invalid attribute \"+h+\": n(t){return i(t,e){for(var r=new s(\"\",\"Invalid uniform dimension matrix \"+name+\": s(\"\",\"Unknown uniform \"+name+\": \"+r)}var s(\"\",\"Invalid vector \"+name+\": r=[];for(var e){var r}function h(e){for(var n=[\"return function s(\"\",\"Invalid s(\"\",\"Invalid uniform dimension matrix \"+name+\": \"+t);return i(r*r,0)}throw s(\"\",\"Unknown uniform \"+name+\": \"+t)}}function i){var p(t){var r=0;r1){l[0]in u=1;u1)for(var l=0;l=0){var t||t}function s(t){function r(){for(var u=0;u 1.0) {\\n discard;\\n }\\n baseColor = color, step(radius, gl_FragColor = * baseColor.a, GLSLIFY 1\\n\\nattribute mat3 main() {\\n hgPosition = matrix * vec3(position, 1);\\n gl_Position = 0, gl_PointSize = pointSize;\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var instanceof instanceof null;var n(t,e,r,n){var GLSLIFY 1\\n\\n\\nvec4 posHi, posLo, scHi, scLo, trHi, trLo) {\\n vec4((posHi + trHi) * scHi\\n \\t\\t\\t//FIXME: thingy does give noticeable precision gain, test\\n + (posLo + trLo) * scHi\\n + (posHi + trHi) * scLo\\n + (posLo + trLo) * scLo\\n , 0, positionHi, size, char, 64-bit form scale scaleHi, scaleLo, translateHi, sampler2D charColor, main() {\\n charColor = vec2(color.x / 255., 0));\\n borderColor = vec2(color.y / 255., 0));\\n\\n gl_PointSize = size * pixelRatio;\\n pointSize = size * charId = char;\\n borderWidth = border;\\n\\n gl_Position = positionHi, positionLo,\\n scaleHi, scaleLo,\\n translateHi, pointCoord = viewBox.xy + (viewBox.zw - viewBox.xy) * * .5 + GLSLIFY 1\\n\\nuniform sampler2D charsStep, pixelRatio, main() {\\n\\tvec2 pointUV = (pointCoord - + pointSize * .5) / = 1. - texCoord = ((charId + pointUV) * charsStep) / dist = alpha\\n\\tif (dist t;){var w.push(new i(){var a(t,e){var e=void null;var characters maximum texture size. Try reducing x=0;x 1.0) {\\n discard;\\n }\\n baseColor = color, alpha = 1.0 - pow(1.0 - baseColor.a, fragWeight);\\n gl_FragColor = * alpha, GLSLIFY 1\\n\\nvec4 pfx_1_0(vec2 scaleHi, scaleLo, translateHi, translateLo, positionHi, positionLo) {\\n + translateHi) * scaleHi\\n + (positionLo + translateLo) * scaleHi\\n + (positionHi + translateHi) * scaleLo\\n + (positionLo + translateLo) * scaleLo, 0.0, positionHi, scaleHi, scaleLo, translateHi, main() {\\n\\n id = pickId + pickOffset;\\n id.y += floor(id.x / 256.0);\\n id.x -= floor(id.x / 256.0) * 256.0;\\n\\n id.z += floor(id.y / 256.0);\\n id.y -= floor(id.y / 256.0) * 256.0;\\n\\n id.w += floor(id.z / 256.0);\\n id.z -= floor(id.z / 256.0) * 256.0;\\n\\n gl_Position = scaleLo, translateHi, translateLo, positionHi, positionLo);\\n gl_PointSize = pointSize;\\n fragId = GLSLIFY 1\\n\\nvarying main() {\\n radius = length(2.0 * - 1.0);\\n if(radius > 1.0) {\\n discard;\\n }\\n gl_FragColor = fragId / i(t,e){var e(e,r){return e n(t,e){var r)return r[t];for(var o=r.gl d(t){var null;var a(t,e){return E=new i(t,e){var r=new n(t);return 0.0 ||\\n || {\\n discard;\\n }\\n\\n N = V = L = {\\n N = -N;\\n }\\n\\n specular = V, N, roughness);\\n diffuse = min(kambient + kdiffuse * max(dot(N, L), 0.0), 1.0);\\n\\n //decide interpolate \\u2014 vertex fragment\\n surfaceColor = .5) * vec2(value, value)) + step(.5, vertexColor) * vColor;\\n\\n litColor = surfaceColor.a * vec4(diffuse * + kspecular * vec3(1,1,1) * specular, 1.0);\\n\\n gl_FragColor = mix(litColor, contourColor, contourTint) * GLSLIFY 1\\n\\nattribute uv;\\nattribute f;\\n\\nuniform mat3 model, view, height, sampler2D value, kill;\\nvarying eyeDirection, main() {\\n dataCoordinate = permutation * vec3(uv.xy, height);\\n worldPosition = model * 1.0);\\n\\n clipPosition = projection * view * clipPosition.z = clipPosition.z + zOffset;\\n\\n gl_Position = = f;\\n kill = -1.0;\\n = = uv.zw;\\n\\n vColor = vec2(value, value));\\n\\n //Don't lighting contours\\n surfaceNormal = vec3(1,0,0);\\n eyeDirection = vec3(0,1,0);\\n lightDirection = GLSLIFY 1\\n\\nuniform value, kill;\\nvarying v) {\\n vh = 255.0 * v;\\n upper = floor(vh);\\n lower = fract(vh);\\n vec2(upper / 255.0, floor(lower * 16.0) / main() {\\n if(kill > 0.0 ||\\n || {\\n discard;\\n }\\n ux = / shape.x);\\n uy = / shape.y);\\n gl_FragColor = vec4(pickId, ux.x, uy.x, ux.y + i(t){var o(t,e){var invalid coordinates Invalid texture size\");return s(t,e){return Invalid ndarray, 2d 3d\");var Invalid shape Invalid shape pixel Incompatible texture format Invalid texture Floating point textures supported platform\");var s=u(t);return s=u(t);return f(t,e){var Invalid texture size\");var Invalid shape Invalid shape pixel b=u(t);return Error(\"gl-vao: Too vertex n(t,e,r){var i=new n(t){for(var n(t,e){var n(t,e,r){var instanceof a=new a(t,e){return o(t){for(var e=[\"function orient(){var orient\");var n=new a(t,e){var o(t,e){var s(t,e){var i}}function c(t,e){for(var s(this,t);var s(this,t);var b}for(var r}return n}return l}function i(t,e,r,n){var n(t,e){var r;if(h(t)){var Error('Unknown function -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n x_a = / 1.0);\\n x_b = / 1.0);\\n y_a = 0.5 + (v_normal.y * v_linewidth.s / y_b = 0.5 + (v_normal.y * v_linewidth.s / pos_a = vec2(x_a, y_a));\\n pos_b = vec2(x_b, y_b));\\n\\n = pos_a), pos_b), u_fade);\\n\\n alpha *= u_opacity;\\n\\n gl_FragColor = * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n v_linesofar = // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define sampler2D main() {\\n // Calculate distance pixel pixels.\\n dist = * // Calculate antialiasing fade factor. either fading in\\n // case offset fading out\\n // blur = u_blur * alpha = clamp(min(dist - (v_linewidth.t - blur), v_linewidth.s - dist) / blur, 0.0, 1.0);\\n\\n sdfdist_a = v_tex_a).a;\\n sdfdist_b = v_tex_b).a;\\n sdfdist = mix(sdfdist_a, sdfdist_b, u_mix);\\n alpha *= smoothstep(0.5 - u_sdfgamma, 0.5 + u_sdfgamma, sdfdist);\\n\\n gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define floor(127 / 2) == 63.0\\n// maximum allowed miter limit 2.0 moment. extrude is\\n// stored byte (-128..127). scale regular normals length 63, but\\n// there also \\\"special\\\" normals bigger length (of 126 in\\n// case).\\n// #define scale 63.0\\n#define scale We scale distance before adding buffers store\\n// long distances long segments. Use unscale mat2 main() {\\n a_extrude = a_data.xy - 128.0;\\n a_direction = mod(a_data.z, 4.0) - 1.0;\\n a_linesofar = / 4.0) + a_data.w * 64.0) * // We store texture normals most insignificant bit\\n // transform y => -1 => 1\\n // In texture normal, x points straight up/down it's round cap\\n // y points up, -1 points down\\n = mod(a_pos, 2.0);\\n normal.y = sign(normal.y - 0.5);\\n v_normal = normal;\\n\\n inset = u_gapwidth + (u_gapwidth > 0.0 ? u_antialiasing : 0.0);\\n outset = u_gapwidth + u_linewidth * (u_gapwidth > 0.0 ? 2.0 : 1.0) + // Scale extrusion vector down width\\n // vertex.\\n dist = outset * a_extrude * scale;\\n\\n // Calculate offset drawing side actual line.\\n // We creating vector points towards extrude, rotate\\n // we're drawing round end points (a_direction = -1 1) since their\\n // extrude vector points another direction.\\n u = 0.5 * a_direction;\\n = 1.0 - abs(u);\\n offset = u_offset * a_extrude * scale * normal.y * mat2(t, -u, u, t);\\n\\n // Remove texture bit position before scaling the\\n // model/view matrix.\\n gl_Position = u_matrix * * 0.5) + (offset + dist) / u_ratio, 0.0, 1.0);\\n\\n v_tex_a = * normal.y * + u_tex_y_a);\\n v_tex_b = * normal.y * + // position y screen\\n y = gl_Position.y / // much features squished y direction tilt\\n squish_scale = / * // much features squished directions = 1.0 / (1.0 - min(y * u_extra, 0.9));\\n\\n v_linewidth = vec2(outset, inset);\\n v_gamma_scale = * lowp\\n#define mapbox: define mapbox: define v_pos;\\n\\nvoid main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n dist = length(v_pos - alpha = 0.0, dist);\\n gl_FragColor = outline_color * (alpha * gl_FragColor = lowp\\n#define mapbox: define mapbox: define main() {\\n #pragma mapbox: initialize #pragma mapbox: initialize opacity\\n\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D v_pos;\\n\\nvoid main() {\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n // find distance outline alpha dist = length(v_pos - alpha = 0.0, dist);\\n \\n\\n gl_FragColor = mix(color1, color2, u_mix) * alpha * gl_FragColor = lowp\\n#define v_pos;\\n\\nvoid main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / v_pos = / gl_Position.w + 1.0) / 2.0 * lowp\\n#define sampler2D main() {\\n\\n imagecoord = mod(v_pos_a, 1.0);\\n pos = imagecoord);\\n color1 = pos);\\n\\n imagecoord_b = mod(v_pos_b, 1.0);\\n pos2 = color2 = pos2);\\n\\n gl_FragColor = mix(color1, color2, u_mix) * gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n scaled_size_a = u_scale_a * scaled_size_b = u_scale_b * // correct offset needs calculated.\\n //\\n // offset depends pixels between world origin and\\n // edge tile:\\n // offset = size)\\n //\\n // At high zoom levels there ton pixels between world origin\\n // edge tile. glsl spec guarantees 16 bits of\\n // precision floats. We that.\\n //\\n // pixel_coord passed two 16 bit values:\\n // = / 2^16)\\n // = 2^16)\\n //\\n // offset calculated series steps should preserve precision:\\n offset_a = scaled_size_a) * 256.0, scaled_size_a) * 256.0 + offset_b = scaled_size_b) * 256.0, scaled_size_b) * 256.0 + v_pos_a = * a_pos + offset_a) / v_pos_b = * a_pos + offset_b) / lowp\\n#define sampler2D sampler2D main() {\\n\\n // read cross-fade colors parent tiles\\n color0 = v_pos0);\\n color1 = v_pos1);\\n = color0 * u_opacity0 + color1 * u_opacity1;\\n rgb = color.rgb;\\n\\n // spin\\n rgb = vec3(\\n dot(rgb, dot(rgb, dot(rgb, // saturation\\n average = (color.r + color.g + color.b) / 3.0;\\n rgb += (average - rgb) * // contrast\\n rgb = (rgb - 0.5) * + 0.5;\\n\\n // brightness\\n u_high_vec = u_low_vec = gl_FragColor = u_low_vec, rgb), gl_FragColor = lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1);\\n v_pos0 = / 32767.0) - 0.5) / u_buffer_scale ) + 0.5;\\n v_pos1 = (v_pos0 * + lowp\\n#define sampler2D sampler2D main() {\\n alpha = v_fade_tex).a * u_opacity;\\n gl_FragColor = v_tex) * gl_FragColor = lowp\\n#define matrix vertex bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n extrude = * (a_offset / 64.0);\\n {\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * } else {\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define sampler2D sampler2D main() {\\n dist = v_tex).a;\\n fade_alpha = gamma = u_gamma * alpha = - gamma, u_buffer + gamma, dist) * gl_FragColor = u_color * (alpha * gl_FragColor = lowp\\n#define PI = matrix vertex bool bool main() {\\n a_tex = a_labelminzoom = a_data[0];\\n a_zoom = a_data.pq;\\n a_minzoom = a_zoom[0];\\n a_maxzoom = a_zoom[1];\\n\\n // u_zoom current zoom level adjusted change font size\\n z = 2.0 - u_zoom) - (1.0 - u_zoom));\\n\\n // map\\n // map | viewport\\n {\\n angle = ? (a_data[1] / 256.0 * 2.0 * PI) : u_bearing;\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, asin, -1.0 * asin, acos);\\n offset = RotationMatrix * a_offset;\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos + extrude, 0, 1);\\n gl_Position.z += z * // viewport\\n // map\\n } else {\\n // foreshortening factor apply pitched maps\\n // label goes horizontal vertical angle\\n // goes 0% foreshortening around 70% pitchfactor = 1.0 - cos(u_pitch * sin(u_pitch * 0.75));\\n\\n lineangle = a_data[1] / 256.0 * 2.0 * PI;\\n\\n // lineangle position points a,b along line\\n // project points calculate label angle projected space\\n // calculation allows labels rendered unskewed pitched maps\\n = u_matrix * vec4(a_pos, 0, 1);\\n b = u_matrix * vec4(a_pos + 0, 1);\\n angle = - b[0]/b[3] - a[0]/a[3]);\\n asin = sin(angle);\\n acos = cos(angle);\\n mat2 RotationMatrix = mat2(acos, -1.0 * asin, asin, acos);\\n\\n offset = RotationMatrix * 1.0) * a_offset);\\n extrude = * (offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n gl_Position.z += z * // viewport\\n // viewport\\n } else {\\n extrude = * (a_offset / 64.0);\\n gl_Position = u_matrix * vec4(a_pos, 0, 1) + vec4(extrude, 0, 0);\\n }\\n\\n v_gamma_scale = (gl_Position.w - 0.5);\\n\\n v_tex = a_tex / u_texsize;\\n v_fade_tex = / 255.0, lowp\\n#define main() {\\n\\n alpha = 0.5;\\n\\n gl_FragColor = vec4(0.0, 1.0, 0.0, 1.0) * alpha;\\n\\n > u_zoom) {\\n gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0) * alpha;\\n }\\n\\n (u_zoom >= v_max_zoom) {\\n gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0) * alpha * 0.25;\\n }\\n\\n >= u_maxzoom) {\\n gl_FragColor = vec4(0.0, 0.0, 1.0, 1.0) * alpha * 0.2;\\n lowp\\n#define main() {\\n gl_Position = u_matrix * vec4(a_pos + a_extrude / u_scale, 0.0, 1.0);\\n\\n v_max_zoom = a_data.x;\\n = values, const t) {\\n (t 7)return[new been deprecated v8\")];if(!(l \"%s\" strict\";var a(l,e,\"array expected, %s a(l,e,\"array length %d expected, length %d r?[new been deprecated v8\")]:[];var n(e,r,\"object expected, %s found\",a)];var o=[];for(var s start \"@\"'));return strict\";var [%s], %s strict\";var t(e){var n(l,s,\"array expected, %s n(l,s,'\"$type\" cannot operator n(l,s,'filter array operator \"%s\" 3 expected, %s key cannot functions functions strict\";var url include \"{fontstack}\" url include \"{range}\" strict\";var n(c,r,'either \"type\" \"ref\" i(e,r,\"%s greater maximum strict\";var n(e,r,\"object expected, %s f r){var property n(e,r,'missing required property strict\";var i(e,o,'unknown property strict\";var n(r,e,'\"type\" e)for(var c a(t){return Sans Unicode MS M=new n){for(var symbols being rendered tile. See glyphs being rendered tile. See exceeds allowed extent, reduce vector tile buffer size\")}return Error(\"Invalid LngLat object: (\"+t+\", x(){return y(){return point(){return instanceof 0===s&&void a(void Error(\"failed invert strict\";var n={\" strict\";var s(t){return l(t,e,r,n){var o=(new n(t,e){return mapbox: ([\\w]+) ([\\w]+) ([\\w]+) a=new n?e(new Error(\"Input valid GeoJSON t.data)return e(new Error(\"Input valid GeoJSON e(new Error(\"Input valid GeoJSON e=0;ee)){var y;for(y p)c[y]=!0;var i(t,e,i){var r(t,r){return delete e(t);var n=new o(new e=new tile source layer \"'+M+'\" does vector tile spec v2 therefore may rendering g(t,L);var F B n=new t.time>=(new t=new i;var strict\";var Error(\"Invalid o[e]}throw Error(\"Invalid r Error('Source layer does exist source \"'+e.id+'\" specified style layer t.id});for(var Error(\"Style done Error(\"There no source ID\");var delete instanceof this;var 0===e)throw Error(\"There no layer ID\");for(var r this;var 0===i||void 0===a?void strict\";var i(t){return t.value}var r,n;for(var i t){var for(n 0===e)delete 0===e)delete o}var strict\";var t){var this.grid=new a}if(r){var _=u;for(var a}}}return r=new r(\"glyphs > 65535 i=!t&&new l(new c(new g(e,r){var y(e,r){var i(0,0));return M a)t[M]=new strict\";var t){var | n(){}var i(t){return 61:case 107:case 171:case 189:case 109:case t=0,e=0;return t=new null!==t&&void Error(\"maxZoom between current minZoom 20, t,e={};return instanceof e;if(t instanceof instanceof c?t:new i(this,e);var Error(\"Failed initialize s if(void if(void n(t){var r=new n(t){for(var e=0;e1)for(var delete error c(t,e,r){var f(t,e){for(var null;var delete Error(\"An API access token required Mapbox GL. See Error(\"Use public access token (pk.*) Mapbox GL JS, secret access token (sk.*). See t}function i(t){return a(t){return t;var n(t){function v[n];void t=0;t=1)return 1;var t={};for(var e =0.22.0 =0.22.0 No README run build-docs # invoked publisher publishing docs mb-pages --debug --standalone mapboxgl > && tap --no-coverage build --github --format html -c --theme ./docs/_theme --output --debug -t unassertify --plugin [minifyify --map --output --standalone mapboxgl > && tap --no-coverage --debug -t envify > --ignore-path .gitignore js test bench diff --name-only mb-pages HEAD -- | awk '{print | xargs build-token watch-dev watch-bench build-token watch-bench build-token watch-dev run build-min && npm run build-docs && jekyll serve --no-cache --localhost --port 9966 --index index.html .\",test:\"npm run lint && tap --reporter dot test/js/*/*.js && node && watchify bench/index.js --plugin [minifyify --no-map] -t [babelify --presets react] -t unassertify -t envify -o bench/bench.js --debug --standalone mapboxgl -o n=new r=new r(t){var n(t,n){var i(t){return t)return t){var 1=0)return V=1;V specify vertex creation specify cell creation specify phase strict\";var n(t){if(t l)return l[t];for(var Invalid boundary dst;};return l){var u){var c){var \"+s),u){var p=new p=new p()}function for(var o=0;o1)for(var f(e,r){var s=\"__l\"+ i=\"__l\"+ _=[\"'use L=new L=new L(r)}function s(t,e){var r=[\"'use [2,1,0];}else [1,0,2];}}else [2,0,1];}else function o=new 0===t){var 0===r){r=new o(t,e){var s(t,e){return a(t,e){var i=new t||\"up\"in strict\";var r=void 0!==r?r+\"\":\" e(t,e){for(var t}function o)throw path.resolve t)throw path.join n(t){for(var Error(\"Given varint doesn't fit bytes\");var o(t,e,r){var s(t,e){for(var type: n(t){var 0:return r||[];case 1:return 2:return Array(t);var r}var r(t,e){var Array(a),new n(t,e){for(var a(t){for(var t-e});var instanceof i(t){return a(t){for(var a=1;i;){var l(t){for(var c(t){return d(t){var u(m)}function p(t){var 0x80 (not basic code x});else for(_ n(t,e){return o;var o};var n(t,e){for(var n&&void e(t){var e=new Error(\"(regl) \"+t);throw n(t){return t?\": i(t,r,i){t r||e(\"unknown parameter possible values: parameter type\"+n(r)+\". typed parameter type\"+n(i)+\". expected \"+r+\", got \"+typeof t)}function parameter type, nonnegative shader source string\",a);var \"+t+\": r=0;e(c(\"| compiling \"+s+\" shader, linking program vertex shader, fragment shader i(t){return M(t,r){var n=m();e(t+\" command called \"+n))}function A(t,e,r,i){t e||M(\"unknown parameter possible values: parameter type\"+n(r)+\". expected \"+e+\", got \"+typeof texture format renderbuffer format L(t,e){return z(t,e,n){var pixel arguments document,\"must manually specify webgl context outside DOM supported, try upgrading browser graphics drivers name string\");var $(t){var et(t,e){var _e:r=new we:r=new Me:r=new ke:r=new Ae:r=new Te:r=new Se:r=new null}return n=0;n0){var t[0]){var buffer data\")}else shape\");var buffer p=new n(a);return d=[];return t=0;return t&&t._buffer instanceof a(t){var e||(e=new Ge:case Xe:case Ze:case element bit element buffers supported, enable first\");var vertex count buffer a}var t&&t._elements instanceof pt(t){for(var At(t){return Tt(t,e){var Or:case Fr:case Rr:case jr:var texture type, specify typed St(t,e){return for(var s}return o*r*n}function texture texture unpack n){var enable extension order floating point enable extension order 16-bit floating point enable extension order depth/stencil texture extension extension d(e,r,i){var m(){return K.pop()||new h}function y(t,e,r){var b(t,e){var e){var e){var e){var e){var e){var i(t,e){var arguments format c=new T(nr);return format C=new z=new I(){for(var for(var P={\"don't care\":$r,\"dont mipmap mipmap mipmap mipmap s3tc dxt1\":Mr,\"rgba s3tc dxt1\":kr,\"rgba s3tc dxt3\":Ar,\"rgba s3tc atc\":Sr,\"rgba atc explicit atc interpolated pvrtc pvrtc pvrtc pvrtc etc1\"]=Pr);var r=B[e];return null});return texture shape z||\"colors\"in render targets buffer enable order floating point framebuffer enable order 16-bit floating point framebuffer enable 16-bit render enable order 32-bit floating point format format extension u=d=1;var for(D=new attachment \"+a+\" attachments much same bits per depth attachment framebuffer stencil attachment framebuffer depth-stencil attachment framebuffer resize framebuffer currently use\");var i;for(var shape framebuffer d||\"colors\"in render targets buffer format l=1;var a(t){var t=0;return vertex fragment shader\",n);var a=i[t];return a||(a=new o(o){var create webgl context order read pixels drawing cannot read framebuffer allowed types 'uint8' framebuffer allowed 'uint8'\"));var arguments buffer regl.read() too s(t){var r;return l(t){return l}function jt(t){return Nt(t){return Bt(){function t(t){for(var r(){function n(){var e=a();return n(){var m(t){return v(t,e,r){var g(t,e,r){var y(){var ei:var ri:return ni:return ii:return ai:return c={};return n=e.id(t);if(n c)return c[n];var b(t){var r){var if(Di n){var e}function x(t,e){var r){var i=r[Pi];return framebuffer n){var a=n[Pi];return framebuffer null}function n(t){if(t i){var a){var \"+t)});var e?new s=o;o=new w(t){function r(t){if(t i){var r});return n.id=r,n}if(t a){var o=a[t];return null}var r(t,r){if(t n){var i){var s=i[t];return n){var i){var o=i[Ri];return n){var t=n[ji];return Be[t]})}if(ji i){var r=i[ji];return \"+n,\"invalid primitive, Aa}):new n){var vertex t})}if(Ni i){var r=i[Ni];return vertex s?new vertex offset/element buffer too l=new k(t,e){var o(e,n){if(t r){var o})}else if(t i){var vi:case si:case oi:case Ai:case hi:case Ci:case xi:case wi:case Mi:case pi:return flag fi:return \"+i,\"invalid \"+t+\", di:return attachment framebuffer sent uniform uniform a[r],\"invalid uniform missing uniform T(t,r){var a&&a,\"invalid attribute offset attribute divisor attribute parameter \"'+r+'\" attribute pointer \"'+t+'\" (valid parameters r)return r[s];var '+a+\"&&(typeof dynamic attribute if(\"constant\" \"+a+'.constant === S(t){var a(t){var parameter L(t,e,r){var C(t,e,r,n){var z(t,e,r){var n=m(e);if(!(n r.state)){var c,h;if(n I(t,e,r,n){var if(mt(u)){var l(t){var ua:case da:case ga:return 2;case ca:case pa:case ya:return 3;case ha:case ma:case ba:return 1}}function attribute i(i){var a=c[i];return a(){function o(){function vertex vertex vertex i(t){return n(e){var n=r.draw[e] s(t){function e(t){var args args e(t){if(t r){var e=r[t];delete delete l(t,e){var regl.clear no buffer takes object cancel frame callback h(){var callback function\");var event, Kt={\"[object renderbuffer renderbuffer arguments renderbuffer r(){return i(t){var s(){return p.pop()||new o}function u(t,e,r){var c(){var t(){var requires least argument; got none.\");var e.href;var \",e);var s=new o;n=-(i+a)}var null;var n(t){return n(t){for(var R;};return i(t){var e=s[t];return strict\";\"use n(t){for(var i}function h(t,e){for(var r=new r}function r=new l(e)}function u(t){for(var e=s(t);;){var t=k[0];return f(t,e){var r=k[t];return n(t,e){var l}else if(u)return l}else if(u)return u;return i(t,e){return t.y-e}function a(t,e){for(var r=null;t;){var t;var r}function l(t){for(var n=d.index;else n(t,e){var i(t,e,r,n){var o(t,e){for(var r}function s(t,e){for(var m}function s[t];for(var unexpected failed parse named argument failed parse named argument mixing positional named placeholders (yet) s[t]=n}var n(t){for(var Array(e),n=new Array(e),i=new Array(e),a=new Array(e),o=new Array(e),s=new x=new u(t){return c(t){var h(t){return f(t){var d(t,e){for(var r t}function p(t){return t.x}function m(t){return t.y}var time\");var r=\"prepare \"+t.length+\" %d clusters c)|0 p=new Array(r),m=new Array(r),v=new Array(r),g=new p=new o}function s}function T(t){return n=z(t);return t){var r={};for(var i e={};for(var r n(t,e){var i(t,e){var s/6}return 1}var n&&void e(t,e){var for(a=0,n=new n})}}var s;var Error(\"n Error(\"already s(t){return l(t){return u(t){return c(t){return h(t){return f(t){return d(t){return p(t){return m(t){return x?new v(t){return n(t)}var null}return t=0;tn)return instanceof n)return t;var i=new n;return a(t){return instanceof o(t,e){return s(t,e){return 'url' string, \"+typeof t);var i(t,e){var a(t,e){var o(t,e){return t}function s(t){var e={};return a;var v=e.name?\": c(e)}var o+\": \"+s}function d(t,e,r){var n=0;return \")+\" \"+t.join(\",\\n \")+\" \"+t.join(\", \")+\" p(t){return t}function v(t){return g(t){return t}function t}function t}function _(t){return 0===t}function w(t){return M(t)&&\"[object k(t){return M(t)&&\"[object A(t){return instanceof t}function S(t){return t||void 0===t}function E(t){return L(t){return t=a)return Error(\"unknown command if(7!==r)throw Error(\"unknown command i(t){for(var e}var Error(\"feature index String too long (sorry, get fixed later)\");var l(t){for(var e(t){var e=n(t);return e?u r(t,e){var o(t){var i?u i&&delete t){var r?r[0]:\"\"}var n?!r&&en)throw al-ahad\",\"Yawm {0} {0} {0} {0} mix {0} {1} a(t,e){return ;var format date another position name position literal position text found dd M MM d, d M d M d M d M yyyy\",RSS:\"D, d M a=this;return var _inline_1_da = - var _inline_1_db = - >= 0) !== (_inline_1_db >= 0)) {\\n + 0.5 + 0.5 * (_inline_1_da + _inline_1_db) / (_inline_1_da - }\\n n(t,e){var r=[];return strict\";var u(r,i){return i(t,e){var E.remove();var null;var strict\";var c();var t}function i(t){var e=x[t];return a(t){return calendar system `\"+t+\"` date data.\"}var i={};return t}var i?\"rgba(\"+s+\", n=i(t);return t){var A(e,r){var T(){var strict\";var strict\";var strict\";var strict\";var strict\";var strict\";var n(){var e(e){return r;try{r=new strict\";var i(t,e,r,n){var a(t){var n.remove();var \")}).split(\" \")}).split(\" scale(\"+e+\", n,i,a;return strict\";var 1,1 0,1 \"+a+\",\"+a+\" \"+a+\",\"+a+\" \"+r+\",\"+r+\" \"+r+\",\"+r+\" 1,1 0,1 1,1 0,1 n(t,e,r,n){var t.id});var strict\";var strict\";var i(t,e,r){var r(t){var r.remove();var r(e,r,o){var if(i[r]){var o;if(void strict\";var n(t){var n(r){return strict\";var n(t){for(var \");var i(t,e){var click legend isolate individual l(t){var u(t){var strict\";var r[1]}return i}function i(t){return t[0]}var h(t){var f(t){var d(t){var n(t,e){var i(t){for(var n(t){for(var 0}}var o(t,e){var 1,1 0,1 extra params segment t(e).replace(\" strict\";var strict\";var u(r,i){return r(t,e){return l(t,e,r){var u(t,e,r){var c(t,e){var n(){return p(t,e){var g(t,e){return y(t,e){return b(t,e,r){var x(t,e){var _(t){for(var r(t,e){return strict\";var strict\";var strict\";var t){var t)return n}function l(t){return u(t){return c(t){return d\")}function h(t){return d, yyyy\")}var t.getTime};var r={};return n=new a(t){return o(t){for(var r={};return n(){return strict\";var for(var c(t){return property r(t,e){var instanceof RegExp){var o(t,e){return t>=e}var binary r=e%1;return n(t){var e=i(t);return n(t,e){return i(t){return \")}function a(t,e,r){var error tex null;var r=0;r1)for(var i=1;i doesnt match end tag . Pretending did s}function c(t,e,r){var o(),void e();var 0,\":\"],k=new t(t,e){return n(t){var i(){var 1px strict\";var strict\";var n(t,e){for(var r=new Error(\"No DOM element id '\"+t+\"' exists page.\");return 0===t)throw Error(\"DOM element provided null previous rejected promises t.yaxis1);var array edits incompatible other edits\",h);var full array edit if(void & removal incompatible edits same full object edit Error(\"each index \"+r+\" Error(\"gd.data 0===e)throw required Error(\"current indices equal u(t,e,r){var Error(\"gd.data 0===e)throw Error(\"traces i(t){return a(t,e){var r=0;return Error(\"This element Plotly plot: \"+t+\". It's likely you've failed create plot before animating it. For details, see c()}function d(t){return overwriting frame frame whose name \"number\" also equates \"'+f+'\". valid may potentially lead unexpected behavior since plotly.js frame names stored internally API call yielded too warnings. For rest call, further warnings numeric frame names addFrames accepts frames numeric names, numbers areimplicitly cast n(t){var i}function i(){var t={};return a(t){var o(){var s(t){return l(t){function u(t){function c(t){return h(t,e,r){var f(t,e,r){var e={};return t&&void n(t){return Error(\"Height width should pixel values.\"));var l(t,e,r){var u(t,e,r,n){var \"+o:s=o+(s?\", dtick p(t,e){var c=new t.dtick){var error: t+i*e;var dtick a(t){for(var strict\";var v(r,n){return enter axis\")+\" e;var n(t,r){for(var n(t,e,r,n){var u(t,e){return y(t){var b(t,e,r){var back X(e,r){var K()}function W(e){function n(e){return k.log(\"Did find wheel motion attributes: \",e);var strict\";var n(t){return t._id}function went wrong axis Error(\"axis o){var t(t){var e(t){return strict\";var r(r,n){var e/2}}function v(t,e){var g(t,e){var b(t,e){var x(t,e){var Error(\"not yet r(t,r){for(var i(){for(var a(t,e){for(var n(t,e){var n(t){return i(t,e,r,n){var a(t,e){return i(t,e){var r(t){return n(t){var l(t,e){var u(t){var c(t,e){var f(t,e,r){var strict\";var i(t){var e=new n;return a(t){var o(t){var i=new n(t,e);return strict\";var Sans Regular, Arial Unicode MS r(t,e){return - delete t)return e,n,i={};for(e i}return r=a(t);return e&&delete P=(new + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + '' + 0px\",\"1px -1px\",\"-1px 1px\",\"1px \"+t+\" \"+n+\" \"+n+\" \"+n+\" c=\"t: \"+u.t+\", r: l;var r t)r r r=e||6;return 0===t)return null;var t(){var t={};return n.mode,delete strict\";var e(e,i){return s;return t(t,e){return i=r[n];return strict\";var t(t,e,r){var e(t,e){return r(t,e){return a(t,i){var tozoom back f(t,e){var i(t){return y,b;return o,s;return ii))return e}return h(t){return f(t,e){return strict\";var strict\";var 0, 0, strict\";var s;return r strict\";var null;for(var strict\";var o(e){var s(e){var strict\";var n(t,e,r){var i(t,e,r){var strict\";var converged strict\";var strict\";var strict\";var strict\";var s(r,i){return n(t,e,r,n){var strict\";var n(t,e){for(var o(t){return strict\";var strict\";var strict\";var c(r,i){return loop contour?\");var s(t,e,r){var 15===r?0:r}var contours, clipping i}function a(t,e,r){var o(t,e,r){var s(t,e,r,n){var e=l(t,r) r(t){return newendpt vert. perimeter scale scale invalid specified inequality contours, clipping strict\";var strict\";var h(t){return newendpt vert. perimeter o(t,e,r){var s(t,e,r){var scale scale strict\";var iterated no strict\";var g}var didn't converge strict\";var s=0;sa){var strict\";var l(r,n){return u(t){var e=l(t);return strict\";var strict\";var e(e){var strict\";var strict\";var r(t,e){return traces support \"+u+\" dimensions c}var l(r,n){return strict\";var l(n){var i}function c(t,e,r){var l(t,e,r){var n=o(r);return u(t,e){return c(t){return h(t){var e=o(t);return f(t){var d(t){return t[0]}function p(t,e,r){var m(t){var v(t){return l(t){var u(t){return c(t,e){for(var e.t+\"px \"+e.r+\"px \"+e.b+\"px 255, 255, 0)\");var 1px 1px #fff, -1px -1px 1px #fff, 1px -1px 1px #fff, -1px 1px 1px strict\";var i(t,e,r){var strict\";var n(t,e){for(var m};var strict\";var o(r,a){return strict\";var strict\";var strict\";var n(t,e,r){var u;var 1;var a(t,e){var r(t,e){return n(t,e){return s(t,e){var 1;var t+\" strict\";var strict\";var strict\";var 0, i(t,e){var r=new for(r=new present Sankey data. Removing nodes strict\";var u(r,a){return n(t){return t.key}function a(t){return t[0]}function o(t){var 0)\":\"matrix(0 0)\")}function M(t){return k(t){return 0)\":\"matrix(0 0)\"}function A(t){return 1)\":\"scale(-1 1)\"}function T(t){return S(t){return L(t,e,r){var var C(t,e,r){var i(){for(var e={};return 1px 1px #fff, 1px 1px 1px #fff, 1px -1px 1px #fff, -1px -1px 1px strict\";var _=new strict\";var strict\";var strict\";var m(r,a){return strict\";var strict\";var strict\";var r(e){var i(t){var strict\";var n(t,e){var + m(t){return v(t){return g(t){return t.id}function g}function x(e){var scatter strict\";var s(t,e){return l(t){return M[t]}function o=0;o=0){var n(t,e,r,n){var strict\";var d(r,i){return s=o[0];if(void 0;var v.push(\"y: strict\";var strict\";var e(t){return r(t){var 1/0;var strict\";var n(t,e){var n}function s(t,e,r,n){var n=new s(t){var 1/0;var strict\";var strict\";var strict\";var strict\";var d(r,i){return strict\";var strict\";var e=f(t);return e=f(t);return e=f(t);return e=f(t);return Unconfirmed transactions\u00b6 In\u00a0[4]: # import mempool downloaded mempool = pd.read_csv( header=None, ) # split datetime date temp = = temp.date = temp.time del # reorder columns cols = mempool = mempool[cols] inplace=True) d2 = mempool = In\u00a0[5]: # there 3 values per day. get average mempool size day mempool = transactions waiting confirmed Bitcoin blockchain increased maximum May 18th 175,978. For comparison, average 2016 less than\u00a010,000. Once unconfirmed transactions had peaked, fell quickly rose mid July generally below 10,000\u00a0again. current state unconfirmed transaction pool along fee rates currently offered seen here. In\u00a0[6]: series1 = go.Scatter( name='Daily average', = dict( = (color2), width = 2,)) series2 = go.Scatter( name='Weekly average', = dict( = (color1), width = 3,)) = [series1, series2] layout = go.Layout( transactions', yanchor='top', y=1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[6]: Median transaction confirmation (minutes)\u00b6I expect average taken confirm transaction increase size unconfirmed transaction pool. figure below shows median minutes transaction be\u00a0confirmed. In\u00a0[7]: # Daily Median taken transactions accepted block, presumably minutes ATRCT = ATRCT = In\u00a0[8]: series1 = go.Scatter( name='Daily median', = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Median taken transactions accepted block', (minutes)'), yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[8]: median transaction confirmation does increase noticeably pool unconfirmed transactions increases, fact two features weak Pearson correlation 0.37 (details below). surprising expected taken confirm transaction increases pool transactions waiting Perhaps valid transactions confirmed included median average calculation, invalid transactions included pool transactions awaiting confirmation. One way test query transactions awaiting confirmation quantify valid fee rate are\u00a0offering. Average block size (daily, MB)\u00b6Each block Bitcoin network had maximum size 1MB before August 2017. As Bitcoin network grown transaction volume increased blocksize limit began limit Was increase unconfirmed transactions correlated blocks getting \u201cfilled up\u201d their maximum 1MB\u00a0size? In\u00a0[9]: # Average block size MB AVBLS = In\u00a0[10]: av_bs = del av_bs['Value'] In\u00a0[11]: series1 = go.Scatter( = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Block size', size (MB)'), yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[11]: From March through June blocksizes seem frequently hit their maximum possible size, suggesting Bitcoin network processing maximum amount possible. increase unconfirmed transactions occurred mid-April end of\u00a0June. average block size began sharp decrease July 2nd, same median transaction confirmation also began quick reduction. By July 2nd unconfirmed transactions had already fallen back (Not transactions same size, transaction any outputs inputs, transaction inputs and/or outputs larger amount transaction input 2\u00a0outputs.) Lets confirm transactions increased over same\u00a0period: Average transactions per (1MB) block\u00b6 In\u00a0[12]: # average transactions per block. day? NTRBL = NTRBL = In\u00a0[13]: series1 = go.Scatter( name='Average transactions per block', = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Average transactions per block', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[13]: average transactions per block hit peak end May 2017 saw two sharp declines. It fell quickly beginning June again beginning of\u00a0July. In June blocksizes remained less large possible suggests blocks were full few large transactions. At size mempool At beginning July transactions per block reduced average blocksize also rapidly reducing. suggests volume smaller transactions had\u00a0reduced. difference average blocksizes early June early July suggests early June transactions reduced average size transactions had increased, July transactions per block reduced fewer transactions were being\u00a0created. Perhaps Bitcoin exchanges other organisations high transaction volumes had changed their behaviour begun posting larger transactions inputs and/or outputs, rather posting smaller transactions fewer inputs Bitcoin often held speculators who expect Bitcoin increase. Perhaps increases transaction volume correlated increases Transaction fees earned miners fees charged users sending Bitcoin. Node operators (miners) collect unconfirmed transactions, confirm their validity perform proof-of-work requirements submit these transactions block In order provide incentive node operators process confirm transactions, compensate equipment energy costs required so, fee charged confirm transaction. size fee proportional size (in bytes) transaction quantified fee rate otherwise miners prefer smaller sized transactions fit each\u00a0block. pool unconfirmed transactions automatically sorted transaction fee rate, miners confirm transactions higher fee rate before those lower fee\u00a0rate. Because this, expected unconfirmed transactions increases, fees paid ensure transaction gets processed also increase. shown figure\u00a0below. Perhaps reason unconfirmed transactions grew fee rate offered these transactions below threshold where wasn\u2019t worth miners efforts confirm\u00a0them. total confirmation fees earned per day size unconfirmed transaction pool plotted\u00a0below: In\u00a0[14]: # transaction fees - total BTC transaction fees miners earn per day. TRFEE = In\u00a0[15]: tn_fee = del In\u00a0[16]: trace1 = go.Scatter( transactions' ) # later trace2 = go.Scatter( fee', yaxis='y2' ) data2 = [trace1, trace2] layout = go.Layout( title='Total (BTC) transaction confirmation fees earned day', yanchor='top', y=1.1, x=0.5), xaxis=dict( ticklen=7, ), yaxis=dict( title='Number unconfirmed transactions', zeroline=True, autotick=True, ticks='', ), yaxis2=dict( title='Daily sum confirmation fees (BTC)', side='right', ) ) fig = layout=layout) py.iplot(fig, Out[16]: It looks confirmation fees correlate positively unconfirmed transactions. expected users pay higher fees there lot unconfirmed transactions order their transactions moved towards front queue processed However looks changes miners fee rate lags behind changes size unconfirmed transaction pool weeks. variation transaction fee also lot smaller variation size unconfirmed suggests method calculating transaction fee rate improved fee rate responds faster changes transactions awaiting confirmation. mining less profitable competitive, Bitcoin network cheaper for\u00a0users. Lets look expensive Bitcoin network analysing transaction fee rate relative Ratio transaction fees transaction volume\u00b6 In\u00a0[17]: # Average transaction confirmation fee rate (%) CPTRV = CPTRV = In\u00a0[18]: series1 = go.Scatter( name='Fee rate', = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Miners revenue percentage transaction volume', rate (%)'), yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[18]: results show fee rate (Miners Volume) 0.5-1% typical Bitcoin network. bit cheaper ecommerce payment methods. Surprinsingly, there correlation -0.25 unconfirmed transactions. means fee rate decreases unconfirmed transactions increases. correlation weak. One possible explanation may activity network increases price Bitcoin increases. When price Bitcoin increases, resources allocated mining increasingly profitable. Also, people decide buy Bitcoin it\u2019s becoming valuable. leads transactions even miners competing confirm transactions claim rewards. increase supply drives down transaction confirmation fee\u00a0rate. Lets see transactions per day changed 2017 so\u00a0far. Number transactions per day\u00b6 In\u00a0[19]: # Number Transactions Popular Addresses NTREP = # excluding popular addresses NTRAN = # addresses NTREP = #excl. popular NTRAN = #all addresses NTRFP = NTRAN - NTREP # Popular NTRFP['all'] = NTRAN['Value'] NTRFP['unpop'] = NTREP['Value'] NTRFP['pop'] = NTRFP['all'] - NTRFP['unpop'] #NTRFP.head() In\u00a0[20]: series1 = go.Scatter( name='From addresses', = dict( = (color2), width = 2)) series2 = go.Scatter( name='From addresses - 7 day average', = dict( = (color1), width = 3)) series3 = go.Scatter( excluding 100 most popular addresses', yaxis='y1', = dict( = ('#CEB7DF'), width = 2)) series4 = go.Scatter( excluding 100 most popular addresses - 7 day average', yaxis='y1', = dict( = ('#830DD4'), width = 3)) series5 = go.Scatter( - 7 day average', yaxis='y2', = dict( = ('#4FA6D4'), width = 3)) = [series1, series2, series3, series4, series5] layout = go.Layout( title='Bitcoin transactions per day', xaxis=dict( ticklen=5, ), yaxis=dict( per day', zeroline=True, autotick=True, ticks='', ticklen=7, ), yaxis2=dict( side='right', ), legend=dict( y=-0.45, x=0, ) ) fig = layout=layout) py.iplot(fig, Out[20]: figure above shows transactions posted day addresses, transactions day addresses excluding 100 most popular addresses. difference between two (the transactions 100 most popular addresses) shown blue axis the\u00a0right. There positive correlation size unconfirmed transaction pool. Interestingly there stronger correlation transactions created 100 most popular addresses (0.54) unpopular addresses (0.46). Possible reasons Finally, lets consider influence price Bitcoin size unconfirmed Bitcoin price\u00b6 In\u00a0[21]: # USD BTC MKPRU = MKPRU = In\u00a0[22]: series1 = go.Scatter( name='Daily', = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Bitcoin price', (USD)'), yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[22]: Apart showing notable increase around 500% 13 months, price correlation just 0.42 size unconfirmed transactions coming popular addresses positively correlated (0.41) Bitcoin price, suggesting Bitcoin price increases trading activity exchanges also increases. Transactions less popular addresses inversely correlated Bitcoin price (-0.31) Bitcoin price surges, individuals holding Bitcoin want spend Bitcoin purchases, exchange convert fiat currencies into\u00a0Bitcoin. Note ordinarily address Ratio unique addresses want compare unique Bitcoin addresses total transactions created. initially expected ratio addresses transactions close 1, realising transaction contain least addresses (1 input output, probably 2nd output address equal input address change). transaction average outputs, idea ratio Bitcoin transactions addresses be\u00a00.5. In\u00a0[23]: # unique addresses day NADDU = NADDU = #number transactions NTRAN RATIO = NTRAN / NADDU d1 = d2 = RATIO = In\u00a0[24]: series1 = go.Scatter( name='Daily', = dict( = (color2), width = 2)) series2 = go.Scatter( name='7 day average', = dict( = (color1), width = 3)) = [series1, series2] layout = go.Layout( title='Ratio transactions unique addresses', yanchor='top', y=1.1, x=0.5) ) fig = layout=layout) py.iplot(fig, Out[24]: figure above shows ratio unique Bitcoin transactions unique addresses approaches 0.5. users reuse address multiple transactions (which bad) ratio rise above 0.5, users create transactions usual minimum unique addresses ratio dip below\u00a00.5. Correlation between series\u00b6The table below shows Pearson correlation coefficients between In\u00a0[25]: '''' # daily averages tseries = [ av_bs['Size'], tn_fee['Fee'], RATIO['Value'] ] cols = ['Unconf trnsx', 'Conf time', 'Block size', 'Trnsx/block', 'Conf fees', 'Fee rate', 'USD/BTC', 'Trnsx - pop addrs', 'Trnsx - unpop addrs', 'Tnsx : Addrs ratio'] tbl = len(tseries))) i j tbl[i,j] = # values index=cols, # 1st column index columns=cols) # 1st row column names '''; In\u00a0[26]: # Using 7 day moving average tseries = [ cols = ['Unconf trnsx', 'Conf time', 'Block size', 'Trnsx/block', 'Conf fees', 'Fee rate', 'USD/BTC', 'Trnsx - pop addrs', 'Trnsx - unpop addrs', 'Tnsx : Addrs ratio'] tbl = len(tseries))) i j tbl[i,j] = # values index=cols, # 1st column index columns=cols) # 1st row column names Out[26]: .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { top; } Unconf trnsx Conf Block size Trnsx/block Conf fees Fee rate USD/BTC Trnsx - pop addrs Trnsx - unpop addrs Tnsx : Addrs ratio Unconf trnsx 1.000000 0.512825 0.572234 0.662592 0.751183 -0.318481 0.476519 0.684877 0.732961 0.042633 Conf 0.512825 1.000000 0.875708 0.821096 0.652057 -0.347289 0.519717 -0.016592 0.466974 0.234847 Block size 0.572234 0.875708 1.000000 0.856833 0.748027 -0.435521 0.624602 0.387743 0.522778 -0.082361 Trnsx/block 0.662592 0.821096 0.856833 1.000000 0.619106 -0.513678 0.332789 0.263169 0.915094 0.402304 Conf fees 0.751183 0.652057 0.748027 0.619106 1.000000 -0.326240 0.824995 0.661089 0.378880 -0.363753 Fee rate -0.318481 -0.347289 -0.435521 -0.513678 -0.326240 1.000000 -0.217555 -0.591717 -0.393656 0.126348 USD/BTC 0.476519 0.519717 0.624602 0.332789 0.824995 -0.217555 1.000000 0.523433 -0.354745 -0.716468 Trnsx - pop addrs 0.684877 -0.016592 0.387743 0.263169 0.661089 -0.591717 0.523433 1.000000 0.244647 -0.409759 Trnsx - unpop addrs 0.732961 0.466974 0.522778 0.915094 0.378880 -0.393656 -0.354745 0.244647 1.000000 0.471671 Tnsx : Addrs ratio 0.042633 0.234847 -0.082361 0.402304 -0.363753 0.126348 -0.716468 -0.409759 0.471671 1.000000 { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , , ]","category":"Technical/Data"},{"title":"Corporate\u00a0London","url":"corporate.html","body":"2014 -\u00a02017 Having made arrangements leave London, seems reasonable reflect time\u00a0here. London tough city live \u2014 it\u2019s big enough sub 1-hour commute considered good, it\u2019s super expensive. My stay London been defined quest complete graduate scheme qualify an\u00a0accountant. When first arrived had no idea London working corporate like. coming academia, motivation moving finance summed two\u00a0points: Understand 2008 Get paid mostly same skills (math) in\u00a0engineering don\u2019t think there\u2019s anything wrong these motivations, should been making long term career plan\u00a0instead. When started job surprised 6 weeks induction hot-desking. Life auditor felt nomadic, everyone spend large amounts client\u2019s offices, no-one their own desk our office. thing really own knowledge network In 2014, arrived high opinion employer view staying several years. Having escaped financial insecurity short-term research grants, I\u2019d moved back home country contribute system educated me. happy regular job decent, A phrase kept coming mind back \u201caccountant factory\u201d. Our training materials were scripted everything standardised process. We were being processed. Graduates in, corporate company huge efficiencies barriers competition come this. When arrived impressed there were free biscuits, felt presumptuous put meeting someones diary. Now ignore any communications addressed mailing\u00a0list. Accountant toughest experiences were related accountancy qualification. Na\u00efvely had believed qualification wouldn\u2019t big deal didn\u2019t give any thought applied \u2014 just wanted find banks worked. there were exams done fine, I\u2019d already achieved PhD handle\u00a0it. That turned mistake. A huge mistake. alarm bells should rung louder realised most graduate colleagues had applied get qualification (and were already intending leave asap afterwards). Doing pre-course work before college wasn\u2019t trivial. College - being sent classroom again. We were being taken office, away clients, put classroom prepare these\u00a0exams\u2026 Starting job required becoming chartered accountant, without considering effort involved qualify dumb. It\u2019s oversight find hard to\u00a0believe. disappointment sadness having study again profound. teaching assessment style several steps behind I\u2019d become to. Compared depth, autonomy research-focus doctorate, writing cookie-cutter essays time-pressured exams felt stupid. exams were hard failed several them, probably low morale whilst revising. Retaking them required weekends annual leave being spent away family, camped-out libraries and\u00a0offices. required much patience generosity Ritsya, who having seen me long periods during doctorate expected us lifestyle came London. found miserable pause social life other interests whilst studying, try rush back them had time, knowing soon I\u2019d pause them\u00a0again. hadn\u2019t already studied Vienna, process working studying London been exciting felt valuable special. I\u2019d passed enough exams though know they\u2019re never important they\u2019re made be, whatever missing life wasn\u2019t going found On upside though, ACA most practical qualification I\u2019ve gained taught me useful aspects business finance. I\u2019m glad finally see business mysterious system something attainable Neighbourhood Living London also required lot trains \u2014 door desk commute hour way, I\u2019ve never lived somewhere London hasn\u2019t felt transient. We\u2019ve needed live near station didn\u2019t want commute hour that\u2019s put us neighbourhoods other young professionals who also don\u2019t long term plans (or financial ability) stay city. We\u2019re looking move move fast possible. want leave London partly there people same attitudes priorities my\u00a0own\u2026 Back office spent first few months figuring people were organised, teams operated decisions were made. think took me year feel understood things really worked, 1.5 years feel aspects job certainty. There difference between things spoken about, things My experience been performance matters behaviour defined self-interest. don\u2019t think different previous environments I\u2019ve worked \u2014 academia isn\u2019t any different1 construction industry certainly isn\u2019t. wonder way people endure they\u2019ve experienced anything else, think normal, necessary. find myself wishing kinder other, create structures incentivise Corporate finance usually appears clean well presented. Its people appear dependable capable. culture sanitised there\u2019s lot pressure conform - see clothes accessories wear jokes tell other the\u00a0canteen. came see office glass steel cathedral. read Middle East, migrants arriving Europe, tower blocks burning, felt Despite high regard hold ourselves, don\u2019t ask other help. Maybe too busy, feel powerless help. Apparently know help, despite our wealth, talents, education remember watching man leave office day thought he gave his whole career left his firm after decades service, there nothing left identify him after few weeks. work always get done. Market forces dictate business adapts grows. City rolls\u00a0on. Publications trump almost other metrics, incentives publish quantity over quality such risky slow research inexcusable. metrics standardise success allocate resources subverted just well academia any other industry. What management measures, team prioritises.\u00a0\u21a9","tag":"[, , ]","category":"Non-technical/Family"},{"title":"Blockchains from the ground up: Part\u00a02","url":"blockchain-networks.html","body":"Maintain accurate list transactions across large group users, without part introduction key features generalised blockchain. Part introduced key features immutable record creation between parties public key cryptography. Part explores network users maintain same (true) list transactions protect other against\u00a0fraud. Broadcasting transactions the\u00a0network In Part saw Lizzie, John Chris exchanging coins. Lizzie also paid John coins were owed her Chris. These transactions were authenticated PKI\u00a0which: Ensured Prevented participants claiming didn\u2019t Prevents anyone creating transaction someone else\u2019s behalf without their\u00a0consent. As people network grows, transfer coins user another becomes harder track. every users ledger identical opportunity arises coins already been spent pay someone who doesn\u2019t know they\u2019ve already been\u00a0used. double spending, possible ledger shared amongst members group weak consistency - necessarily correct all\u00a0locations. Weak consistency solved requiring everyone votes accept transaction before accepted ledger (Unanimous consensus), save reduce requirements 50% users validate transaction before accepted ledger (Quorum consensus). Either these solutions possible small local group list all\u00a0users. However Unanimous Quorum Consensus doesn\u2019t solve weak consistency problem\u00a0if: group is\u00a0large group small spread across different locations or\u00a0timezones It possible know members there therefore proportion users real identity user is\u00a0unknown In these cases peer-to-peer network required where transactions between users require approval other users before being confirmed. been trivial solve, users incentivised dishonest, may mistakes. distributed consensus problem, wikipedia defined\u00a0as: consensus problem requires agreement among agents single value. Some processes (agents) may fail unreliable other ways, consensus protocols fault tolerant resilient. processes somehow put forth their candidate values, communicate another, agree single When identity participants known, distributed consensus possible. Two types protocol allows users distributed system agree transaction Paxos family protocols Two-phase commit protocol. Both these require least 50% users reach agreement order add However public peer-to-peer network total active users known - fast cheap create user profiles, existing user profiles may become dormant. makes impossible know users 50% be. Additionally, possible cheaply create user profiles (just generate public-private key pair), single actor generate control user accounts order votes force incorrect transactions onto ledger. An attack where user subverts network creating profiles known Sybil attack. Proof of\u00a0Work solution Sybil attack increase cost verifying transaction such cost exceeds reward. achieved through proof-of-work (PoW) algorithms, expensive sender claiming verified transaction, simple receiver verify sender validated One possible Proof Work approach require hash verification message begins certain set characters. chosen set characters called nonce way create verification message acceptable hash try slightly different messages. For example, nonce may 3 zeros. It\u2019s arbitrary, longer nonce difficult becomes find hash fits hash random list characters, altering even single part being hashed result completely different hash value. Therefore there no way predict hash value. way generate hash required none repeatedly alter being hashed (even just character) until hash required features randomly achieved. expensive achieve, simple to\u00a0verify. Using method, user who seeks verify transaction broadcast result (once they\u2019ve verified transactions) repeatedly try different messages until randomly find message meets nonce requirements. It simple user check transaction verification message meets nonce requirements, simple inspect hash compare the\u00a0nonce. effect requirement process makes expensive claim transaction been verified cheap check verification claim. removes threat Sybil attack, does remove distributed consensus problems created not\u00a0knowing: true identity users the\u00a0network How users\u00a0exist problem cannot completely solved, practical solution relax requirements such probability accepting fraudulent transaction lower user defined threshold. acceptable user require higher degree confirmation high-value transaction low-value transaction, therefore willing incur cost verify high transaction reduce probability accepting incorrect transaction below a\u00a0threshold. user wishes fast low-value transactions, trusts party they\u2019re transacting with, may accept transaction without any other users network verifying sender required However senders assured, verification required. risky valuable transaction, users receiver funds ask verify sender access required funds. higher users, higher probability dishonest transaction identified before An appropriate level verification depend amount being transferred well receiver funds knows the\u00a0sender. Asking peers network verify transactions introduces problem. Verifying transaction requires effort, incurs cost. cost requires network participants rewarded correctly verifying transactions between An attacker attack cost less reward. Therefore cost verifications required should just enough cost attack introduces problem costs verify transaction transaction itself. It also create recursive problem where users who verified first transaction verify payment received also valid. Furthermore, high proportion original transaction spent transaction fee (for verification) not\u00a0efficient. These problems avoided combining multiple transactions verifying them same time, broadcasting successful verification multiple transactions simultaneously grouping transactions together block By confirming multiple transactions once (and proving transaction fees aggregated (allowing individual fee much lower). Each block includes list verified transactions, reference previous block, block ID. Incentivised transaction verification process outlined above remarkable creates demand participants network creating financial incentive verify transactions. makes network secure increasing participants makes sybil attack Summary Users generate transactions broadcast them peer-to-peer network An idle user listens transactions collects them until sum transactions\u2019 verification fees greater cost user incur verify them meet idle user adds extra transaction their list transactions transfers sum transaction fees their own\u00a0address. idle user generates block newly verified transactions, referencing previously verified block transactions ordered completing proof-of-work challenge. block broadcast the\u00a0network. Other users listening block announcements. These users verify block valid according proof-of-work requirements order the\u00a0blocks. Users unverified transactions look inside verified block see their pending transactions been\u00a0accepted. Competing validate blocks Each user choose transactions verify, verify before beginning proof-of-work requirement hopefully collecting transaction fees. lack order around transaction verification fine way increase probability being first claim transaction fees associated collection transactions (a block) spend CPU power searching required partial two users complete block approximately same blockchain look different different parts network, completed block begins propagate other users accept block add their ledger. ok rule enforced requires user always accept longest chain of\u00a0blocks. works multiple blocks created same time, takes create subsequent blocks vary due random behaviour proof-of-work algorithm. Therefore chains different length always exist version block chain longer others, providing clear candidate branch blockchain use. there transactions discarded branch present (longest) blockchain added back pool transactions A block transactions never above procedure verifying transactions adding blocks onto chain means even user inspects block sees their transaction been verified, possible future longer chain discovered (which accepted) doesn\u2019t include Therefore any block potentially removed, means transaction never completely verified. However probability block being removed decreases blocks after increases. means verification thought terms blocks been added chain after block containing willing accept high level risk, trust party transacting opt small blocks added after block containing transaction. benefit increasing speed transaction verification. transaction risky high-value, might require larger blocks added chain before accepting transaction. increase required verify transaction, reduce probability longer chain undo block containing transaction in\u00a0question.","tag":"[, , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Move","url":"move.html","body":"Ambition Since 15, ambitions been entrepreneur. joke dad buying him nice boat one\u00a0day. Life far been predominantly education, stage over now. I\u2019m walking away I\u2019ve come see lifestyle career too doesn\u2019t sense live this. Ultimately want develop multiple sources passive income. want to\u00a0create. Summer\u00a02017 last few months been intense, weeks leaving me feeling ambitious energetic, others feeling anxious overwhelmed. get better defining goal, taking quickest path there, ignoring Ritsya brave enough imaginative enough force me think big consider live better life. My biggest fear screw up, shooting myself foot Ritsya daughter also. We were headed safely unremarkable existence terrible swap something worse. That won\u2019t\u00a0happen. know better decisions produce best work under pressure, thrive I\u2019m perceived underdog. accept without reason foolish. Whilst don\u2019t clear plan, direction, goal, (I them) I\u2019ve got skills want see make. I\u2019ll never best work, most productive combination skills experiences, I\u2019m cog someone It\u2019s safer being employee self-employed. guess price removing risks difference between generate employer you\u2019re paid. think those risks overpriced, most people capable realise. Sometimes walk situation find most it. And sometimes leave place order Autumn\u00a02016 Last year boss gave me advice supposed encouraging. I\u2019d requested reduce involvement stuff unrelated job contribute team still maintain semblance My boss pretty clear reducing involvement extra stuff possible. During our conversation he advised me worry much contributed team \u201cthe work get done anyway\u201d. meant encouraging, instead removed any conviction work did was\u00a0important.","tag":"[]","category":"Non-technical/Family"},{"title":"Flee","url":"flee.html","body":"Summer children squeal shriek, Watch wars. Excitement mounts. How exotic. Unexpectedly, Death arrives. Grow-up Grow old Face death Evade evil. Don\u2019t tire. World fragile. Towers burn, Bridges bludgeon, Markets stab. Got get\u00a0out.","tag":"[]","category":"Non-technical/Family"},{"title":"Understanding VC\u00a0Investment","url":"investment.html","body":"attended Lisbon Investment Summit June wrote experiences here. One best sessions Boris Golden called \u201cUnderstand Investment\u201d. These my\u00a0notes: VC\u2019s seeking identify high-potential startups, support fund\u00a0them. They looking something innovative and\u00a0unproven. A startup company organisation searching Whilst executing discovering scalable way to\u00a0grow. Startups money ambitious credible growth\u00a0plans. A typical stake VC roughly\u00a020%. VC\u2019s want exit price least 100m, otherwise their business models don\u2019t work\u00a0out. $10m seem lot founder 30% stake, it\u2019s enough attract VCs, aim\u00a0higher. How to\u00a0pitch Identify specific people real\u00a0needs Size of\u00a0market Why\u00a0now? What clear competitive advantage - why no-one else do\u00a0this? Market Find large Management Build smart, skilled cohesive\u00a0team With strong ability deliver quickly learn\u00a0quickly That ready go big whatever it\u00a0takes With unique vision Model Valuable Efficient go-to-market Profitable Scalability Momentum Show traction you\u2019ve cracked Show ambitous credible growth\u00a0plans With growth\u00a0model And clear strategy scale and\u00a0win","tag":"[, , , ]","category":"Non-technical/Entrepreneurship"},{"title":"How to be an ambitious founder in\u00a0Europe","url":"ambitious.html","body":"Whilst Lisbon Investment Summit went session called \u201cWhat means ambitious founders Europe\u201d Oussama Ammar. I\u2019ve written generally summit here. Oussama spoke passion humour. It\u2019s clear he cares encouraging would-be founders confronting cultural hurdles exist Europe. These notes the\u00a0session: serious building something matters great exciting future\u00a0ahead. You never predict who successful who fail. There lot dumb successful people clever founders can\u00a0fail. It\u2019s really important learn leverage effectively. You lose anything else get back never recover you\u2019ve already\u00a0spent. way succeed try\u00a0hard. It\u2019s hard something that\u00a0matters. In Europe ambitious average (measured against other countries) environment makes harder entrepreneur. (Attitudes risk, comfort, security, expectations failure.. unhelpful for\u00a0founders.) It\u2019s impossible, just harder. So Everyone replaceable, no-one is\u00a0unique. You always lose money replace it. There much money the\u00a0world. Take look Crunchbase see failure rate companies raised $1m - $10m, same rate those raised\u00a0$10m+. lose money project learn things experience leverage that\u00a0learning \u2026 But never get back you\u00a0spent. Zombies companies enough money survive enough provide joy people company - aim high\u00a0and\u2026 Starting company big deal, starting marriage. Think hard doing, problem trying solve, who working\u00a0with. In Europe there enough money go around makes pitching hard. Silicon Valley doesn\u2019t this\u00a0problem. On average startup Europe raise less startup USA. Europe irrationally concerned risk. USA less concerned risk very\u00a0helpful. So pragmatic about\u00a0risk. Incorporate London where laws good, even don\u2019t want operate UK. It better designed system corporate law. Estonia also\u00a0good. Best European city for\u00a0founders London, There isn\u2019t best city none are\u00a0holistic London the\u00a0money Paris engineering product development (and no-one outside Paris knows Berlin automation execution, execution and\u00a0scaling \u2026You draw 3 these cities, taken together surpass Anecdotes founder Slack lives Vancouver his wife kids. He spends day week California everyone thinks Slack Californian due good marketing. Forget national pride, pragmatic. Leverage the\u00a0internet. founders Airbnb fly New York California day week. They were originally California where AirBnB started, decided work New York AirBnB success, moved New York flew back meetings , etc. ask Europeans come meeting London (which far California New York) people start complaining deciding can\u2019t be\u00a0bothered.","tag":"[, , , ]","category":"Non-technical/Entrepreneurship"},{"title":"The Lisbon Investment\u00a0Summit","url":"lis17.html","body":"attended Lisbon Investment Summit June 6 7 part Oula.la InsurTech startup team John Sullivan. It first startup conference I\u2019d been arrived hoping useful conversations understand Fintech startup spaces Europe. As usual wanted focus tech, finance Who was\u00a0there As well outstanding sessions there high ratio investors startups. made talking VCs, bankers M&A lawyers really easy. happy meet London-based VC sat down lunch, thanks interrupting session ask blockchain related questions Day 1, banker struck conversation me over breakfast next day. met lot people across relevant roles, once I\u2019ve worked through notes collection business cards hope great most useful sessions me\u00a0were: \u201cWhat means ambitious founders Europe\u201d Oussama Ammar TheFamily \u201cUnderstanding Investment\u201d Boris Golden \u201cBuilding successful businesses blockchain technologies\u201d panel discussion moderated Kevin Loaec, founder Chainsmiths blockchain consultancy, including Mir Serena Liponi Blockchain\u00a0Lab blockchain session valuable it\u2019s unusual meet people who been working blockchain space several years. I\u2019m always wary being distracted hype noise around developments blockchain space appreciated hearing informed opening session included speech Mayor Lisbon next day opened speech Secretary Industry. Both speeches conveyed open progressive attitude international cooperation aimed promoting supporting founders startups Portugal. warm words were supported practical measures including tax incentives state-backed scheme match amounts contributed private investors. It really refreshing hear politician extol virtues multinational cooperation bringing different cultures Portugal. wish Britain this\u00a0too. On topic Brexit, inevitably arose due London\u2019s present role centre finance innovation, seems Europe still expecting UK come senses, cannot understand why it\u2019s destroying goodwill reputation so\u00a0thoroughly. Overall two days Lisbon were full useful energetic conversations great experience pitching Oula.la multiple times talking we\u2019re trying blockchains part that. opportunities meet founders investors invaluable making informed decisions. Lisbon beautiful city found easy get around always felt safe in. It\u2019s also refreshingly affordable!","tag":"[, , , ]","category":"Non-technical/Entrepreneurship"},{"title":"Blogging with Pelican: Design, Plugins,\u00a0Sharing","url":"pelican2.html","body":"Design My approach building blog keep simple possible, adding features significant improvement content understood used. Therefore I\u2019ve done away several features normally come baked WordPress theme. For example footer full links never used, sidebar full opted single column design hopefully presents text-heavy articles clearly intuitively (please leave comment tell me you\u00a0think). Plugins My plugins extend Pelican\u2019s functionality reflects this, there Neighbors plugin next previous post accessed bottom post without going back index, Tag Cloud plugin reflect subjects written most (and provide link Speed speed site important faster site enjoyable use. Therefore I\u2019ve minified CSS JavaScript Assets plugin. I\u2019ve also set CSS JavaScript load Images optimised Optimize Images plugin their file size small possible download quickly. site uses CloudFlare\u2019s free CDN features hopefully no matter view site get decent page\u00a0speed. I\u2019ve also arranged homepage posts shown their category posting date. may work very well larger posts, I\u2019ll consider problem once presents itself. Designing hypotheticals conditions don\u2019t yet exist waste of\u00a0time. There examples I\u2019ve Jinja templates below context sharing articles Twitter and\u00a0Facebook. Plugin: Share\u00a0Post noticed posts were beginning get tweeted about, thought useful sharing buttons bottom post Twitter, Facebook Email. Looking Pelican Plugins repo Github showed there (as usual) plugin (called Share Post), though noted hadn\u2019t been updated couple of\u00a0years. Installing initial set-up simple thanks readme git repo. You copy plugin folder plugins directory, add name plugin list Then copy paste Jinja/HTML article.html template. That\u2019s enough it\u00a0work. noted though shared Twitter text tweeted encapsulated quotes there \u2018b\u2019 front. realised due Python 3.x plugin (which hadn\u2019t been updated years) likely written Python 2.x. A quick google obligatory trip SO showed me convert bytes string text\u00a0string. # Python tweet = ('%s%s' % (title, # Python 3 tweet_as_byte = ('%s%s' % (title, tweet = also found article couldn\u2019t shared twitter mobile device due URL being incorrectly formatted. URL format required separate arguments URL, additional text # Incorrect twitter_link = % tweet # Correnct twitter_link = % (url, tweet, t_handle) Using meta-data specify tweet\u00a0text thought cool add default text tweet, I\u2019ve enjoyed feature other blogs I\u2019ve found post wanted share Twitter. - A user may know want share article they\u2019re hurry might hard find right words, why provide ready-made tweet. text editable it\u2019s a\u00a0suggestion. text different post makes sense specify writing article. article \u2018summary\u2019 too long, know Pelican supports arbitrary meta-data tags. assumed Jinja pick same way picks \u2018standard\u2019 meta-data added function def tweet = '' 'tweet'): tweet = quote(('%s' % else: ' ' Once function working simply case calling function assigning output variable called \u201cTweet\u201d, adding \u201cTweet\u201d text string included tweets\u00a0text: tweet = tweet_as_byte = ('%s' % tweet = t_handle = There bit fiddling around sure spaces between part tweet correct, nothing complicated making Time Until. Specifying text image Facebook\u00a0share Sharing Facebook worked without any formatting problems, bugged me opening text article being preview shared Facebook had summary already prepared much useful potential readers. For articles also had article image wanted see being\u00a0used. Googling revealed needed particular meta tags webpage\u2019s header wanted control Facebook pickup. Facebook uses \u201copen graph\u201d standards headers article pages include the\u00a0following: `<!-- Open Graph -->` `<meta content=\"Title Here\" />` `<meta />` `<meta />` `<meta />` `<meta Here\" /> see already had meta tags being generated Jinja templates set copy-pasting modifying them build tags. had issues trailing white space breaks being included within content string. solved like\u00a0so: {# Adding '-' after before %'s strips white space breaks #} {% block description %} {%- -%} {{ }} {%- else -%} {{ }} {%- endif -%} {% endblock description %} also needed blocks once, description tag already included Facebook wants Twitter wants too. All three these tags include same text (generated Jinja2 snippet above). block needs once it\u2019s generated like\u00a0this; <meta content=\"{% block description %}{% endblock description %}\"> But call \u201c{% block description %}{% endblock description %}\u201d again Jinja throw error. documentation (and SO) reveal solution to\u00a0use: <meta content=\"{{ }}\"> allows reuse blocks multiple times keep Finally, testing Facebook see correct text image being picked initially frustrated see tags were having any effect. Facebook crawls site saves finds. want take fresh look page meta tags, tell Facebook crawl page again, Facebook You see sharing buttons below, please click them see what\u00a0happens! Note: My first article describing began Pelican here","tag":"[, , , , , , ]","category":"Technical/Web"},{"title":"Blockchains from the ground up: Part\u00a01","url":"blockchain-introduction.html","body":"How maintain reliable list across small network without part introduction key features generalised blockchain. haven\u2019t included references Bitcoin any particular digital currencies blockchain digital currency just application Create financial document cannot forged or\u00a0disputed Let\u2019s imagine there village somewhere where people still trade bartering. John apples whilst Lizzie oranges. John orange, offers Lizzie apple exchange. She accepts, writes John a\u00a0receipt. Date: 1234 From: Lizzie To: John What: Orange Price: Apple So far, good. receipt evidence transaction. next day John wants orange doesn\u2019t anything exchange. He offers write Lizzie note saying he owes Lizzie orange (an IOU). They think agree John should sign note Lizzie prove John owes her 1\u00a0orange. Date: 1234 From: John To: Lizzie What: Orange Signed: John's signature, Lizzie's signature IOU nice gesture, it\u2019s simple forge. Lizzie copy IOU once Lizzie seen Johns signature, she easily copy create IOU\u2019s. She also change IOU orange 11 oranges (for example) John couldn\u2019t prove original amount was. Lizzie John disagreed over owed impossible know who telling truth. It\u2019s person\u2019s word against the\u00a0other. Lizzie realises suggests improvement - find witness 3 copies IOU. Each copy signed Lizzie, John Witness. Lets call Date: 1234 From: John To: Lizzie What: Orange Witness: Walter Signed: \"John's signature\", \"Lizzie's signature\", \"Walter's signature\" much stronger document difficult forge. Lizzie changes \u201cWhat:\u201d \u201c11 Oranges\u201d, both John Walter copies original her signature it. It pieces evidence against Lizzie\u2019s 1. Lizzie laughed court.\u00a0Hahaha. 3 Party transactions work pretty well, most transactions recorded today. But there weakness: Lizzie bribe Walter transaction falsified! John rely Walter verify his version transaction down Walters lack integrity. Lizzie Walter change orange 11 oranges Lizzie offered Walter extra oranges give them both incentive forge documentation. Walter liked oranges enough, he might care his career witness be\u00a0ruined. problem modern financial systems great deal time, money regulation devoted trying ensure third parties trustworthy. E.G. buy car bank cahoots car dealership, defrauded. Reducing risk acceptably low level makes financial services slower expensive otherwise to\u00a0be. solution public-key infrastructure (which introduced previous post). In system, individual generates their own public-private key pair. They keep their private key private their public key freely available. A detailed description public-key cryptography scope post, but\u00a0briefly: A public key derived private key, pair together set unique mathematical properties. Either key encrypt message other key decrypt it. You cannot same key encrypt decrypt message. private key encrypt anybody decrypt (because public key publicly available) whilst clearly terrible way keep secret it\u2019s great way verify who encrypted message, person private key. Because this, private key encrypt message effectively creating digital signature cannot forged. (If public key encrypt message private key decrypt it, approach transfer secret Back fruit. Lizzie wants accept John\u2019s IOU she public-key cryptography no-one needs worry Walter. There 3 steps 1] Create IOU stating John owes Lizzie 1\u00a0orange. Date: 1234 From: John To: Lizzie What: Orange 2] John creates public private key pair encrypts IOU his private key. He adds unencrypted \u201cFrom\u201d\u00a0line. From: John Date: 1234 To: Lizzie, What: Orange <- Signed encrypted John his private key 3] John makes his public key freely available anyone who wants\u00a0it. work anybody (not just Lizzie) check John signed IOU. transaction verified looking \u201cFrom\u201d part transaction, noticing transaction supposedly John John\u2019s public key decrypt encoded signature decrypted John\u2019s public key his private key encrypt it. Because John person his private key, proves transaction valid, Lizzie isn\u2019t dishonestly creating debt John to\u00a0pay. Clearly John discloses his private key (or stolen) he system insecure, problem John his security protocols, Create maintain accurate list So far we\u2019ve seen IOU (for orange) securely created, signed verified. process extended people exchange fruit. For\u00a0example. original\u00a0note: From: John Date: 1234, To: Lizzie, What: Orange <- Signed encrypted John his private key Then From: Lizzie // Date: 1235, To: John, What: Apples <- Signed encrypted Lizzie her private key From: John // Date: 1236, To: Chris, What: Banana <- Signed encrypted John his private key From: Chris // Date: 1237, To: Lizzie, What: Bananas <- Signed encrypted Chris his private key After these 4 transactions, between John, Chris and\u00a0Lizzie: John owes orange Lizzie banana to\u00a0Chris Lizzie owes apples to\u00a0John Chris owes bananas to\u00a0Lizzie. confusing, (and ridiculous). It possible know who most debt who most wealthy. Lizzie owes apples, owed bananas apple. Does mean her fruit business losing money making money? We cannot say. To able know same unit fruits. Lets say orange worth apples, banana also worth apples (therefore banana = orange.), also lets invent currency called \u201ccoins\u201d say apple worth coin. 4 transactions now rewritten\u00a0as: From: John // Date: 1234, To: Lizzie, What: coins <- Signed encrypted John his private key From: Lizzie // Date: 1235, To: John, What: coins <- Signed encrypted Lizzie her private key From: John // Date: 1236, To: Chris, What: coins <- Signed encrypted John his private key From: Chris // Date: 1237, To: Lizzie, What: 4 coins <- Signed encrypted Chris his private key By going through list transactions see\u00a0that: John owes Lizzie Chris coins each, owed coins Lizzie. His net amount is\u00a0-2 Lizzie owes John coins owed 4 coins Chris. Her net amount is\u00a0+2 Chris owes Lizzie 4 coins owed coins John. His net amount is\u00a0-2 So far Lizzie person who appears any What Lizzie wanted 4 coins she owed Chris buy something John? Could she system transfer Chris\u2019 promise pay her 4 coins Chris pay John instead? fact everyone sure record transactions accurate authentic allows debt payment. Lizzie\u2019s transaction look like\u00a0this: From: Lizzie // Date: 1235, To: John, What: ba781... <- Signed encrypted Lizzie her private key \u201cWhat\u201d section contains hash original transaction (with Chris) she wants transfer John. A hash signature file text case signature Lizzie\u2019s transaction Chris. signature unique transaction identifies transaction being payment. Because both transactions signed Lizzie\u2019s private key, simple verify Lizzie right previous transaction where she owed (or paid) coins payment shows public-private key infrastructure securely record transactions enable trade between group people, - under certain conditions. Blockchains transfer units example, just easily put selfies certificates ownership (for houses, financial instruments, diamonds, etc) inside \u201cWhat\u201d part transaction. two other changes - removing \u201cTo\u201d part transaction, including hash transaction part text signed private key. this, record would\u00a0be: From: Chris // Date: 2345, What: \"A photo me\" <- Signed encrypted Chris his private key create reliable record Chris claims he looks like. He confidently send anyone record his public key verify Chris himself who signed asserting photo him. somebody changed photo transaction change transaction hash value. hash match hash contained within signature, text signature cannot changed encrypted Chris\u2019 private key, Chris has. Therefore simple show someone other Chris trying change the\u00a0photo. Another public-key cryptography arises Chris were employee bank, \u201cWhat\u201d contained documents customer bank providing financial services for. In scenario, Chris (representing bank) effectively confirming customer\u2019s true identity documenting evidence that\u2019s been collected show bank knows who their customer really is. transaction included section called \u201cCustomer ID\u201d (for example) database customers whose identity checks been successfully completed made. shared other departments (or banks) easily immutably. concept behind KYC a\u00a0blockchain. Back our fruit traders: At moment participant allowed carry net negative balance. For system work reality, creation \u201ccoins\u201d controlled order maintain their value. In example above, people freely create \u201ccoins\u201d also carry negative amounts \u201ccoins\u201d. result \u201ccoin\u201d plummeting. Therefore their creation (and conversion fruit) controlled Our examples far include 3 people. there lot people network wouldn\u2019t feasible insist everyone present online transaction added list (the chain) transactions. However allow transactions added whilst people offline create opportunity fraud. reasons why, solution other problems described part 2.","tag":"[, , , ]","category":"Technical/Cryptocurrencies"},{"title":"London Rent vs. London\u00a0Salaries","url":"london.html","body":"Living London expensive, everyone UK knows this. Everyone knows mostly due price property, enjoy talking\u00a0about. I\u2019ve lived here 3 years now, wife were both working lived comfortably. Two incomes under roof just fine. Not fine other cities, reasonable. Just over year ago first child born, now wife\u2019s maternity pay ended single income household. not\u00a0fine. Even though earn almost \u00a350k/year, any salary increase taxed 40%, cannot cover essential day-to-day costs. I\u2019m 40% tax bracket, basic monthly outgoings exceed monthly take home pay \u00a3400. employer wanted pay me enough cover essential costs, cost them approximately double shortfall due tax. None makes\u00a0sense. Salaries living expenses become For most people most obvious way increase wealth buy property. Mortgage repayments cheaper rent, property increases over time. Double win. But there big hurdle overcome before possible - saving money deposit house often impossible without external help (i.e. \u201cBank Mum Dad\u201d), much money earnt spent rent\u00a0first. It\u2019s trap. Repayments mortgage cheaper paying rent, cannot save enough much salary goes paying rent1,\u00a0and average cost flat London 500k2, means 5% deposit \u00a325k \u2014 higher deposit anywhere else UK, despite being place least able accumulate\u00a0it. What partner went back work put our baby childcare? Childcare cheap, working bring cost childcare. requires higher average salary graduate job, (which life stage people might reasonably start having children), unless both parents unusually high earners option isnt viable\u00a0either. Living London financially possible either single household income You\u2019d lucky find bedroom flat less \u00a31000/month\u00a0\u21a9 According Rightmove, estate agent useful price statistics.\u00a0\u21a9","tag":"[, ]","category":"Non-technical/Family"},{"title":"Introduction to the \u00c6ternity blockchain\u00a0project","url":"aeternity.html","body":"These notes \u00e6ternity blockchain project, I\u2019m affiliated \u00e6ternity\u00a0team. \u00c6ternity blockchain project pre-launch. headline goal securely facilitate large volumes interface external sources. made possible via decentralised oracle based prediction markets. These terms explained below. \u00e6ternity project proposed several notable Smart Contracts Oracles native Governance Written in\u00a0Erlang Different types of\u00a0node Sharding Smart Contracts A smart contract way execute contract without intermediary (middle-man) smart contract protocol stored executed blockchain, executing transactions (outputs) based specific inputs programmable logic automatically. logic often mirrors contained clauses State channels payment networks exchange funds off-chain periodically settle accounts blockchain. (The Bitcoin Lightning Network creating system routing Bitcoin payments through State channels increase scalability making groups transactions independent other. allows them processed in\u00a0parallel. \u00e6ternity proposes executing state channels (Turing complete means, colloquially, real-world general purpose), should allow greater volumes transactions, smart contracts secure easier to\u00a0analyse. executing off-chain makes them private code execute smart contract won\u2019t broadcast primary blockchain. should increase processing capacity allowing contracts execute in\u00a0parallel. Disadvantages state-channel approach include reduced transparency, running smart contracts state channels requires trust both contract creator node running\u00a0it. Oracles Oracle functionality allows interact outside \u00e6ternity blockchain. possible checking on-chain prediction market results rewarding users who made correct prediction. Users rewarded through automated payments immediate recording transactions blockchain. creates incentives participate prediction markets, been shown be\u00a0effective. On-chain, rather off-chain allows greater efficiency prediction market expected run native (on-chain) consensus procedure. oracle mechanism designed same Governance Oracle functionality compliments prediction Prediction markets proposed implement governance \u00e6ternity blockchain. new\u00a0approach. \u00e6ternity protocol governed user input. A prediction market exist where changes features protocols result higher token\u00a0value. incentive increase token (\u00c6on) allow \u00e6ternity community decide efficiently changes to\u00a0implement. Low level protocol changes variables block times block capacity be\u00a0possible consensus developed prediction market initially provide input development Later, fully autonomous prediction market governance expected (a DAO) Written in\u00a0Erlang Erlang normally large-scale systems manage allocation scarce network resources (telecoms, banking, Could easier run lightning network process state-channels in\u00a0parallel As far know, \u00c6Ternity first blockchain project written in\u00a0Erlang Different types of\u00a0node \u00e6ternity network contain nodes different functions. Each node contribute towards efficient functioning particular aspects the\u00a0network Node types will\u00a0include Liquidity - Lots channels lots users. Open channel issue contract, a\u00a0fee. Exchanges - Trustless exchanges assets offered market makers. Profitable market makers Presumably features such consensus algorithms prediction markets also require their own dedicated node types. Users node incur transaction fees participate, providing incentive run a\u00a0node. Sharding Allows greater transaction volume, removing scalability problems Bitcoin Ethereum Sharding works splitting space possible accounts subspaces (for example based first digit Each shard gets set validators. Each validator validates shard\u00a0only Contracts transactions within same shard work as\u00a0normal Contracts transactions across shards require alternative techniques based","tag":"[, , , , ]","category":"Technical/Cryptocurrencies"},{"title":"The \u00c6ternity ICO: My\u00a0experience","url":"aeternity-ico.html","body":"On April 3rd, happened Googling digital currencies blockchain innovations came across \u00c6ternity website skimmed their white paper. project ambitious, crypto projects, seems well organised. team well known space. There clear plan develop project create blockchain technology that, successful, bring. A step change digital currencies high volume low transactions, viable implementation ICO To surprise, realised phase Initial Coin Offering (ICO) begin, wanted acquire rights \u00c6ons (the \u00c6ternity token). During phase 1, ETH purchase 1100 \u00c6ons. In early April 2017, ETH worth about\u00a0\u00a338. willing small risky investment, order work convert conventional Sterling Bitcoin Ether, order purchase \u00c6ons. \u00c6ternity website made super easy set Etherium wallet, wallet invest \u00c6ternity project, buying Ether immediately putting wallet proved Helpfully, \u00c6ternity project had partnered Swiss firm \u2018Bitcoin Suisse AG\u2019 who directly convert \u00c6ons fiat currencies, cutting purchase intermediate digital currency. However once I\u2019d completed identity checks signed, scanned sent multiple forms, realised I\u2019d pay \u2018signing on\u2019 fee \u00a370. To Bitcoin Suisse\u2019 credit though, did manually approve identification contract within an\u00a0hour. At time, thought project still good investment even extra cost, determined exhaust other possibilities first. I\u2019m familiar cryptocurrency wallets public/private keys due previous research, able immediately begin trying set account an\u00a0exchange. Exchanges What followed fairly chaotic few hours where sign-up several exchanges see close get purchasing either Bitcoin Ether immediately, before realising either had wait 48 hours security clearances, provide additional details, wait manual verification scanned By end evening had rough idea usernames, passwords (small) sterling amounts had been submitted each\u00a0exchange. After couple false starts, combination Coinbase desktop website their iOS app purchase ETH their weekly limit, multiple cards increase holding ETH. Coinbase app bug processing debit card payment verifying card details bank. had initially led me try other exchanges, where hit other roadblocks delays. CEX.IO, example, doesn\u2019t allow trades first 48 hours (IIRC) after registering, reasonable enough unless you\u2019re a\u00a0hurry. Conclusion Once had few Ether name, rest process simple. delighted visit Etherscan.io view details Etherium - \u00c6ternity transactions almost immediately. gave me lot confidence hadn\u2019t sent money void, nice contrast (successful) experience buying bitcoin early\u00a02014. Finally, simple tool check \u00c6 balance bottom Eternity\u2019s contribution page assured me I\u2019d made investment successfully. To me, \u00c6ternity project stands exciting endeavor seeking solve widespread highly valuable technical challenges, hope they\u2019re successful wish them\u00a0well.","tag":"[, , , , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Blogging with\u00a0Pelican","url":"pelican.html","body":"When began blogging 2016, became aware blogs designed. Many favorting blogs had simple designs made easier focus content, loaded really fast. (E.g. CuriousGnu). wanted blog, too. I\u2019d Wordpress build publish blog great way begin, felt compromising design functionality. wanted control over led me static sites contain fixed content faster load easier design built dynamic blogging platform such Wordpress. Because already familiar Python chose Pelican rather another static site generator such as\u00a0Jekyll. There plenty sites tell start blogging Pelican, here focus experience after initial set-up. When learning begin, found Amy Hanlons blog particularly useful and\u00a0clear. learning\u00a0curve \u2026 longer expected. Since setting switch Wordpress Pelican, I\u2019ve taught myself enough following tools hack site together. I\u2019m really happy these tools future projects\u00a0too. HTML find HTML quirky intuitive. Tags sense, comments laborious learning google relatively quick. Whatever I\u2019m trying (like add link jump back top page) someone posted CSS Writing CSS feels lot concise HTML also felt impossible learn without taking step back reading introductory course. Usually learn hacking phrases together existing examples frustrating go backwards before progressing. There lightbulb moment realised CSS Selectors were thing, realising CSS files get called header (usually) HTML\u00a0file\u2026 ended trial subscription Thinkfuls Front-end developer course, pretty good explaining CSS structured arrange content page. still had access, I\u2019d completing second half course\u00a0:) Jinja tool written Python create HTML pages. It doesn\u2019t look intuitive me, I\u2019ve been able get enough done copy-pasting similar snippets other parts theme started (Thanks Molivier!) changes wanted. I\u2019d learn seems Pelican To build website Pelican, run commands terminal. There various commands found myself few regularly. generate project skeleton get started. \u201cmake devserver\u201d initialise local server generate output files view changes locally before uploading (its opposite \u201cmake stopserver\u201d). Finally \u201cpelican content -s generates html css remote hosting. Some plugins such \u201cAssets\u201d minifies CSS work publshconf.py called, confused me initially didn\u2019t think working Git really challenged me, still don\u2019t feel know I\u2019m doing. Git far powerful be, want undo erroneous edits upload version site to\u00a0Github. stage commit files, create local remote repo\u2019s command line. change remote\u2019s URL, reset repo force push pull. That\u2019s all. haven\u2019t tried merge create test branch, part process goes wrong usually takes hours right\u00a0again. tool awesome SO Google cannot magic exact right answer For example, there still output folder source repo is\u2026 mysterious me. Its real output, version frozen few weeks ago, \u201c@\u201d name. don\u2019t know got there. It created afternoon blur frustrated google queries find git\u2019s commands least intuitive tools use, preceeding single dashes double dashes, random words thrown middle otherwise But Git ubiquitous Github awesome, learn\u00a0it. Github pages external URL You\u2019ll add file called CNAME repo containing output. CNAME should contain address site You\u2019ll also update DNS records domain name point name Github\u2019s servers. For Github, two \u201cA Records\u201d host \u201c@\u201d values respectively. You also CNAME record host \u201cwww\u201d equal It took 12 hours changes propagate, during had variable success loading the\u00a0site. Plugins One thing didn\u2019t want moving away Wordpress site bloated features didn\u2019t content easier read. However found still needed few plugins optimise site provide basic functionality doesn\u2019t come Super useful, publish notebook webpage copy .ipynb file context directory add sidecar .ipynb-meta file standard meta data. functionality reasons why Pelican popular bloggers. (Though Nikola Neighbors At end post there should link previous next blog posts - surprised wasn\u2019t included standard. After putting plugin plugins folder updating copy couple jinja snippets template, maybe add css links look\u00a0nice. Make those images small possible help site fast possible. Add plugin, update thats\u00a0all. Assets Before started working Pelican, minifying css JavaScript been too advanced. But once Pingdom Google Pagespeed started criticising me multiple .css files, accepted the\u00a0challenge. Conclusion I\u2019m super happy wth websites design speed. It\u2019s designed way want it, I\u2019ve learnt ton useful stuff along the\u00a0way. Update: My second post blogging Pelican here.","tag":"[, , , ]","category":"Technical/Web"},{"title":"Analysing a personal\u00a0library","url":"books.html","body":"A friend mine collected books years recently begun catalogue them. In post, show simple analysis catalogue query ISBN database fill missing\u00a0data. In\u00a0[1]: import HTML function code_toggle() { (code_show){ } else { } code_show = !code_show } $( document </script> <font toggle visibility code blocks, click <a <script> window.onload = function(){ //time set milliseconds 10000) }; </script> ''') Out[1]: function code_toggle() { (code_show){ } else { } code_show = !code_show } $( document To toggle visibility code blocks, click here. Set-up settings import some\u00a0packages: In\u00a0[2]: # Display plot results inline, separate window %matplotlib inline %pylab inline # Set size figures = (14, 5) import pandas pd import re import bibtexparser import numpy np import plt Populating interactive namespace numpy matplotlib Load In\u00a0[3]: table = table = table[0:9188] df = table orig_rows = (df.shape[0]) print(\"There %d rows catalogue\" % (df.shape[0]) ) There 9187 rows catalogue Data formatting tidying:\u00b6View top 5 rows see arranged cells are\u00a0complete. In\u00a0[4]: df.head() Out[4]: Location Subject Title Author Publisher ISBN? Shelf Pages Price Value Date HR Islam Islamic Invasion R Morey Harvest HP 1960 89081 983 17cm 221 3 8 2008-04-01 00:00:00 HR Word lists New Testament Word Lists Morrison & Barnes Erdmans 1975 8028 1141 8 NaN 125 3 NaN 2008-04-01 00:00:00 HR Theology: Salvation Triumph crucified E Sauer Paternoster 1952 NaN NaN 207 3 2008-04-01 00:00:00 3 HR Early Fathers Ante-Nicene Christian Library Ed Menzies T&T Clark 1897 NaN NaN 533 9 NaN 2010-03-01 00:00:00 4 HR Apologetics Earth\u2019s earliest ages G.H. Pember H & S 1895 NaN NaN 494 3 NaN 2008-04-01 00:00:00 Set format two decimal places (currency). Not rows become a\u00a0float: In\u00a0[5]: = def to_number(s): try: s1 = s1 except ValueError: s df.Price = f : to_number(f)) df.Value = f : to_number(f)) Find remove blank\u00a0rows: In\u00a0[6]: # How rows NaN values df = # drop row ALL columns NaN print('%d row removed ' % (orig_rows - df.shape[0]) ) # row contained NaN been removed row removed List rows column are\u00a0empty: In\u00a0[7]: # How rows column NaN Out[7]: Location 29 Title 34 Publisher 175 Shelf 336 Pages 540 Author 915 Price 3611 ISBN? 4770 Date 5712 Subject 6208 Value 9179 dtype: int64 Based these results, title publisher most Split column containing two types of\u00a0data: \u201cPublisher\u201d column contains both publisher year published. should split two\u00a0columns. In\u00a0[8]: = None # default='warn' df['PubYear'] = expand=True) # regex confusing = expand=True) Improve format \u2018Date\u2019\u00a0column: In\u00a0[9]: df['Date'] = frame now columns want in, top 5 rows\u00a0are: In\u00a0[10]: df.head() Out[10]: Location Subject Title Author Publisher ISBN? Shelf Pages Price Value Date PubYear HR Islam Islamic Invasion R Morey Harvest HP 89081 983 17cm 221 3.00 8.00 2008-04-01 1960 HR Word lists New Testament Word Lists Morrison & Barnes Erdmans 8028 1141 8 NaN 125 3.00 NaN 2008-04-01 1975 HR Theology: Salvation Triumph crucified E Sauer Paternoster NaN NaN 207 3.00 10.00 2008-04-01 1952 3 HR Early Fathers Ante-Nicene Christian Library Ed Menzies T&T Clark NaN NaN 533 9.00 NaN 2010-03-01 1897 4 HR Apologetics Earth\u2019s earliest ages G.H. Pember H & S NaN NaN 494 3.00 NaN 2008-04-01 1895 books bar chart below shows books library were published given decade. list below shows 5 oldest\u00a0books. In\u00a0[11]: = '{:,}'.format df.PubYear = fig = // * logy = False) Publication\") Books\") fig Out[11]: 0x10501f2b0> View 5 oldest\u00a0titles: In\u00a0[12]: df['PubYear'] = df2 = != 0.0] Out[12]: Location Subject Title Author Publisher ISBN? Shelf Pages Price Value Date PubYear 4753 Lib NaN In Christ\u2019s own country Dom Ernest Graf Burns Oates NaN Sh.4.5 302 Gift NaN 1999-07-30 1037 3043 StM NaN First Epistle Peter C.E.B. Cranfield SCM Press interesting Sh.5.5 128 NaN NaN NaT 1050 4574 Lib Music Score Easy-Play Speed Music; waltz clas NaN Sight & Sound NaN Sh.4.4 47 99P NaN NaT 1076 7184 25A NaN Noble Qur\u2019an transl Al-Hilali & Khan Madinah NaN Sh.3.6 956 3.0 NaN 2010-12-10 1417 3296 Lib NaN Chained Bible NaN Chris Barker Very incomplete Sh.1.1 NaN NaN NaN NaT 1585 List books each\u00a0location: In\u00a0[13]: df3 = df = Out[13]: Location 25A 3411 LIB 2457 CH 1088 ST9 1000 STM 886 HR 305 NAN 29 ST.M 3 HR ST M SA LB CH :LIB dtype: int64 Create list differnet subjects, order list most In\u00a0[14]: df4 = df df4[\"Subject\"] = Out[14]: Subject NAN 6208 COMMENTARY 61 LOCAL HISTORY 58 SERMONS 41 THE CENTURY BIBLE 37 THEOLOGY 36 CHRISTIAN BIOGRAPHY 34 BIOGRAPHY 31 NT COMMENTARY 31 HEBREW GRAMMAR 30 SACRED BOOKS OF THE EAST 30 POETRY 29 CLARK'S FOREIGN THEOL LIB 28 GENERAL EDIT ANTONIA FRAZER 25 NOVEL 24 WRITERS AND THEIR WORK 24 CATALOGUE 22 AUTOBIOGRAPHY 20 OT COMMENTARY 19 GREEK 19 THE EXPOSITOR'S BIBLE 18 SRIMAD BHAGAVATAM 18 THE BABYLONIAN TALMUD 18 PHOTOGRAPHS 17 GREAT MUSEUMS OF T WORLD 15 CHURCH HISTORY 14 DAILY READINGS 14 CHRISTIAN LECTURES 14 NOTES ON THE CATHEDRALS 14 INTERNATIONAL CRITICAL COMM 13 ARAMAIC 13 THE CLARENDON BIBLE 13 FICTION - CADFAEL 13 CLARK'S FOREIGN THEOL LIB. 13 APOLOGETICS 12 PSALMS 12 THE CAMBRIDGE BIBLE 12 PRAYER 12 LIFE LIBRARY OF PHOTOGRAPHY 11 COMMENTARY ON HOLY SCRIPT 11 THE MASTERPIECE LIBRARY 11 COMMENTARY ON THE O.T. HYMNS POEMS MYSTICISM DICTIONARY OF THE BIBLE EXHIBITION CATALOGUE POETICAL WORKS OF TENNYSON DICTIONARY HISTORY dtype: int64 Create list authors library. Order list of\u00a0books: In\u00a0[15]: df5 = df df5[\"Author\"] = Out[15]: Author NAN 915 VARIOUS 31 BHAKTIVEDANTA S PRAB 19 C.H. SPURGEON 19 ELLIS PETERS 17 ED. RABBI I. EPSTEIN 17 LESLIE WEATHERHEAD 15 ED CARLO RAGGHIANTI 15 ALBERT BARNES 14 JAMES HASTINGS 13 GEORGE ADAM SMITH 13 WILLIAM TEMPLE 12 JAMES MOFFATT 11 ED J A HAMMERTON 11 KEIL & DELITZSCH 11 WILLIAM BARCLAY SHAKESPEARE PETER ACKROYD IAN WILSON 9 CHARLES DICKENS 9 BERNHARD WEISS 9 J.B. PHILLIPS 9 ED QUENNELL & HODGE 8 CHARLES GORE 8 H.V. MORTON 8 M.F. SADLER 8 VARIOUS AUTHORS 8 ED ANDREW LANG 8 GEZA VERMES 8 S.R. DRIVER 8 EVELYN UNDERHILL 8 \" 8 HENRY ALFORD 7 ALDOUS HUXLEY 7 ED JAMES HASTINGS 7 ED ARTHUR MEE 7 ROY STRONG 7 ALEXANDER MACLAREN 7 MARCUS DODS 7 JOACHIM JEREMIAS 6 THOMAS WRIGHT 6 ED R. CROMARTY 6 SUSAN GLYN 6 DAVID FOUNTAIN 6 WILLIAM WHISTON 6 C.S. LEWIS 6 BARRIE TRINDER 6 DAVID TRUMPER 6 G. CAMPBELL MORGAN 6 ALISTER MCGRATH 6 dtype: int64 Distribution book length of\u00a0pages: In\u00a0[16]: def try: s1 = s1 except ValueError: '' df.Pages = f : df6 = != ''] 2000, 100.0)) fig = range=[0, 2000]) Pages\") Books\") Out[16]: 0x10585b3c8> Query ISBN database find missing\u00a0data: Lastly, thought fun challenge fill gaps data. table below shows rows ISBN missing either Author, Title or\u00a0Publisher. It turns there rows meet criteria, cases publisher is\u00a0missing. In\u00a0[17]: df7 = & ((df['Author'] == '') | (df['Title'] == '') | == ''))] df7 Out[17]: Location Subject Title Author Publisher ISBN? Shelf Pages Price Value Date PubYear 1430 ST9 BIOGRAPHY OF SCIENTIST Longitude (John Harrison) DAVA SOBEL 85702 571 7 Sh.1.2 184.0 5.99 NaN NaT 1998 2707 STM DEVOTIONAL! Romans: Momentous News DAVID COOK 978 906173241 Sh.3.4 55.0 1.0 NaN 2011-07-28 2011 3874 LIB NAN Annie\u2019s Box - Darwin\u2019s daughter RANDAL KEYNES 84115 060 6 Sh.2.4 331.0 3.99 NaN 2002-07-20 2001 4705 LIB HISTORICAL NOVEL Galileo\u2019s Daughter DAVA SOBEL 85702 861 9 Sh.4.5 429.0 NaN NaN 2002-09-27 1999 5949 25A NAN Short Life Long Times Mrs Beeton KATHRYN HUGHES 84115 373 7 Sh.1.4 525.0 \u00a32.50P NaN 2012-02-09 2005 6008 25A NAN Signs Sky (Birth New Age ADRIAN GILBERT 609 80793 5 Sh.1.5 329.0 4.0 NaN 2012-03-07 2001 6097 25A NAN Isaac Newton, last Sorcerer MICHAEL WHITE 85702 706 X Sh.1.6 403.0 \u00a31.50P NaN 2012-02-09 1997 6663 25A NAN Live Wires - powerful stories cha D. J. CARSWELL 978 906173 13 5 Sh.2.7 124.0 1.0 NaN 2011-06-29 2010 8640 25A KING ARTHUR QUINCENTENARY One Specyal ED SIDNEY HART 948485 Sh.5.9 145.0 \u00a32.49P NaN 2003-06-28 1985 8845 25A NAN Order St John - short history E L EDMONDS 947718 07 9 Sh.5.7b 35.0 \u00a33.75P NaN NaT 1986 In\u00a0[18]: isbnlib import * isbnlib.config import * import * import bibtexparser def SERVICE = 'isbndb' APIKEY = 'IZXL3ESD' # YOUR key APIKEY) # register key bibtex = isbn = clean(isbn) try: = SERVICE)) except: 'isbn invalid' In\u00a0[19]: def get_pub(isbn): bibtex_str = has_isbn(isbn) try: bib_db = dic = except: In\u00a0[20]: df7['ISBN?'] = df7.Publisher = f : get_pub(f)) table below shows results isbnlib query. thought odd \u2018missing\u2019 publishers names began number. It turns regex method split publisher name year publication separate columns doesnt work there numbers publishers name. Rather go back correct this, I\u2019ll leave script show In\u00a0[21]: df7 Out[21]: Location Subject Title Author Publisher ISBN? Shelf Pages Price Value Date PubYear 1430 ST9 BIOGRAPHY OF SCIENTIST Longitude (John Harrison) DAVA SOBEL Fourth Estate 85702 571 7 Sh.1.2 184.0 5.99 NaN NaT 1998 2707 STM DEVOTIONAL! Romans: Momentous News DAVID COOK 10Publishing 978 906173241 Sh.3.4 55.0 1.0 NaN 2011-07-28 2011 3874 LIB NAN Annie\u2019s Box - Darwin\u2019s daughter RANDAL KEYNES 4th Estate 84115 060 6 Sh.2.4 331.0 3.99 NaN 2002-07-20 2001 4705 LIB HISTORICAL NOVEL Galileo\u2019s Daughter DAVA SOBEL Fourth Estate 85702 861 9 Sh.4.5 429.0 NaN NaN 2002-09-27 1999 5949 25A NAN Short Life Long Times Mrs Beeton KATHRYN HUGHES None 84115 373 7 Sh.1.4 525.0 \u00a32.50P NaN 2012-02-09 2005 6008 25A NAN Signs Sky (Birth New Age ADRIAN GILBERT Three Rivers Press 609 80793 5 Sh.1.5 329.0 4.0 NaN 2012-03-07 2001 6097 25A NAN Isaac Newton, last Sorcerer MICHAEL WHITE Fourth Estate 85702 706 X Sh.1.6 403.0 \u00a31.50P NaN 2012-02-09 1997 6663 25A NAN Live Wires - powerful stories cha D. J. CARSWELL None 978 906173 13 5 Sh.2.7 124.0 1.0 NaN 2011-06-29 2010 8640 25A KING ARTHUR QUINCENTENARY One Specyal ED SIDNEY HART Three Golden Crowns 948485 Sh.5.9 145.0 \u00a32.49P NaN 2003-06-28 1985 8845 25A NAN Order St John - short history E L EDMONDS s.n 947718 07 9 Sh.5.7b 35.0 \u00a33.75P NaN NaT 1986 { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , ]","category":"Technical/Data"},{"title":"FakeGL: A Synthetic General Ledger and Trial\u00a0Balance","url":"fakegl.html","body":"My work involves processing lot General Ledgers wanted build test various automation analytical techniques see workflow improved. In order free fun way, fake data, set build process generate fake General Ledger (GL) corresponding Trial Balance (TB). Motivation didn\u2019t know comprehensive needed GL - modern systems complex store wide variety uses. resolved start something simple iterate long I\u00a0wanted. journals produced below satisfy following general Each journal contains equal debits and\u00a0credits Opening closing Trial Balances net to\u00a00 Profit Loss (P&L) accounts start year balance, Balance Sheet (BS) accounts do\u00a0not. Each transaction hits both P&L BS (i.e. account P&L credited, other side transaction debit BS) Distinguish between manual GL: Contains journals posted evenly throughout year (this isnt realistic, simple way generate date\u00a0data) Receives journals Identifies journal manual depending subledger Records user posted journal journal is\u00a0manual script below allows user to\u00a0specify: accounts GL/TB journals GL A mean variance lines each\u00a0journal A mean variance functional amounts posted to\u00a0accounts How different users post beginning financial\u00a0year criteria manual journal, based on\u00a0subledger proportion manuals are\u00a0manual proportion accounts hit P&L BS An arbitrary list of\u00a0subledgers Jupyter Notebook below shows annotated Python 3 code I\u00a0wrote: Notebook set-up\u00b6Load various libraries easily add required features. Two libraries to\u00a0note: Pandas pythons ubiquitous handling\u00a0tool Faker useful tool generate fake data, easy way bootstrap a\u00a0database In\u00a0[1]: random import gauss faker import Factory import random import numpy np import datetime import timedelta import datetime natsort import natsorted, ns import pandas pd Choose parameters values GL TB\u00b6 In\u00a0[2]: # ****** Number different accounts GL ********* x = 111 # ****** Number journals GL j = 15713 # Setup posting date d0 = '20160101' # first day, generated over year. d1 = \"%Y%m%d\") # ****** Distribution lines per journals ************* jl_1 = 21 # mean jl_2 = # variance j_l = lambda x, y: # ****** Number different users posting journals ***** fake = U = ul = [] _ range(0,U): # ****** Functional amount values q1 = 700 # mean q2 = 104 # variance def q(q1,q2): p = < 0.5 # True implies p: i = -1 else: i = = i * # ****** Proportion journals manual ******** Mp = 0.23 # ****** Proportion accounts P&L accounts *** Pp = 0.3 # ****** Subledger names ********* source_feeds = account feeds P&L BS: In\u00a0[3]: def len(element) > 0: element[2] == 'P' False def len(element) > 0: element[2] == 'B' False Generate account\u00a0codes: In\u00a0[4]: def b_names = [] p_names = [] a_names = [] p = 'ACP' b = 'ACB' i range(x): A = < Pp A: y = else: y = len(b_names) % != 0: del b_names[-1] len(p_names) % != 0: del p_names[-1] a_names = b_names + p_names Generate journal names and\u00a0lengths: In\u00a0[5]: def d0 = '20160101' # first day, generated over year. d1 = \"%Y%m%d\") a_n = [] i range(j): = y = 'J_' + + d1 = d1 + a_n.append(y) j_names = dict((el, int( j_l(jl_1,jl_2) / )) el a_n) # determine lines journal. j_names Create list journal names account codes\u00b6 In\u00a0[6]: j_names = a_names = Create fake General Ledger save text file\u00b6 In\u00a0[7]: # Output format glf = f = open('gl.txt', 'w') f.write(glf + '\\n') key key=lambda y: y.lower()): line_no = -1 i = # Assign journal source feed source_id = # Assign journal posting date posting_date = d1 = d1 + # Make journal either M A, M assign user = < Mp # True implies U, 3*U/4) t: man_ind = 'M' u_name = ul[int(p)] else: man_ind = 'A' u_name = '' # Assign functional amount while i < j_names[key]: i = i + line_no = line_no + line_no2 = line_no + dr = q(q1,q2) cr = -1 * dr a_names_p = a_names)) a_names_b = a_names)) an1 = an2 = l_1 = key + '|' + str(line_no) + '|' + man_ind + '|' + posting_date + '|' + u_name + '|' + an1 + '|' + source_id + '|' + 'GBP' + '|' + str(dr) l_2 = key + '|' + str(line_no2) + '|' +man_ind + '|' + posting_date + '|' + u_name + '|' + an2 + '|' + source_id + '|' + 'GBP' + '|' + str(cr) f.write(l_1 + '\\n') f.write(l_2 + '\\n') f.close() Create Trial Balance save text file\u00b6 In\u00a0[8]: # Use gl calc movement account gl = sep = '|') tb = # Calc net movement account tb = inplace=True) tb.columns = = 'Account') # Assign account # Set b/f balances P&L accounts == 'P', 'Balance b/f'] = == 'P', 'Type'] = 'P&L' == 'B', 'Type'] = 'BS' tb['Balance b/f'] # b/f balance != 0, generate balance account i = index, row tb.iterrows(): row['Balance dummy'] != 0: row['Balance b/f'] = bal = b/f'] = bal b/f'] = -1 * bal i += del tb['Balance dummy'] # create c/f field tb['Balance c/f'] = ( tb['Balance b/f'] + tb['Movement'] ).round(2) # create 'date balance' column tb['Balance date'] = # Arrange columns tb = tb[['Account', 'Type', 'Balance b/f' , 'Balance c/f', 'Balance date']] # print TB file sep='|', header=True, index=False) Load text files back display their top rows\u00b6Verify files been produced correctly TB balances as\u00a0expected In\u00a0[9]: gl = sep = '|') tb = sep = '|') In\u00a0[10]: tb.head(10) Out[10]: Account Type Balance b/f Balance c/f Balance date ACB00003 BS 673.10 72348.68 20161231 ACB00007 BS -673.10 20045.09 20161231 ACB00010 BS 748.16 -30340.79 20161231 3 ACB00012 BS -748.16 188.39 20161231 4 ACB00015 BS 814.96 48294.11 20161231 5 ACB00017 BS -814.96 10659.80 20161231 6 ACB00021 BS 835.56 18357.33 20161231 7 ACB00032 BS -835.56 3406.80 20161231 8 ACB00034 BS 759.60 26505.40 20161231 9 ACB00036 BS -759.60 -39128.80 20161231 In\u00a0[11]: gl.head(10) Out[11]: Journal_ID Line Type Date User Account Source J_20160101_1 M 20160101 Iain Gardiner ACP00054 sl2 GBP -587.49 J_20160101_1 M 20160101 Iain Gardiner ACB00064 sl2 GBP 587.49 J_20160101_1 3 M 20160101 Iain Gardiner ACP00022 sl2 GBP 816.17 3 J_20160101_1 4 M 20160101 Iain Gardiner ACB00017 sl2 GBP -816.17 4 J_20160101_1 5 M 20160101 Iain Gardiner ACP00088 sl2 GBP 628.60 5 J_20160101_1 6 M 20160101 Iain Gardiner ACB00062 sl2 GBP -628.60 6 J_20160101_1 7 M 20160101 Iain Gardiner ACP00079 sl2 GBP -672.34 7 J_20160101_1 8 M 20160101 Iain Gardiner ACB00017 sl2 GBP 672.34 8 J_20160101_2 A 20160101 NaN ACP00005 sl1 GBP -683.52 9 J_20160101_2 A 20160101 NaN ACB00036 sl1 GBP 683.52 In\u00a0[12]: print('Net Opening TB:',\"%.2f\" % tb['Balance b/f'].sum()) print('Net Closing TB:',\"%.2f\" % tb['Balance c/f'].sum()) Net Opening TB: 0.00 Net Closing TB: 0.00 { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , , , , , , ]","category":"Technical/Data"},{"title":"Reconciliation of a trial balance to a general\u00a0ledger","url":"reconciliation.html","body":"I\u2019ve been working financial ledgers lot recently. python code below shows automated workflow import, process report reconciliation Trial Balance (TB) General Ledger (GL). I\u2019m fake data, script work fine real fields were renamed appropriately. A real set additional fields needed considered, these vary depending size business being analysed. Therefore fake GL TB here simple generic. Additional fields, such entity code, transaction status, approver, stamps, etc added quickly and\u00a0simply. Set-up notebook import\u00a0data: In\u00a0[1]: # Import libraries import pandas pd import random In\u00a0[2]: # Import (possibly incomplete and/or inaccurate) gl = sep = '|') tb = sep = '|') Create Calculate net movement account ledger\u00a0data: In\u00a0[3]: gl_move = gl_move = inplace=True) = = 'Account') inplace = True) Calculate movement account trial\u00a0balance: In\u00a0[4]: = ( tb['Balance c/f'] - tb['Balance b/f'] ).round(2) inplace = True) Compare accounts movement ledger trial balance write result report containing reconciliation results all\u00a0accounts: In\u00a0[5]: Rec_report = = 'outer', left_index = True, right_index = True) = - = date'] = sep='|', header=True, index=True) Put accounts reconcile In\u00a0[6]: Unreconciled = != 0] Unreconciled = = False).index) sep='|', header=True, index=True) Unreconciled Out[6]: Type Balance b/f Balance c/f Balance date TB_Movement GL_Movement difference Account ACP00081 P&L 0.00 -16279.96 20161231 -16279.96 -17017.89 737.93 ACB00082 BS 760.09 -4041.02 20161231 -4801.11 -4063.18 -737.93 ACP00071 P&L 0.00 -28547.84 20161231 -28547.84 -29260.31 712.47 ACB00091 BS 628.24 3054.74 20161231 2426.50 3138.97 -712.47 ACP00017 P&L 654.01 24449.74 20161231 23795.73 23123.06 672.67 ACB00076 BS 768.49 -48456.11 20161231 -49224.60 -48551.93 -672.67 ACB00037 NaN NaN NaN nan NaN 19808.54 NaN ACP00001 NaN NaN NaN nan NaN -3817.92 NaN ACP00041 NaN NaN NaN nan NaN -14365.77 NaN ACP00046 NaN NaN NaN nan NaN 1825.79 NaN ACP00086 NaN NaN NaN nan NaN -7263.37 NaN Create report containing In\u00a0[7]: # Accounts TB GL = == True] In\u00a0[8]: # Accounts TB where TB_Movement isn't matched GL = == ==False)] In\u00a0[9]: Total_Accounts = = Total_Accounts - = Rec_Fraction = / Total_Accounts Unrec_Fraction = / Total_Accounts In\u00a0[10]: \"w\") text_file: print('The 'accounts', 'accounts reconcile (', '%)\\n', 'accounts reconcile (', '%)', In\u00a0[11]: \"a\") text_file: print('There are', 'accounts GL TB. (', '% unreconciled accounts)', print('There are', 'accounts journals missing (', '% unreconciled accounts)', In\u00a0[12]: net_diff = == \"a\") text_file: print('The net differences is', net_diff, In\u00a0[13]: # Does TB balance? \"a\") text_file: print('\\nTB opening balance unbalanced by', \"%.2f\" % tb['Balance b/f'].sum(), print('TB closing balance unbalanced by',\"%.2f\" % tb['Balance c/f'].sum(), print('***If these TB certainly wrong receiving \\nbalanced TB first step reconciling accounts***', In\u00a0[14]: diffs = frequency = {} w diffs: frequency[w] = 0) + pairs = {x x frequency x > 1} # dict comprehension filter pairs \"a\") text_file: print('\\nThere are', len(pairs), 'unreconciled accounts equal opposite differences', In\u00a0[24]: 'r') fin: contains 110 accounts 99 accounts reconcile ( 90.0 %) 11 accounts reconcile ( 10.0 %) There 5 accounts GL TB. ( 45.45 % unreconciled accounts) There 6 accounts journals missing ( 54.55 % unreconciled accounts) net differences 0.0 TB opening balance unbalanced -2486.28 TB closing balance unbalanced 1326.45 ***If these TB certainly wrong receiving balanced TB first step reconciling accounts*** There 3 unreconciled accounts equal opposite differences { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, , , , , ]","category":"Technical/Data"},{"title":"Spotify song\u00a0history","url":"spotify.html","body":"Spotify recently sent me their \u20182016 Wrapped\u2019 email containing few statistics listening habits 2016, playlist 101 most played\u00a0songs. decided compare their statistics those I\u2019d gathered myself. There option Preferences menu log (\u2018scrobble\u2019) Spotify listening history last.fm. where download data. thought interesting verify Spotify stats, see discover any other 1. Notebook set-up\u00b6 In\u00a0[1]: # Display plot results inline, separate window %matplotlib inline %pylab inline # Set size figures = (14, 5) # Import pandas nicer plotting style import pandas pd import plt plt.style.use = 'default' Populating interactive namespace numpy matplotlib In\u00a0[2]: # Make dataframes look bit prettier import HTML css = + # Print output decimal places = # Just works cell # sets behaviour entire notebook %precision %.2f Out[2]: '%.2f' 2. Load explore data\u00b6 In\u00a0[3]: # Load .csv file downloaded column_names = ['Artist', 'Album', 'Name', 'd_t'] # Choose column names df = names = column_names, header=None) # Convert date column (d_t) string date time, search date df['d_t'] = Some initial questions answer get feel the\u00a0data: How much is\u00a0there? What is\u00a0present? What maximum \u2026etc. In\u00a0[4]: # View top rows df.head(10) Out[4]: Artist Album Name d_t Bonobo Animal Magic Kota NaT Samaris Samaris G\u00f3\u00f0a tungl 2016-12-15 09:44:00 Staves Dead & Born & Grown Mexico 2016-12-15 09:40:00 3 Bonobo Animal Magic Kota 2016-12-15 09:34:00 4 Gloaming Gloaming Sailor\u2019s Bonnet 2016-12-15 09:30:00 5 St. Germain St Germain Forget Me Not 2016-12-15 09:24:00 6 Yosi Horikawa Wandering Bubbles 2016-12-15 09:19:00 7 South Music O.C. Mix Paint Silence 2016-12-15 09:13:00 8 Staves Sleeping In A Car Sleeping In A Car 2016-12-15 09:09:00 9 Bonobo Days Come Recurring 2016-12-15 09:04:00 In\u00a0[5]: #How rows there? len(df) Out[5]: 36454 In\u00a0[6]: # How 2016 rows == 2016]) Out[6]: 1983 In\u00a0[7]: # Are there any NaN values 2016? Ans = == 2016) & print('There are', Ans, 'rows NaN values 2016') There rows NaN values 2016 In\u00a0[8]: # Maximum minimum dates print(\"Oldest record print(\"Most recent record Oldest record is: 1970-01-01 00:00:00 Most recent record is: 2016-12-15 09:44:00 Scrobbling last.fm turned off first half of\u00a02016. In\u00a0[9]: #print(\"Oldest record 2016 == 2016 began == Scrobbling 2016 began at: 2016-06-14 20:24:00 Therefore important remember being analysed represents half of\u00a02016. 3. Verify Spotify\u2019s statistics\u00b63a. Total Minutes\u00b6 According Spotify, listened 2357 unique artists year, 3309 unique tracks. Total streaming 45202 minutes. They dont tell me non-unique plays I\u00a0accumulated. Googling \u2018average song length\u2019 reveals most pop songs last 3.5 minutes, think songs listen longer than\u00a0that. Spotify\u2019s UI understandably light details, initially wondered calculate average song length. First just eyeballed (\u2018scanning analytics..\u2019). Then realised sort playlist song length pick median, although I\u2019d know songs were the\u00a0playlist. Whilst searching playlist properties \u2018number songs\u2019 simply spotted needed below description; 101 songs, total play 8hrs, 29\u00a0minutes. Spotify tell me I\u2019ve spent 45202 minutes streaming music listened 3309 unique tracks in\u00a02016. Therefore: In\u00a0[10]: # Average length 101 most listened songs Average = round((8*60 + 29)*60/101,2) print(\"Average song length:\", Average, \"seconds\") print(\"or 5 minutes, seconds \\n\") # Time spent listening Spotify days print(\"Days listening Spotify 2016:\", A whole month?!? \\n\") # Time spent listening Spotify seconds seconds_used = 45202 * 60 # Number songs played n_tracks = / Average,2) print(\"Number songs played # Average plays per songs unique_tracks = 3309 # From summary email average_plays = round(n_tracks / print(\"On average, listen track\", average_plays, \"times\") Average song length: 302.38 seconds 5 minutes, seconds Days listening Spotify 2016: 31.46 ...Really? A whole month?!? Number songs played 2016: 8969.24 On average, listen track 2.71 times surprisingly large amount spent listening music. cannot believe spent 1/12 2016 streaming music Spotify. also thought quite repetitive listener, average 2.7 plays per song surprisingly low. (For example, short playlist \u2018Recurring\u2019 Bonobo 5\u00a0times.) 3b. Unique Spotify, listened 2357 unique artists in\u00a02016. In\u00a0[11]: Ans = == print('Number unique artists scrobbled 2016:', Ans) Number unique artists scrobbled 2016: 510 songs were being scrobbled last.fm listening behaviour remained same thoughout year, expected result half Spotify\u2019s result (because began scrobbling June). summary email reported 2357 unique artists 2016. 510 clearly much less half of\u00a02357. 3c. Unique tracks\u00b6 In\u00a0[12]: Ans = == print('Number unique tracks scrobbled 2016:',Ans) Number unique tracks scrobbled 2016: 1060 Spotify reported 3309 unique tracks played 2016. My result 1060 unique tracks second half 2016 less expected, though difference between expectation result great 3d. My top Spotify, 3 most played tracks 2016\u00a0are: Lights Out Words\u00a0Gone Shuffle Luna \u2026all Bombay Bicyle\u00a0Club In\u00a0[13]: # Which tracks did listen most 2016? == Out[13]: Miserere 14 Shuffle 14 Lights Out Words Gone 12 Pilgrim\u2019s Song 12 Always Like 12 Luna 11 Hare 11 You Already Know 11 Koop Island Blues Sailor's Bonnet Name: Name, dtype: int64 shows whilst \u2018top tracks\u2019 most listened tracks, Spotify either uses different method calculate plays, \u2018top\u2019 synonymous When June onwards, \u2018top tracks\u2019 joint 1st, 3rd 6th most 3e. Top from\u00a0Spotify: Bonobo Bombay Bicyle\u00a0Club The\u00a0Staves Jack\u00a0Johnson In\u00a0[14]: == Out[14]: Staves 170 Bonobo 161 Gloaming 132 Koop 107 Bombay Bicycle Club 105 Giovanni Pierluigi da Palestrina 70 Jimi Hendrix 48 Jack Johnson 44 Gregorio Allegri 43 Broken Social Scene 33 Name: Artist, dtype: int64 My results different Spotify\u2019s, by\u00a0much. Artist Spotify\u2019s results My result Bonobo Bombay Bicycle Club 5 Staves 3 Thievery Corporation 4 - Jack Johnson 5 8 Apart Thievery Corporation being conspicuously absent own scrobbled data, other differences reasonably explained listening trends being different Jan - June July -\u00a0Dec. results show prefer listening Bonobo over Bombay Bicycle Club, 3 most played songs Bombay Bicyle Club. shows there songs Bonobo enjoy listening to, polarised opinions songs Bombay Bicyle\u00a0Club. 3f. Favourite day Spotify, stream music Saturday any other\u00a0day. In\u00a0[15]: # Plot songs wer played day week second half 2016 == Out[15]: 0x111243c88> Monday=0 and\u00a0Sunday=6. result shows stream music Sunday any other day. different result small difference explained (again) set relating second half 2016. From January June listened music Saturday Sunday - probably playing Starcraft. hobby unfortunately put ice had come second revision exams July and\u00a0November. 4. Time day\u00b6I thought interesting also see much music listen different times. expect listening habits different during week compared weekends, split day summed songs played whilst grouping them by\u00a0hour. figures below show unexpected dip around 3pm weekends, consistent streaming through day whilst office during week. No matter day week, appears always listen music the\u00a0evenings. In\u00a0[16]: # Count songs played during hour weekends == 2016) & > Out[16]: 0x110493dd8> In\u00a0[17]: # Count songs played during hour during week == 2016) & < Out[17]: 0x11048fa58> 5. attempts verify Spotfiy\u2019s statistics fall short covers second half 2016. shows requirement good quality inputs order achieve good Having said that, clear listen Spotify far thought did. observation Bonobo\u2019s tracks polarised views Bombay Bicycle Club\u2019s songs novel. Most all, think I\u2019m getting great\u00a0value! chart below songs played day 14 June 2016 15 December\u00a02016. My top 101 songs 2016 played at: In\u00a0[18]: import warnings figure = == foo = = 3 ticks = ticklabels = [l.get_text() l { var mathjaxscript = = = = ? \"innerHTML\" : \"text\")] = + \" config: + \" TeX: { extensions: { autoNumber: 'AMS' } },\" + \" jax: + \" extensions: + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || }","tag":"[, ]","category":"Technical/Data"},{"title":"Vim!","url":"vim.html","body":"Vim text editor renowned efficiency keyboard shortcuts. It\u2019s based Vi text editor 1970\u2019s. It first released 1991 still being developed today. It comes pre-installed Unix systems (including MacOS) run the\u00a0terminal. Vim famous another way too - being difficult learn. found good remarkably creative tools begin learning concepts controls. necessary there no GUI. There game here, there interactive tutorial. There\u2019s also built-in vim tutorial - just \u2018vimtutor\u2019 into\u00a0Terminal. Vim designed don\u2019t take hands off keyboard mouse. It \u2018insert\u2019 mode where enter text usual, \u2018command\u2019 mode where comprehensive flexible shortcut language move around, edit search text. With no GUI toolbar, it\u2019s very different approach text editing I\u2019m used\u00a0to. You run Vim terminal, there also versions run apps. MacVim MacOS option show tool bar simple commands program, lets arrow keys move cursor addition VIM\u2019s \u2018hjkl\u2019 functionality. makes getting started There also lot plugins extend Vim\u2019s functionality turn text editor IDE. post walks through setting Vim Python IDE explains manage recommend Daniel Mieslers blog post quick overview use\u00a0Vim.","tag":"[]","category":"Technical/Developer Tools"},{"title":"Autumn, BIN and $PATH","url":"autumn-bin-and-path.html","body":"Two small things been learnt recently: importance PATH contents various BIN\u00a0folders. Autumn 2016 gone planned. Whilst studying couple exams plans were put hold hobbies were ceased. Now life returning normal, opportunity post\u00a0again. PATH $PATH variable (string) contains series folder locations separated \u201c:\u201d. Each these folders contains programmes. When name programme terminal without specifying location, OS looks sequentially folder locations listed $PATH see programme there, executes\u00a0it. BIN Bin Binary, Bin in\u00a0Trash. bin folders contain binary files, programmes ready be\u00a0run. run \u201cecho $PATH\u201d Terminal, see 9 folders called bin, convention contain binaries. They just folders, OS set look asked run","tag":"[]","category":"Technical/Developer Tools"},{"title":"Introduction to my doctorate research -\u00a0Silos","url":"silos.html","body":"Background From Spring 2010 until Autumn 2013, PhD candidate living Vienna, Austria working University Natural Resources Life Sciences. Before working Vienna, completed Masters degree Civil Environmental Engineering University of\u00a0Edinburgh. My research quantified effects changing amount gravity acting granular materials poured a\u00a0silo. My PhD thesis short presentation defended\u00a0it. Granular materials broard class materials encountered everyday - salt, pills, breakfast cereal, sand, rice, soil, landslides, salt granular materials. They ubiquitous occur different sizes and\u00a0varieties. Silos common container storing granular materials. You pour granular material top, store while, dispense material controlled quantities the\u00a0bottom. Research\u00a0focus My research focussed quantifying changes gravity affected material contained inside silo, particularly whilst silo being emptied. pertinent engineers scientists yet scientific understanding granular materials behave. Whilst gravity clearly affects granular materials, cannot say exactly\u00a0how. means can\u2019t analytical methods quantify physics occur real system. Instead empirical methods guesses, knowledge worked previous similar situations). isn\u2019t necessarily bad, less efficient less reliable built small model silo (30cm tall) put quite large centrifuge (3 metre diameter). By rotating model silo around centre centrifuge constant speed simulate higher gravity. added high-speed cameras, pressure sensors weighing scales measure material moving once opened silo outlet silo began empty. Photos experimental model built seen\u00a0below. also programmed computer model (using commercial PFC 3D software working FISH scripting language) simulate investigate same behaviours observed numerically as\u00a0physically. class computer model known DEM (Discrete Element Modelling). These models work considering every grain material individually, usually sphere. sphere overlaps another (i.e. distance between two particle centres less sum their radiuses) force proportional overlap size repels two spheres away other. simple approach repeated over every grain particle model, produces life behaviour situations. It advantages over \u201ccontinuum\u201d based techniques model groups grains were just big particle unusual properties. DEM massive limitation, though. It requires huge amounts computational resources - limits industrial scenarios outside. Until computers become much, much powerful, DEM theoretical research Results When gravity increases factor \\(x\\), both discharge rate local velocities within silo increase \\(\\sqrt(x)\\)\u00a0. That\u2019s good know you\u2019re planning storing stuff moon, it\u2019s also useful step towards explaining exactly why bulk granular materials behave way they\u00a0do. An overview research, doctorate thesis published papers downloaded below. PDFs containing 3D models movies require flash render, Adobe Reader Desktop order view\u00a0them. PhD Thesis\u00a0(2013) Modeling silo discharge centrifuge Experimental investigation flow segregation behaviour bulk solids silos under high gravity conditions (Particles 2013 Centrifugal modelling granular flows (Eurofuge Overview research (PhD defence,\u00a02013) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; (false) { align = (screen.width","tag":"[, , , , , , , , ]","category":"Technical/Civil Engineering"},{"title":"Encryption","url":"encryption.html","body":"Blockchains Elliptical Curve Cryptography (ECC) authenticate users authorise transactions. These notes introduce field cryptography explains modern cryptographic methods work. wrote them teach myself encryption To begin absolute basics, encryption generally works taking message representing series numbers turned series random looking numbers. Decryption works turning random looking numbers back Background history Cryptography split classical modern eras. Modern cryptography began 1977 introduction RSA Diffie-Hellman algorithms. Until then, Cryptography required single key (the secret code) encrypt decrypt message. transferred sender receiver secretly, In classical cryptography, code shared\u00a0secret. modern era removed requirement shared secret instead theory basis quantifying strength encryption method. strength modern cryptographic technique quantifiable provable reference theory, rather users ability transport transfer secret\u00a0code. Modern cryptography defined Public Key Cryptographic systems. They key (code) encryption another decryption. encryption key made public without any risk message being decrypted, therefore known public key. key decrypt private key, revealed. message encrypted public key decrypted private\u00a0key. Public Key Cryptographic (PKC) systems algorithms easy process direction difficult reverse, known mathematical trap-door functions. A simple example trap-door function product two prime numbers. two random prime numbers chosen, trivial find their product. However product two numbers known, relatively difficult find either factors create (this first noticed 1874, \u201cCan reader say two numbers multiplied together produce 8,616,460,799? think unlikely anyone myself ever\u00a0know.\u201d* simple problem shows finding product two (secret) prime numbers simple, factorising result not. problem key feature modern cryptography. Factoring prime numbers super famous mathematical problem, studied Eratosthenes 3 3rd century BC recently RSA Factoring Challenge intended track factorisation techniques issues cash prizes factorisation products large\u00a0primes. Generally, bigger difference difficulty between executing function reversing it, better RSA algorithm below uses factorisation foundation security, factorisation hardest problem solve relative size keys required. Algorithms been developed factor products large prime numbers, much efficient randomly guessing possible factors. greater size primes being factored, efficient these algorithms become, therefore difference difficulty between executing function (multiplying two large primes) reversing becomes smaller size cryptographic key length increases. problem public key cryptography becomes commonly resources available factor products primes increases, consequently larger keys are\u00a0required. Ultimately, encryption techniques based difficulty factorisation become redundant difficulty gap between creating solving them shrinks. A better trap door function is\u00a0required. Overview RSA\u00a0algorithm Named after founders (Ron Rivest, Adi Shamir, Leonard Adleman), RSA first public-key encryption algorithms still widely\u00a0used. RSA (as well other cryptographic techniques) makes loops back zero after reaching maximum value, rather increasing indefinitely. means once maximum \\(n\\) been defined, greater \\(n\\) created result simply loops around begins counting again. i.e. \\(n = 10\\), \\(7 + 5 = 12 - = 2\\). result calculation looping may easily found doing long division remainder final answer, i.e. \\(12 / = 1\\) Generation pair RSA\u00a0keys: 1. Generate RSA\u00a0module Select two large random prime numbers, \\(p\\) \\(q\\). They random anyone who knows guesses them able decrypt Calculate \\(n =\u00a0pq\\) 2. Find derived number\u00a0(e) e greater less \\(( p - 1)( q - 1)\\). There no common factor e \\(( p - 1)( q - 1)\\) except 1. 4 3. Form public\u00a0key pair numbers \\((n, e)\\) form public key made\u00a0public. Even though \\(n\\) public, difficult factor product large prime numbers attacker able find component primes available. strength RSA rests entirely difficulty factoring \\(n\\) two component prime\u00a0numbers. 4. Generate private key\u00a0(d) private key generated \\(p\\), \\(q\\) e inputs Extended Euclidean Algorithm. For given set values, there unique answer \\(d\\). \\(d\\) inverse \\(e\\) modulo \\(( p - 1)( q - )\\). means \\(d\\) less \\(( p - ) ( q - )\\) such multiplied e, equal \\(1\\) modulo \\(( p - ) ( q - )\\). RSA\u00a0example: RSA does directly operate strings bits, operates numbers modulo (less than) \\(n\\). necessary represent plain text series numbers less \\(n\\). dominant encoding internet UTF-8, represents upper case Latin letter between 65 90. Using encoding, message \u201cHELLO\u201d become \u201c\\(72, 69, 76, 76, 79\\)\u201d. maximum \\(n\\) needs product two prime numbers \\(p\\) \\(q\\). For example choose \\(p = 7\\) \\(q = 13\\), \\(n = 91\\) 5 public key component e any choose, long there no other common factor e \\(( p - ) ( q - )\\). In our example, requires there no common factor between 72 e other 1, e \\(= 5\\). Therefore our public key (91, 5). made available anyone without messages being decrypted difficulty factoring product (very large) prime\u00a0numbers. Using fact know 5 11 prime factors 55 e 5, Extended Euclidean Algorithm compute our private key \\(d\\), is\u00a029. Therefore prime factors 7 13 used, public key (91, 5) private key (91, 29). These parameters fully define functional RSA\u00a0system. Encoding To encode letter H message (\u2018H\u2019 \\(72\\) UTF-8), multiply itself \\(e\\) times (\\(e = 5\\)), remembering wrap around pass our maximum \\(n = 91\\). \\(72 \\times 72 = 5184, 5184 / 91 = 56\\) \\(88\\) remaining, (i.e. \\(5184 = 91 \\times 56 + 88\\)). Therefore: \\(72 \\times 72 = 5184 = 88\\) \\(88 \\times 72 = 6336 = 57\\) \\(57 \\times 72 = 4104 = 9\\) \\(9 \\times 72 = 648 =\u00a011\\) Therefore encrypted \u201cH\u201d \u201c\\(11\\)\u201c Using method character message \u201cHELLO\u201d results encoded message To decrypt message, take multiply itself \\(d\\) times, (\\(d=29\\)) wrapping around pass \\(91\\). \\(11 \\times 11 = 121 = 30\\) \\(30 \\times 11 = 330 = 57\\) \u2026 \\(57 \\times 11 = 627 = 81\\) \\(81 \\times 11 = 891 =\u00a072\\) And we\u2019re back our Files spreadsheet calculate encrypted decrypted values downloaded here. A simple python script encrypt decrypt message here. It uses AES Footnotes explanations here here lot.\u00a0\u21a9 A simple example \\(A=1, B=2\\) etc\u00a0\u21a9 Eratosthenes invented his famous sieving algorithm finds primes given limit.\u00a0\u21a9 case e ( p - 1) ( q - ) called \u201ccoprime\u201d\u00a0\u21a9 Whilst Extended Euclidean Algorithm apparently simple compute, description not. Therefore I\u2019ve same numbers following example tutorials here here.\u00a0\u21a9 { var align = \"center\", indent = \"0em\", linebreak = \"false\"; (false) { align = (screen.width","tag":"[, , , , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Digital currencies: the\u00a0basics","url":"digital-currencies-the-basics.html","body":"Digital currencies often discussed context finance, technology economics. Blockchain - technology applications Bitcoin built - significant removes trust intermediary between unrelated parties transacting other. So far, most influential famous digital currency is\u00a0Bitcoin. post intended introduce basic concepts digital currencies problems distributed ledger system needs to\u00a0overcome. What A digital currency internet based medium exchange. Units digital currency printed, physical, represent nothing. A unit currency produced running algorithms solve complex mathematical problems. When solution found, unit currency (for example, Bitcoin) is\u00a0generated. currency represents nothing, why it\u00a0valuable? Because people believe future, other people believe does, people willing trade real goods services exchange for\u00a0it. same dollars, sterling euros (fiat currencies) also don\u2019t represent anything physical. (Although these examples supported laws In past, creating currency without support government hasn\u2019t been A central bank required control physical creation currency (otherwise people create counterfeit currency, decreasing scarcity moving towards\u00a0zero) An intermediary (a bank) required large remote transactions, sure amount money party owns correctly recorded updated ledger (preventing double spending of\u00a0funds) technological breakthrough preventing double spending without requiring intermediary. made possible cryptographic techniques developed over last few decades, cheap, powerful computers recently Central With conventional currencies everyone\u2019s balance transactions recorded central ledger (a list showing much money account has) account holder access their own balance transactions. With digital currencies, copy entire ledger (every transaction ever made everyone) held computer (or node), anyone see two parties wish remote transaction bank intermediary. bank mediates updating central ledger record change parties funds result transaction. party knows counter-party able pay, payment confirmed. there copy ledger, maintained bank, bank involved every transaction between account holders. intermediary increases complexity cost Sending\u00a0money To send money, message broadcast network amount account should decrease amount another account should increase. Each computer network (a node) receives message check authenticity, changes, pass message along other\u00a0nodes. What problems does For transaction accepted entered distributed ledger, authenticity needs verified. Because ledger distributed, everyone see everyone else\u2019s transactions. Therefore user authentication transaction authorisation needs possible without compromising user\u2019s ability send secure payments in\u00a0future. There also problem double spending - currency neither physical, printed representative anything, prevent user spending their currency once, simply creating much currency they\u00a0want? Another problem addition transactions ledger unrelated users. party their own copy ledger, updating (or changing) want, ledgers completeness accuracy assured? How update ledger take account transactions between third parties, know order occurred?1 blockchain remarkable first technology solve these problems. Future posts consider these problems are\u00a0overcome. Byzantine Generals problem, nicely described introduction paper\u00a0\u21a9","tag":"[, , , , , ]","category":"Technical/Cryptocurrencies"},{"title":"Spare\u00a0time","url":"spare-time.html","body":"list interests want consider pursuing. wrote began study last set exams mind filled things I\u2019d rather doing instead. Some these interests just me reacting having no spare few months, others decent goals projects. Temporarily losing spare made me it\u00a0more. wrote post compare thought important busy wasn\u2019t. Writing list allowed me move without forgetting. Here\u2019s break down each\u00a0item: \u201cRun 10k 50 minutes\u201d - easier imagined. When wrote list barely run 2k without stopping, intended go weekly run whilst studying. I\u2019ve struggled stay energetic healthy during previous exam phases, now rule mild exercise even think can\u2019t spare time. find running really lowers stress levels, increasing heart rate working sweat lets me sleep better concentrate longer. After few weeks minimal running, run 5k easily. kept it, 10k 50 mins easy. But point\u00a02\u2026 \u201cBe Insanity strong\u201d - As in, Insanity workout programme. Again. thought decided P90x instead. Week going\u00a0great. \u201cRead bible habitually\u201d - When 17 found Jesus became Christian. In months years after I\u2019d regularly read bible almost every day pray lot. wanted understand, set goal 5 chapters each\u00a0day. read through testament repeatedly read most old testament during time. knew scriptures well enough lot sermons became boring obvious - I\u2019d already studied bible passage being used. During remember being aware way thought different been otherwise. My perspectives were long-term less me focused. thought reading instead days\u2019 headlines social chatter. remember enjoying benefits thinking should keep habit. reasons why think Christianity wonderful well summarised sermon. It\u2019s now years later, whilst convictions strong, knowledge bible sadly pretty fuzzy. My thinking clouded perspectives contained media consume conversations I\u2019m part of. strongly suspect acting thinking differently read bible more, don\u2019t know those differences be. Trouble is, it\u2019s often obvious immediate benefits reading bible are, work bit. Praying help effective. books bible were written last through ages across cultures, it\u2019s surprising they\u2019re easy read something written English speaker hurry. should stop being hurry, stop prioritising \u201cThink more\u201d - On similar note 3, less supernatural. spent less consuming content little looking around me walking, reckon I\u2019d self-aware better decisions. probably lead happier, \u201cPray more\u201d - don\u2019t know why, creator universe wants me talk share life him. He cares me. makes no sense me, all. God, go way consider views concerns very flawed human. But pray, prayers very often answered. should ask him about\u00a0this. \u201cAmazon seller?\u201d - Amazon \u201cFulfilled Amazon\u201d service, means don\u2019t even hold stock want sell. choose right products, import them cheaply China reselling them Amazon profit, end quids minimal effort manageable risk. \u201cBlog interesting data\u201d - Here am, blogging. should stick topic get technical. inspired blog in\u00a0particular. \u201cFinish Coursera\u201d - science specialization great! It\u2019s R, want focus Python, I\u2019d still it. consider opportunity cost \u201cRead fun, history, fiction\u201d - When started job, April 2014, half way through Savage Continent, eye-opening eye-watering history Europe years after World War 2. see Europe through different eyes it. However got half way though, since April \u201814 never felt had free energy pick back up. should change. When researcher, student, had much opportunity develop own pursuits. Since entering corporate world, find myself fighting war attrition exert personality onto my\u00a0lifestyle. Read fiction\u2026 I\u2019m unconvinced. What end it? What it? Maybe I\u2019ve just been reading wrong authors, I\u2019m going leave now. Sure, gain appreciation different place, appreciation comes via fictional characters events, secondary. What abstract constructs, perspectives, morals\u2026 things history books ill-suited for? Great fiction essential exploring these. But now, I\u2019ll prioritise point\u00a03. \u201cDo photography project\u201d - love do, probably won\u2019t. It luxury, opportunity cost too great right now. I\u2019d shoot series black white portraits, turn them large prints. think good portrait photography uniquely impactful moving, choosing B&W removes distractions leaves subjects humanity more\u00a0exposed. \u201cHave list ideas\u201d - There\u2019s no excuse one, anyone several good ideas. It\u2019s turning them reality takes skill. Need ideas first,\u00a0though. \u201cDo law MOOC\u201d - i.e Study particular areas law, own own pace. studied tiny bit law during ACA, realised employment law contract law really useful. (Same tax system - another surprise). We had brief introduction though, find I\u2019d know\u00a0more. \u201cDo InfoSec Network Security MOOC\u201d - Its super interesting, likely good of\u00a0time. \u201cLearn fight - Krav Maga / MMA\u201d - Ever since watching Bourne Identity I\u2019ve wanted learn Krav Maga, Georges St-Pierre made me want train MMA. For now though, I\u2019ll P90x. reconsider 90\u00a0days. \u201cGet London\u201d - My contract ends April 2017, next summer crossroads. hate commute, hate being constantly rushed. Living other cities been lot more\u00a0pleasant.","tag":"[, , ]","category":"Non-technical/Family"},{"title":"\u00dcbersicht widget: Time\u00a0Until","url":"time-until.html","body":"In previous post described introduced CoffeeScript via \u00dcbersicht, desktop widget app OS X, eventually published \u201cTime Since\u201d\u00a0widget. Seeing few people download widget really satisfying, soon wondering else publish. As pragmatic engineer, seemed clear me next widget should do: first widget calculated since event, next should calculate until event. set create companion \u201cTime Since\u201d improve upon My first code design choice cut Apple Script calculated everything CoffeeScript file. It efficient easier to\u00a0read. Unfortunately soon began realise why original widget I\u2019d based \u201cTime Since\u201d had AppleScript calculate elapsed. Date-Times fiddly work languages, true My code began look increasingly spaghetti tried achieve 6 key\u00a0features: Calculate months days between two dates (complicated varying days Add option specify level detail output text (to minute, hour, day,\u00a0etc.) Remove any amounts output (\u201c2 Months 5 Hours\u201d \u201c2 Months, Days 5\u00a0Hours\u201d) Add option abbreviate times (\u2018years\u2019 \u2192 \u2018y\u2019, \u2018hours\u2019 \u2192 \u2018h\u2019, \u2018and\u2019 \u2192 \u2018&\u2019,\u00a0etc.) Output grammatically correct sentence (correct pluralisation comma separated terms, \u201cand\u201d between last two\u00a0terms) Prepend append users After few frustrating hours, clear lot easier modify existing AppleScript rather reinvent wheel JavaScript. decided instead JavaScript knew AppleScript file correctly consider days months between dates (feature 1), contains function pluralise correct parts string (feature\u00a05). remaining features were added combination statements arrays. statements simply ask amount equal zero. not, it\u2019s appended array terms include output. At end code chunk it\u2019s possible ask non-zero terms include output. An array length less output terms created filled commas \u2018and\u2019 two arrays combined correct order looping through index longer array appending term final array. final array the\u00a0output. \u2018Time Until\u2018 downloaded \u00dcbersicht widgets gallery. think another useful feature option specify output terms chosen amount, such weeks days. Maybe I\u2019ll the\u00a0future.","tag":"[, , , , , ]","category":"Technical/Web"},{"title":"How to wake up\u00a0early","url":"how-to-wake-up-early.html","body":"For years I\u2019ve wished wake early quiet pre-breakfast hours productivity. And years spectacularly failed this. love quiet, hours end day too, well waking slowly.1 Many famous leaders politicians known start their days early, able too. After years trying failing, had secret waking early is\u00a0this: Become a\u00a0parent. After first couple months a\u00a0new-born: You well-practiced quickly waking previously You operating less sleep ever Your beautiful child become reliable alarm clock, waking crack dawn cute smiles increasingly insistent demands get up, play freedom begin sleeping working want, still believe great option. bashed PhD 3.5 years during usually woke late began work around lunch time! - Glorious autonomy!\u00a0\u21a9","tag":"[, ]","category":"Non-technical/Family"},{"title":"Jupyter (iPython) notebooks +\u00a0Pandas","url":"Jupyter-ipython-notebooks-pandas.html","body":"When working fit Excel file, want sure won\u2019t edited, usually interact One biggest sinks (for me) working these tools (ACL, SQL, Python) debugging, working exactly where chain individual commands something unexpected happened. Even modest page code, quickly find myself rerunning entire script multiple times commenting-out uncommenting multiple lines order understand what\u2019s really going on. consuming task start script, such summarise sort command, extra required even greater. leads interrupted flow Pandas python package manipulate large datasets, Jupyter notebook application allows user run python script chunks, output results chunk before continuing. You re-run previous chunk without returning beginning, change code go along. amazingly flexible and\u00a0intuitive. recently worked through exceptionally good Pandas tutorial recorded PyCon 2015. \u201cPandas ground up\u201d well structured, clear, good scope resources available download github. Brandon Rhodes gives good working foundation Pandas Jupyter notebook manipulate datasets using\u00a0Python.","tag":"[, , , ]","category":"Technical/Developer Tools"},{"title":"Coursera\u2019s \u201cData Science\u00a0Specialisation\u201d","url":"courseras-data-science-specialisation.html","body":"Last year decided learn tools required work scientist. confident already had mathematical analysis skills needed, wasn\u2019t familiar tools the\u00a0trade. Some googling brought me Coursera, Data Science Specialisation run Johns Hopkins University. It consists 9 courses, far I\u2019ve completed five. courses order prior knowledge isn\u2019t required, think courses strike good balance brevity and\u00a0depth. downside me courses exclusively R (which popular academia) rather Python (which popular in\u00a0Industry). Each course lasts 3 weeks deals specific aspect science, such statistical inference machine learning. Key concepts tools subject explained developed, whilst it\u2019s thorough longer course be, there enough material packed lectures, quizzes, assignments projects apply I\u2019ve read second half specialisation lot technical first, I\u2019m looking forward setting aside time, working through assignments acquiring useful\u00a0skills!","tag":"[, , ]","category":"Technical/Data Science"},{"title":"\u00dcbersicht widget: Time\u00a0Since","url":"ubersicht-widget-time-since.html","body":"\u00dcbersicht desktop widgets app OS X. Its free, open source, pretty good widgets library download play with. A widget small app feature embeds desktop displays simple information. It tell song currently playing, weather forecast, disk space remaining, etc. widgets written CoffeeScript, variant of\u00a0JavaScript. When started \u00dcbersicht began playing widgets, changing their appearance their position screen. Some widgets too complicated mess without specific programming knowledge, others surprisingly simple and\u00a0intuitive. By trial error, began customize widgets preferences. One widget wanted couldn\u2019t simply download timer tell me exactly much had elapsed since specific past\u00a0event. By combining display attributes widget calculation method another, able mash together foundation widget. added extra Optional text before after elapsed\u00a0time Choice expanded abbreviated display\u00a0styles Flexible formatting remove zero\u00a0amounts widget called \u201cTime Since\u201d \u00dcbersicht widgets gallery.","tag":"[, , , , , , ]","category":"Technical/Web"}]